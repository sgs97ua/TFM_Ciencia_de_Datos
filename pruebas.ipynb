{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install https://github.com/amazon-science/ReFinED/archive/refs/tags/V1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden utilizar dos tipos de conjuntos de entidades:\n",
    "- Wikipedia: 6M que son aquella que tienen página de wikipedia\n",
    "- Wikidata: 33M no se encuentran todas ya que muchas han sido filtradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proporcionan 4 versiones de modelos que han sido entrenados en base a la arquitectura.\n",
    "\n",
    "* wikipedia_model: Es en el que se ha entrenado el modelo descrito en el paper\n",
    "* wikipedia_model_with_numbers: Igual que en caso anterior pero agrega la inferencia del tipo de dato numérico por parte de spacy.\n",
    "* aida_model: modelo fine tuenado para entity linking de AIDA, no es el mismo que se utiliza para entity disambiguation.\n",
    "* question_model: Modelo que es finetuenado en dataset WebQSP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Linking Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine-tuned with AIDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL results (with model fine-tuned on AIDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AIDA: 231it [00:12, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8495\n",
      "accuracy: 0.9017\n",
      "gold_recall: 0.9785\n",
      "p: 0.8031\n",
      "r: 0.9017\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "*******MD*****\n",
      "MD_f1: 0.9534, (p: 0.9479, r: 0.9589)\n",
      "*****************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:01, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7505\n",
      "accuracy: 0.7926\n",
      "gold_recall: 0.9954\n",
      "p: 0.7127\n",
      "r: 0.7926\n",
      "num_gold_spans: 651\n",
      "************\n",
      "*******MD*****\n",
      "MD_f1: 0.8409, (p: 0.8055, r: 0.8796)\n",
      "*****************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from refined.evaluation.evaluation import eval_all\n",
    "from refined.inference.processor import Refined\n",
    "refined = Refined.from_pretrained(model_name='aida_model',\n",
    "                                  entity_set='wikipedia',\n",
    "                                  use_precomputed_descriptions=True)\n",
    "print('EL results (with model fine-tuned on AIDA)')\n",
    "metrics = eval_all(refined=refined, el=True, filter_nil_spans=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that the paper is based on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL results (with model fine-tuned on Wikipedia model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AIDA: 231it [00:08, 28.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7825\n",
      "accuracy: 0.8118\n",
      "gold_recall: 0.9785\n",
      "p: 0.7552\n",
      "r: 0.8118\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "*******MD*****\n",
      "MD_f1: 0.9295, (p: 0.9238, r: 0.9352)\n",
      "*****************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7343\n",
      "accuracy: 0.7727\n",
      "gold_recall: 0.9954\n",
      "p: 0.6996\n",
      "r: 0.7727\n",
      "num_gold_spans: 651\n",
      "************\n",
      "*******MD*****\n",
      "MD_f1: 0.7971, (p: 0.7649, r: 0.8322)\n",
      "*****************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AIDA': Metrics(el=True, num_gold_spans=4464, tp=3624, fp=1175, fn=840, tp_md=5252, fp_md=433, fn_md=364, gold_entity_in_cand=4368, num_docs=231, example_errors=[{'doc_title': 'SOCCER - JAPAN GET L', 'fp_errors': [('Asian Cup', 141, 'Q157894'), ('Syrian', 1177, 'Q878607'), ('Salem Bitar', 1206, 'Q7404049'), ('Bitar', 1479, 'Q7404049'), ('Nader Jokhadar', 1493, 'Q6957562')], 'fn_errors': [('AL-AIN', 68, 'Q234600'), ('Asian Cup', 141, 'Q369539'), ('Chinese', 570, 'Q148'), ('Asian Games', 832, 'Q729592'), ('Syrian', 1177, 'Q272097')]}, {'doc_title': 'RUGBY UNION - CUTTIT', 'fp_errors': [('CUTTITTA', 14, 'Q3297752'), ('Stefano Bordon', 455, 'Q3497946'), ('Coste', 497, 'Q1117881'), ('World Cup', 681, 'Q16640'), ('Coste', 790, 'Q1117881')], 'fn_errors': [('RUGBY UNION', 0, 'Q5849'), ('CUTTITTA', 14, 'Q1421525'), ('ITALY', 32, 'Q113135'), ('1995 World Cup', 676, 'Q1130017')]}, {'doc_title': 'SOCCER - LATE GOALS ', 'fp_errors': [('AL-AIN', 47, 'Q812720'), ('Salem Bitar', 287, 'Q7404049'), ('Syrian', 393, 'Q878607'), ('Bitar', 573, 'Q7404049'), ('Nader Jokhadar', 667, 'Q6957562')], 'fn_errors': [('AL-AIN', 47, 'Q234600'), ('Syrian', 393, 'Q272097'), ('Syrian', 810, 'Q272097')]}, {'doc_title': 'FREESTYLE SKIING-WOR', 'fp_errors': [('Jesper Ronnback', 148, 'Q6086841'), ('Andrei Ivanov', 189, 'Q9151163'), ('Ryan Johnson', 221, 'Q9324232'), ('Jim Moran', 362, 'Q97170659'), ('U.S', 373, 'Q30')], 'fn_errors': [('World Cup', 83, 'Q1453654'), ('U.S.', 373, 'Q30'), ('U.S.', 472, 'Q30'), ('U.S.', 637, 'Q30'), ('U.S.', 670, 'Q30')]}, {'doc_title': 'SOCCER - ASIAN CUP G', 'fp_errors': [('Nader Jokhadar', 233, 'Q6957562')], 'fn_errors': [('AL-AIN', 36, 'Q234600')]}, {'doc_title': 'CRICKET - PAKISTAN V', 'fp_errors': [('PAKISTAN', 10, 'Q7125780'), ('Ijaz Ahmad', 299, 'Q47405325'), ('Vaughan', 323, 'Q1929664'), ('Astle', 360, 'Q7812250'), ('Astle', 428, 'Q7812250')], 'fn_errors': [('PAKISTAN', 10, 'Q182538'), ('Vaughan', 323, 'Q16197357'), ('Astle', 360, 'Q6968870'), ('Harris', 382, 'Q5106801'), ('Harris', 407, 'Q5106801')]}, {'doc_title': 'SOCCER - ENGLISH F.A', 'fp_errors': [('ENGLISH F.A. CUP', 9, 'Q11151'), ('English', 78, 'Q21'), ('F.A. Challenge Cup', 86, 'Q11151')], 'fn_errors': []}, {'doc_title': 'SOCCER - BLINKER BAN', 'fp_errors': [('Dutch', 47, 'Q55')], 'fn_errors': [('Dutch', 47, 'Q47050'), ('Swiss', 712, 'Q39')]}, {'doc_title': \"SOCCER - LEEDS ' BOW\", 'fp_errors': [('England under-21', 86, 'Q204238'), (\"McDonald's\", 230, 'Q38076'), ('Yorkshire', 689, 'Q163')], 'fn_errors': [('LEEDS', 9, 'Q1128631'), ('England', 86, 'Q21')]}, {'doc_title': 'BASKETBALL - EUROLEA', 'fp_errors': [('EUROLEAGUE', 13, 'Q185982'), ('EuroLeague', 76, 'Q185982'), ('Turkey', 297, 'Q43'), ('Olympiakos', 412, 'Q847701'), ('Charleroi', 541, 'Q81046')], 'fn_errors': [('EUROLEAGUE', 13, 'Q5411943'), ('EuroLeague', 76, 'Q5411943'), ('Charleroi', 541, 'Q597364'), ('Bayer Leverkusen', 722, 'Q707832')]}, {'doc_title': 'RUGBY UNION - LITTLE', 'fp_errors': [('RUGBY', 0, 'Q2934697'), ('Australia', 109, 'Q622443'), ('Little', 191, 'Q3162966'), ('Daniel Manu', 487, 'Q3014401'), ('Australian', 725, 'Q622443')], 'fn_errors': [('RUGBY UNION', 0, 'Q5849'), ('CAMPESE', 29, 'Q1173922'), ('Australia', 109, 'Q408'), ('Australian', 725, 'Q408'), ('England', 1605, 'Q21')]}, {'doc_title': 'GOLF - ZIMBABWE OPEN', 'fp_errors': [('U.S', 337, 'Q30'), ('Andrew Park', 426, 'Q4758202'), ('Schalk van der Merwe', 448, 'Q7430937'), ('Greg Reid', 508, 'Q5606179'), ('Sammy Daniels', 626, 'Q7409821')], 'fn_errors': [('U.S.', 337, 'Q30'), ('U.S.', 695, 'Q30')]}, {'doc_title': 'SOCCER - UNCAPPED PL', 'fp_errors': [('Valentin Stefan', 228, 'Q12743029'), ('Iordanescu', 418, 'Q539072'), ('Turkish', 858, 'Q43'), ('Valentin Stefan', 1167, 'Q12743029')], 'fn_errors': [('BUCHAREST', 52, 'Q19660'), ('World Cup', 196, 'Q19317'), ('European', 362, 'Q46'), ('Macedonia', 392, 'Q221'), ('European Cup', 740, 'Q18756')]}, {'doc_title': 'SOCCER - BRAZILIAN C', 'fp_errors': [], 'fn_errors': [('BRAZILIAN', 9, 'Q155')]}, {'doc_title': 'CRICKET - LARA ENDUR', 'fp_errors': [], 'fn_errors': [('MELBOURNE', 60, 'Q3141'), ('World Series', 196, 'Q3349761'), ('World Series', 1767, 'Q3349761')]}, {'doc_title': 'CRICKET - AUSTRALIA ', 'fp_errors': [('Moody', 278, 'Q6907187'), ('S. Chanderpaul', 286, 'Q967484'), ('C. Hooper', 322, 'Q2963834'), ('Moody', 357, 'Q6907187'), ('J. Murray', 365, 'Q317820')], 'fn_errors': [('WEST INDIES', 22, 'Q912881'), ('WORLD SERIES', 34, 'Q3349761'), ('World Series', 98, 'Q3349761'), ('Moody', 278, 'Q3537597'), ('Moody', 357, 'Q3537597')]}, {'doc_title': 'CRICKET - AUSTRALIA ', 'fp_errors': [('MELBOURNE', 54, 'Q4289724')], 'fn_errors': [('MELBOURNE', 54, 'Q3141'), ('World Series', 123, 'Q3349761')]}, {'doc_title': 'CRICKET - WEST INDIE', 'fp_errors': [('MELBOURNE', 61, 'Q4289724')], 'fn_errors': [('MELBOURNE', 61, 'Q3141'), ('World Series', 137, 'Q3349761')]}, {'doc_title': 'CRICKET - SHEFFIELD ', 'fp_errors': [('Australia', 42, 'Q142555')], 'fn_errors': [('Australia', 42, 'Q408')]}, {'doc_title': 'CRICKET - LARA SUFFE', 'fp_errors': [('AUSTRALIAN', 28, 'Q142555'), ('Australian', 133, 'Q142555'), ('Australian', 872, 'Q1318423')], 'fn_errors': [('MELBOURNE', 52, 'Q3141'), ('Australian', 133, 'Q408'), ('Australian', 872, 'Q408'), ('World Series', 2032, 'Q3349761')]}, {'doc_title': 'CRICKET - WEST INDIE', 'fp_errors': [('MELBOURNE', 53, 'Q4289724'), ('Melbourne Cricket Ground', 237, 'Q330136')], 'fn_errors': [('MELBOURNE', 53, 'Q3141'), ('World Series', 173, 'Q3349761'), ('Melbourne', 237, 'Q3141')]}, {'doc_title': 'BADMINTON - WORLD GR', 'fp_errors': [('Chen Gang', 166, 'Q1069691'), ('Indra Wijaya', 302, 'Q1661820'), ('Budi Santoso', 596, 'Q1001420'), ('Indra Wijaya', 705, 'Q1661820'), ('Meiluawati', 897, 'Q1917844')], 'fn_errors': []}, {'doc_title': 'SOCCER - ARAB CONTRA', 'fp_errors': [('ARAB CONTRACTORS', 9, 'Q2073915'), ('Arab Contractors', 174, 'Q2073915'), ('Zaire', 211, 'Q6500954')], 'fn_errors': [('National stadium', 145, 'Q6634155'), ('Arab Contractors', 174, 'Q4783172'), ('Zaire', 211, 'Q974')]}, {'doc_title': 'NHL ICE HOCKEY - STA', 'fp_errors': [('NEW YORK', 51, 'Q60'), ('MONTREAL', 341, 'Q188143'), ('OTTAWA', 395, 'Q203013'), ('ATLANTIC DIVISION', 418, 'Q756394'), ('FLORIDA', 452, 'Q812')], 'fn_errors': [('NHL', 0, 'Q1215892'), ('MONTREAL', 341, 'Q340'), ('OTTAWA', 395, 'Q281504'), ('ATLANTIC', 418, 'Q756394'), ('FLORIDA', 452, 'Q204623')]}, {'doc_title': 'NHL ICE HOCKEY - THU', 'fp_errors': [('La Clippers', 159, 'Q976396'), ('Ny Islanders', 174, 'Q194369'), ('CAP', 255, 'Q179304'), ('FLORIDA', 283, 'Q812'), ('Ny Islanders', 293, 'Q194369')], 'fn_errors': [('NHL', 0, 'Q1215892'), ('FLORIDA', 283, 'Q204623')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors': [('INDIANAPOLIS', 68, 'Q193753'), ('AFC', 183, 'Q276530'), ('NFC East', 845, 'Q594428'), ('NFC', 1063, 'Q319007'), ('NFC', 1985, 'Q319007')], 'fn_errors': [('NFL', 0, 'Q1215884'), ('EAGLES', 36, 'Q219714'), ('INDIANAPOLIS', 68, 'Q6346'), ('Colts', 420, 'Q193753'), ('Eagles', 464, 'Q219714')]}, {'doc_title': 'NBA BASKETBALL - STA', 'fp_errors': [('NEW YORK', 51, 'Q60'), ('BOSTON', 360, 'Q100'), ('NEW JERSEY', 378, 'Q1408'), ('CENTRAL DIVISION', 404, 'Q745984'), ('MILWAUKEE', 530, 'Q37836')], 'fn_errors': [('NBA', 0, 'Q155223'), ('ATLANTIC', 227, 'Q638908'), ('NEW YORK', 273, 'Q131364'), ('WASHINGTON', 311, 'Q169165'), ('BOSTON', 360, 'Q131371')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors': [('AMERICAN FOOT', 198, 'Q1116609'), ('CLINCHED', 1156, 'Q304821'), ('CLINCHED', 1184, 'Q304821')], 'fn_errors': [('NFL', 0, 'Q1215884'), ('AMERICAN', 198, 'Q30'), ('NEW ENGLAND', 256, 'Q193390'), ('BUFFALO', 282, 'Q221626'), ('INDIANAPOLIS', 304, 'Q193753')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors': [('National Football League', 71, 'Q1215884')], 'fn_errors': [('NFL', 0, 'Q1215884'), ('National', 71, 'Q1215884'), ('INDIANAPOLIS', 135, 'Q193753')]}, {'doc_title': 'NCAA AMERICAN FOOTBA', 'fp_errors': [('PACE', 36, 'Q4910419'), ('the Lombardi Award', 166, 'Q1868747'), ('the Rotary Club', 205, 'Q109179'), ('Houston', 224, 'Q16555'), ('the Rose Bowl', 360, 'Q543429')], 'fn_errors': [('NCAA', 0, 'Q271805'), ('PACE', 36, 'Q25478'), ('Lombardi Award', 170, 'Q1868747'), ('Rotary Club', 209, 'Q109179'), ('Houston', 224, 'Q5916446')]}, {'doc_title': 'SOCCER - DUTCH FIRST', 'fp_errors': [('Vitesse Arnhem', 395, 'Q219233'), ('Heerenveen', 461, 'Q574558')], 'fn_errors': [('DUTCH', 9, 'Q55'), ('Heerenveen', 461, 'Q200321')]}, {'doc_title': 'SOCCER - GERMAN FIRS', 'fp_errors': [('Karlsruhe', 193, 'Q695784'), ('Karlsruhe', 465, 'Q695784'), ('FC Cologne', 525, 'Q104770')], 'fn_errors': [('GERMAN', 9, 'Q183'), ('BONN', 52, 'Q586'), ('German', 79, 'Q183'), ('Karlsruhe', 193, 'Q105853'), ('Karlsruhe', 465, 'Q105853')]}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors': [(\"Japhet N'Doram\", 123, 'Q982887'), ('Christophe Pignol', 184, 'Q2966445'), (\"Bruno N'Gotty\", 262, 'Q708079'), ('Paul Fischer', 288, 'Q339970')], 'fn_errors': [('FRENCH', 9, 'Q142')]}, {'doc_title': 'SOCCER - DUTCH FIRST', 'fp_errors': [('Starbuck', 142, 'Q7182442'), ('Van der Vegt', 190, 'Q2588496')], 'fn_errors': [('DUTCH', 9, 'Q55')]}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors': [('PARIS', 34, 'Q1051013'), ('Lille', 433, 'Q2338486'), ('Le Havre', 557, 'Q42810'), ('Montpellier', 609, 'Q6441'), ('Caen', 639, 'Q41185')], 'fn_errors': [('FRENCH', 9, 'Q142'), ('PARIS', 34, 'Q90'), ('Lille', 433, 'Q19516'), ('Le Havre', 557, 'Q328658'), ('Montpellier', 609, 'Q19513')]}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors': [], 'fn_errors': [('FRENCH', 9, 'Q142')]}, {'doc_title': 'SOCCER - GERMAN FIRS', 'fp_errors': [('GERMAN', 9, 'Q43310'), ('Kirsten', 188, 'Q817570'), ('Karlsruhe', 341, 'Q1040'), ('Reich', 354, 'Q1581943'), ('Carl', 366, 'Q5040323')], 'fn_errors': [('GERMAN', 9, 'Q183'), ('BONN', 42, 'Q586'), ('Kirsten', 188, 'Q310519'), ('Karlsruhe', 341, 'Q105853'), ('Reich', 354, 'Q318266')]}, {'doc_title': 'TENNIS - GRAND SLAM ', 'fp_errors': [('U.S', 273, 'Q30')], 'fn_errors': [('U.S.', 273, 'Q30')]}, {'doc_title': 'SOCCER - WEAH HEAD-B', 'fp_errors': [('Joao Manuel Pinto', 112, 'Q3187314'), ('Liberian', 291, 'Q1014'), ('Joao Manuel Pinto', 795, 'Q3187314'), ('Deportivo Coruna', 892, 'Q8760'), ('Jose Barroso', 1027, 'Q6291660')], 'fn_errors': [('PORTUGAL', 33, 'Q267245'), ('LISBON', 52, 'Q597'), ('World Cup', 161, 'Q19317'), ('Liberian', 291, 'Q387301'), ('European', 468, 'Q46')]}, {'doc_title': 'SOCCER SHOWCASE-BETT', 'fp_errors': [('Barcelona', 201, 'Q1492'), ('Barcelona', 257, 'Q1492'), ('Ronaldo', 786, 'Q529207'), ('Giovanni', 888, 'Q18392356'), ('Victor Sanchez', 902, 'Q545968')], 'fn_errors': [('Barcelona', 201, 'Q7156'), ('Barcelona', 257, 'Q7156')]}, {'doc_title': 'SOCCER SHOWCASE-FANS', 'fp_errors': [('Santiago Bernabeu', 133, 'Q164027'), ('Real Madrid', 204, 'Q8682'), ('Barcelona', 216, 'Q7156')], 'fn_errors': [('Santiago Bernabeu stadium', 133, 'Q164027')]}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors': [('Deportivo Coruna', 270, 'Q8760'), ('Sporting Gijon', 665, 'Q12278'), ('Logrones', 698, 'Q657865'), ('Extremadura', 834, 'Q994224')], 'fn_errors': [('SPANISH', 9, 'Q29'), ('Sporting', 665, 'Q12278'), ('Extremadura', 834, 'Q732742')]}, {'doc_title': 'SOCCER - SPAIN PICK ', 'fp_errors': [('ARMANDO', 29, 'Q678578'), ('Spain', 76, 'Q42267'), ('Deportivo Coruna', 123, 'Q8760'), ('Armando Alvarez', 151, 'Q3321164'), ('Yugoslavia', 216, 'Q188363')], 'fn_errors': [('SPAIN', 9, 'Q29'), ('WORLD CUP', 41, 'Q101730'), ('Spain', 76, 'Q29'), ('World Cup', 188, 'Q19317')]}, {'doc_title': 'SOCCER - FIFA BOSS H', 'fp_errors': [('world soccer', 159, 'Q729035'), ('fair play', 174, 'Q1388547'), ('Fair Play award', 457, 'Q1388547'), ('Havelange', 518, 'Q207358'), ('European', 836, 'Q35572')], 'fn_errors': [('European', 836, 'Q46'), ('Italians', 1381, 'Q676899')]}, {'doc_title': 'GUNMEN WOUND TWO MAN', 'fp_errors': [], 'fn_errors': [('Britons', 220, 'Q842438')]}, {'doc_title': 'SOCCER - ITALIAN FIR', 'fp_errors': [('ITALIAN', 9, 'Q676899'), ('Italian Serie A', 70, 'Q15804'), ('Piacenza', 190, 'Q3659590'), ('Russian', 357, 'Q49542'), ('Piacenza', 439, 'Q3659590')], 'fn_errors': [('ITALIAN', 9, 'Q38'), ('Italian', 70, 'Q38'), ('Serie A', 78, 'Q15804'), ('Piacenza', 190, 'Q459794'), ('Russian', 357, 'Q159')]}, {'doc_title': 'BASKETBALL - EUROLEA', 'fp_errors': [('EUROLEAGUE', 13, 'Q185982'), ('EuroLeague', 64, 'Q185982'), ('Charleroi', 129, 'Q81046'), ('Charleroi', 208, 'Q81046'), ('Ron Ellis', 238, 'Q3940963')], 'fn_errors': [('EUROLEAGUE', 13, 'Q5411943'), ('EuroLeague', 64, 'Q5411943'), ('Charleroi', 129, 'Q597364'), ('Charleroi', 208, 'Q597364')]}, {'doc_title': 'SQUASH - EYLES WITHI', 'fp_errors': [('World Open', 260, 'Q581634'), ('Australian', 314, 'Q1318423'), ('Englishman', 348, 'Q21')], 'fn_errors': [('Australian', 314, 'Q408'), ('Englishman', 348, 'Q42406')]}, {'doc_title': 'SQUASH - MAHINDRA IN', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'GUNMEN KILL FOUR IN ', 'fp_errors': [('ZULU', 31, 'Q129962'), (\"South Africa's\", 157, 'Q258'), ('Zulu', 181, 'Q129962'), ('Izingolweni', 418, 'Q1676136'), ('Zulu', 1367, 'Q129962')], 'fn_errors': [('ZULU', 31, 'Q729768'), ('South Africa', 157, 'Q258'), ('Zulu', 181, 'Q729768'), ('Zulu', 1367, 'Q729768')]}, {'doc_title': 'HAVEL PRAISES CZECH ', 'fp_errors': [('Czech', 179, 'Q170217'), ('the United States', 481, 'Q30'), ('State', 566, 'Q789915'), ('velvet revolution', 657, 'Q182817'), ('Communist', 692, 'Q6186')], 'fn_errors': [('HAVEL', 0, 'Q36233'), ('CZECH', 14, 'Q213'), ('Czech', 179, 'Q213'), ('United States', 204, 'Q30'), ('United States', 485, 'Q30')]}, {'doc_title': 'RADIO ROMANIA AFTERN', 'fp_errors': [('RADIO ROMANIA', 0, 'Q3488631'), ('BUCHAR', 42, 'Q7342485'), ('Radio Romania', 63, 'Q3488631'), ('The Democratic Convention', 96, 'Q2420523'), ('the Social Democratic Union', 210, 'Q1263608')], 'fn_errors': [('BUCHAREST', 42, 'Q19660'), ('Oradea', 681, 'Q2102332'), ('Sibiu', 692, 'Q946418')]}, {'doc_title': 'CZECH VICE-PM SEES W', 'fp_errors': [('ODS', 142, 'Q828099'), ('ODS', 230, 'Q828099'), ('ODS', 613, 'Q828099'), ('ODS', 854, 'Q828099'), ('Klaus', 876, 'Q57434')], 'fn_errors': [('CZECH', 0, 'Q213')]}, {'doc_title': 'POLAND GOT MONEY FRO', 'fp_errors': [('the World War Two', 263, 'Q362'), (\"Alfonse D'Amato\", 682, 'Q2064037'), ('U.S. Senate Banking Committee', 724, 'Q7891260'), ('Nazi', 1006, 'Q7310'), ('communists', 1260, 'Q6186')], 'fn_errors': [('POLAND', 0, 'Q36'), ('WARSAW', 64, 'Q270'), ('Polish', 162, 'Q36'), ('World War Two', 267, 'Q362'), ('Swiss', 438, 'Q39')]}, {'doc_title': 'INTERVIEW-ZYWIEC SEE', 'fp_errors': [('ZYWIEC', 10, 'Q75438'), ('Zywiec', 88, 'Q75438'), ('Zywiec', 615, 'Q75438'), ('Van Boxmeer', 777, 'Q1701997'), ('van Boxmeer', 1128, 'Q1701997')], 'fn_errors': [('WARSAW', 56, 'Q270'), ('Heineken', 1656, 'Q180855'), ('Okocim', 1704, 'Q2017377')]}, {'doc_title': 'HAVEL HAS TRAECHEOTO', 'fp_errors': [], 'fn_errors': [('HAVEL', 0, 'Q36233')]}, {'doc_title': 'UK-US open skies tal', 'fp_errors': [('UK-US', 0, 'Q1227237'), ('UK', 70, 'Q145'), ('Department of Transport', 73, 'Q2982287'), ('DOT', 307, 'Q2982287')], 'fn_errors': []}, {'doc_title': 'Tambang Timah at $ 1', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Telkom at $ 35 in Lo', 'fp_errors': [('Telkom', 0, 'Q1818970')], 'fn_errors': [('Telkom', 0, 'Q2305438')]}, {'doc_title': 'Woman charged over N', 'fp_errors': [], 'fn_errors': [('BELFAST', 41, 'Q10686')]}, {'doc_title': 'Britain sets conditi', 'fp_errors': [('Atlantic', 161, 'Q97'), ('Trade and Industry', 334, 'Q584148'), ('the United States', 503, 'Q30'), ('trans-Atlantic', 535, 'Q13479645'), ('Lang', 617, 'Q333030')], 'fn_errors': [('United States', 507, 'Q30'), ('U.S.', 1014, 'Q30'), ('American', 1378, 'Q30'), ('American', 1453, 'Q30'), ('AMR Corp.', 1472, 'Q295280')]}, {'doc_title': 'Med oil products mos', 'fp_errors': [('Elf', 33, 'Q154037'), ('Mediterranean', 68, 'Q4918'), ('Elf', 139, 'Q154037'), ('Elf', 1398, 'Q154037'), ('Elf', 1526, 'Q154037')], 'fn_errors': [('Elf', 33, 'Q1505649'), ('Elf', 139, 'Q1505649'), ('Elf', 1398, 'Q1505649'), ('Elf', 1526, 'Q1505649')]}, {'doc_title': 'New meningitis scare', 'fp_errors': [], 'fn_errors': [('Lanarkshire', 1239, 'Q530296')]}, {'doc_title': \"Major's office-Conse\", 'fp_errors': [('Downing Street', 454, 'Q192687'), ('House of Commons', 794, 'Q11005'), ('House of Commons', 1001, 'Q11005')], 'fn_errors': [('Downing Street', 454, 'Q169101')]}, {'doc_title': 'Electronic Data bags', 'fp_errors': [('Electronic Data', 0, 'Q173285'), ('Electronic Data Systems', 89, 'Q691126'), ('Private Finance Initiative', 218, 'Q7246203'), ('EDS', 262, 'Q691126'), ('the Civil Aviation Authority', 518, 'Q795009')], 'fn_errors': [('Electronic Data Systems', 89, 'Q28782856'), ('EDS', 262, 'Q28782856'), ('Civil Aviation Authority', 522, 'Q795009')]}, {'doc_title': 'RTRS - Cricket - Pla', 'fp_errors': [('Sydney Newsroom', 393, 'Q7669731')], 'fn_errors': [('World Series', 112, 'Q3349761')]}, {'doc_title': 'Cricket - Pakistan b', 'fp_errors': [('Pakistan', 57, 'Q182538')], 'fn_errors': [('Pakistan', 57, 'Q843')]}, {'doc_title': 'Manitoba Pork forwar', 'fp_errors': [('Canadian', 119, 'Q1104069'), ('Manitoba Government', 672, 'Q1191519'), ('Manitoba', 731, 'Q1948'), ('CAN', 780, 'Q1104069')], 'fn_errors': [('Canadian', 119, 'Q16'), ('CAN', 780, 'Q16')]}, {'doc_title': 'Canadian West Coast ', 'fp_errors': [('Canadian West Coast', 0, 'Q3010627'), ('CWB', 38, 'Q2511292'), ('The Canadian Wheat Board', 63, 'Q2511292'), ('the Canadian West Coast', 143, 'Q3010627'), ('the West Coast', 210, 'Q12606')], 'fn_errors': [('Canadian', 0, 'Q16'), ('Canadian Wheat Board', 67, 'Q2511292'), ('Canadian', 147, 'Q16')]}, {'doc_title': 'New York timecharter', 'fp_errors': [('NEW YORK', 39, 'Q1384'), ('New York', 89, 'Q1384')], 'fn_errors': [('New York', 0, 'Q60'), ('NEW YORK', 39, 'Q60'), ('New York', 89, 'Q60')]}, {'doc_title': 'New York coal / ore ', 'fp_errors': [('New York', 0, 'Q1384'), ('ORE', 66, 'Q102798'), ('Dampier', 101, 'Q1158897'), ('Kaohsiung', 111, 'Q181557')], 'fn_errors': [('New York', 0, 'Q60')]}, {'doc_title': 'Clean tankers fixtur', 'fp_errors': [], 'fn_errors': [('Mobil', 136, 'Q156238')]}, {'doc_title': 'Dirty tanker fixture', 'fp_errors': [('MIDEAST', 68, 'Q7204')], 'fn_errors': [('Fos', 293, 'Q455657')]}, {'doc_title': 'NYC Jan refunding ha', 'fp_errors': [('Euro', 30, 'Q4916'), ('Goldman, Sachs', 299, 'Q193326')], 'fn_errors': []}, {'doc_title': 'USDA gross cutout hi', 'fp_errors': [('DES MOINES', 40, 'Q39709')], 'fn_errors': []}, {'doc_title': 'Wall St speculates a', 'fp_errors': [('Santa Fe', 25, 'Q753942'), ('Wall', 105, 'Q11690'), ('Santa Fe', 196, 'Q753942'), ('Newmont Mining Corp', 232, 'Q1785405'), ('Santa Fe', 253, 'Q753942')], 'fn_errors': [('Wall Street', 105, 'Q13677'), ('Wall Street', 368, 'Q13677'), ('United States', 1800, 'Q30'), ('Mexico', 2198, 'Q1489')]}, {'doc_title': 'Russ Berrie presiden', 'fp_errors': [('N.J', 50, 'Q1408')], 'fn_errors': [('N.J.', 50, 'Q1408')]}, {'doc_title': 'Zimbabwe executes co', 'fp_errors': [], 'fn_errors': [('Zimbabwe', 0, 'Q954')]}, {'doc_title': 'Multinational comman', 'fp_errors': [('Zaire', 43, 'Q6500954'), ('Zaire', 153, 'Q6500954'), ('Zaire', 195, 'Q6500954'), ('Zairean', 706, 'Q6500954'), ('Zaire', 749, 'Q6500954')], 'fn_errors': [('Zaire', 43, 'Q974'), ('Zaire', 153, 'Q974'), ('Zaire', 195, 'Q974'), ('Zairean', 706, 'Q974'), ('Zaire', 749, 'Q974')]}, {'doc_title': 'Mauritius put on cyc', 'fp_errors': [('Indian Ocean', 84, 'Q1239')], 'fn_errors': []}, {'doc_title': 'U.N. evacuates staff', 'fp_errors': [('The United Nations', 71, 'Q1065'), ('the Central African Republic', 113, 'Q929')], 'fn_errors': [('United Nations', 75, 'Q1065'), ('Central African Republic', 117, 'Q929')]}, {'doc_title': 'Senegal proposes for', 'fp_errors': [('The United States', 410, 'Q30'), ('Egyptian', 461, 'Q1061510'), ('the United Nations', 737, 'Q1065')], 'fn_errors': [('United States', 414, 'Q30'), ('Egyptian', 461, 'Q79'), ('United Nations', 741, 'Q1065')]}, {'doc_title': 'Ex-minister, son kil', 'fp_errors': [('Central Africa', 27, 'Q27433'), ('Red Cross', 843, 'Q7178'), ('Patasse', 1297, 'Q314524'), ('French-owned', 1787, 'Q142'), ('Patasse', 1875, 'Q314524')], 'fn_errors': [('Central Africa', 27, 'Q929'), ('Central Africa', 2589, 'Q929')]}, {'doc_title': 'Five die as SAfrican', 'fp_errors': [(\"South Africa's\", 183, 'Q258')], 'fn_errors': [('South Africa', 183, 'Q258')]}, {'doc_title': 'WEATHER - Conditions', 'fp_errors': [('CIS', 24, 'Q7779'), ('CIS', 95, 'Q7779'), ('Moscow', 188, 'Q649')], 'fn_errors': []}, {'doc_title': 'Skinheads attack Bra', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Albanian jailed for ', 'fp_errors': [('Albanian', 0, 'Q179248'), ('Gjonaj', 903, 'Q21140259')], 'fn_errors': [('Albanian', 0, 'Q222'), ('Albanian', 65, 'Q222')]}, {'doc_title': 'Polish ex-communist ', 'fp_errors': [('Pope', 39, 'Q19546'), ('Polish-born', 137, 'Q36'), ('Pope', 149, 'Q19546'), ('John Paul', 154, 'Q989'), ('Vatican', 215, 'Q159583')], 'fn_errors': [('Vatican', 215, 'Q237'), ('Vatican', 608, 'Q237'), ('Catholic Church', 914, 'Q9592'), ('Vatican', 1066, 'Q237')]}, {'doc_title': 'Russia warns Norilsk', 'fp_errors': [('Norilsk', 13, 'Q1284261'), ('Norilsk', 310, 'Q1284261'), ('Norilsk', 468, 'Q1284261'), ('Livshits', 486, 'Q1976707'), ('Livshits', 593, 'Q1976707')], 'fn_errors': [('Russian', 87, 'Q159'), ('Moscow', 1248, 'Q159'), ('Moscow', 1666, 'Q159'), ('Krasnoyarsk', 2647, 'Q6563')]}, {'doc_title': 'Estonian Tallinna Pa', 'fp_errors': [('Estonian', 0, 'Q9072'), ('TALLINN', 50, 'Q980219')], 'fn_errors': [('Estonian', 0, 'Q191'), ('TALLINN', 50, 'Q1770')]}, {'doc_title': 'Russia ready for con', 'fp_errors': [('State', 215, 'Q789915'), ('Moscow', 302, 'Q649'), ('Washington', 841, 'Q61'), ('the United Nations', 895, 'Q1065'), ('Soviet-led', 1103, 'Q170541')], 'fn_errors': [('Moscow', 302, 'Q159'), ('Washington', 841, 'Q30'), ('U.S.', 876, 'Q30'), ('United Nations', 899, 'Q1065')]}, {'doc_title': 'Yeltsin plans return', 'fp_errors': [('the Soviet Union', 759, 'Q15180')], 'fn_errors': [('Soviet Union', 763, 'Q15180')]}, {'doc_title': 'Bomb explodes outsid', 'fp_errors': [('TASR', 259, 'Q2437491'), ('Frantisek Gaulieder', 332, 'Q15303766'), ('Gaulieder', 451, 'Q15303766'), ('TASR', 917, 'Q2437491'), ('Gaulieder', 923, 'Q15303766')], 'fn_errors': []}, {'doc_title': 'Bomb explodes at mos', 'fp_errors': [('Moslems', 453, 'Q47740'), ('Ottoman', 491, 'Q12560'), ('Turkish', 499, 'Q43'), ('Christians', 542, 'Q106039')], 'fn_errors': [('Moslems', 453, 'Q432'), ('Turkish', 499, 'Q12560')]}, {'doc_title': 'Hungary o / n rates ', 'fp_errors': [('social security', 186, 'Q12002092'), (\"Budapest Bank's\", 319, 'Q27493463'), ('social security', 729, 'Q12002092')], 'fn_errors': [('BUDAPEST', 54, 'Q1781'), ('Budapest', 319, 'Q1781')]}, {'doc_title': 'Mexico stocks off lo', 'fp_errors': [('IPC', 486, 'Q291740'), ('Simec', 1097, 'Q60740496'), ('New York', 1334, 'Q1384'), ('Carlos Ponce', 1606, 'Q743870')], 'fn_errors': [('Dow', 230, 'Q180816'), ('ADRs', 1317, 'Q463881'), ('New York', 1334, 'Q60')]}, {'doc_title': 'Plastic surgery gets', 'fp_errors': [('Brazilians', 132, 'Q873625'), ('SBCP', 536, 'Q2789500'), (\"Latin America's\", 1089, 'Q12585'), ('SBCP', 1499, 'Q2789500'), ('liposuction', 1967, 'Q825490')], 'fn_errors': [('Brazilians', 132, 'Q155'), ('Latin America', 1089, 'Q12585'), ('Brazilians', 2245, 'Q155'), ('United States', 2402, 'Q30'), ('Brazilian', 2568, 'Q155')]}, {'doc_title': 'Daily Argentine grai', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Mexican daily port, ', 'fp_errors': [('Chris Aspin', 1319, 'Q82005180')], 'fn_errors': []}, {'doc_title': 'Brazil exam cheats c', 'fp_errors': [('Brazilian', 75, 'Q873625')], 'fn_errors': [('Brazilian', 75, 'Q155')]}, {'doc_title': 'Chile, Mexico to see', 'fp_errors': [('Chilean Congress', 930, 'Q1968468'), ('Congress', 976, 'Q1968468')], 'fn_errors': [('Finance', 191, 'Q4294804'), ('Chilean', 930, 'Q298')]}, {'doc_title': \"Indonesia's Belo lea\", 'fp_errors': [('Nobel', 28, 'Q7191'), ('Nobel', 441, 'Q7191'), ('Jakarta', 1212, 'Q3630'), ('The United Nations', 1455, 'Q1065'), ('Jakarta', 1495, 'Q3630')], 'fn_errors': [('Nobel', 28, 'Q35637'), ('Nobel', 441, 'Q35637'), ('United Nations', 1459, 'Q1065'), ('Nobel Peace Prize', 1556, 'Q35637'), ('Vatican', 1896, 'Q237')]}, {'doc_title': 'China to open port i', 'fp_errors': [('State Council', 74, 'Q59261')], 'fn_errors': []}, {'doc_title': 'Government disperses', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Burmese students mar', 'fp_errors': [('YIT', 472, 'Q2300228'), ('the University of Yangon', 592, 'Q1185947'), ('State Law and Order Restoration Council', 1785, 'Q1062377'), ('SLORC', 1826, 'Q1062377'), (\"Suu Kyi's\", 2131, 'Q36740')], 'fn_errors': [('RANGOON', 60, 'Q37995'), ('University of Yangon', 596, 'Q1185947'), ('Suu Kyi', 2131, 'Q36740'), ('Nobel', 2189, 'Q35637'), ('Yangon', 2605, 'Q37995')]}, {'doc_title': 'Union leaders outrag', 'fp_errors': [('Jordan', 559, 'Q8013775'), ('Hansenne', 727, 'Q2648073'), ('Jordan', 910, 'Q8013775'), ('Jordan', 1107, 'Q8013775'), ('Bill Brett', 1360, 'Q2578113')], 'fn_errors': []}, {'doc_title': 'Indian rubber demand', 'fp_errors': [], 'fn_errors': []}, {'doc_title': \"Japan's authorities \", 'fp_errors': [('Yasuo Matsushita', 376, 'Q5385313'), ('the United States', 1204, 'Q30'), ('Sumitomo', 1435, 'Q717318'), ('Yen', 2172, 'Q8146'), ('Matsushita', 2261, 'Q5385313')], 'fn_errors': [('Robert', 953, 'Q370316'), ('Rubin', 961, 'Q370316'), ('United States', 1208, 'Q30'), ('Sumitomo', 1435, 'Q4671036'), ('Japanese', 2964, 'Q17')]}, {'doc_title': 'Lebanon sentences pr', 'fp_errors': [('pro-Israeli', 18, 'Q42388'), ('Lahd', 381, 'Q586575'), ('Lahd', 590, 'Q586575'), ('Lahd', 874, 'Q586575'), ('Lahd', 1168, 'Q586575')], 'fn_errors': [('BEIRUT', 65, 'Q3820'), ('Moslem', 1517, 'Q432'), ('Christian', 2419, 'Q9592'), ('Saqr', 2448, 'Q2700625')]}, {'doc_title': 'Texas / w Okla fed c', 'fp_errors': [('Panhandle', 96, 'Q2297417')], 'fn_errors': [('Panhandle', 96, 'Q1414375')]}, {'doc_title': 'USDA daily cattle an', 'fp_errors': [('NASS', 600, 'Q861855')], 'fn_errors': []}, {'doc_title': 'BALANCE - Hartford, ', 'fp_errors': [('BALANCE', 0, 'Q1365641'), ('Conn', 20, 'Q779'), ('CITY OF HARTFORD', 37, 'Q33486'), ('CONNECTICUT', 55, 'Q779'), ('FSA', 172, 'Q5440431')], 'fn_errors': [('HARTFORD', 45, 'Q33486'), ('S&P', 129, 'Q106158'), ('FSA', 172, 'Q638053')]}, {'doc_title': '14 years later, Flor', 'fp_errors': [('Florida', 16, 'Q812'), ('Fla', 59, 'Q812'), ('Florida', 203, 'Q812'), ('Florida', 261, 'Q812'), ('Eugene Morris', 595, 'Q4872402')], 'fn_errors': [('God', 677, 'Q190'), ('Allah', 685, 'Q234801'), ('God', 756, 'Q190'), ('U.S. Supreme Court', 1112, 'Q11201'), ('Florida Supreme Court', 1493, 'Q3001105')]}, {'doc_title': 'New York grain freig', 'fp_errors': [('NEW YORK', 41, 'Q1384')], 'fn_errors': [('New York', 0, 'Q60'), ('NEW YORK', 41, 'Q60')]}, {'doc_title': 'Iowa-S Minn fed catt', 'fp_errors': [('USDA', 46, 'Q501542')], 'fn_errors': [('Minn', 7, 'Q1527'), ('DES MOINES', 52, 'Q39709'), ('Chicago', 757, 'Q1297')]}, {'doc_title': 'Man stole pigs, tipp', 'fp_errors': [('Wis', 59, 'Q1537'), ('Luebke', 445, 'Q7152086')], 'fn_errors': []}, {'doc_title': 'Canadian grain stati', 'fp_errors': [], 'fn_errors': [('CHICAGO', 34, 'Q1297')]}, {'doc_title': 'NYMEX natgas ends sh', 'fp_errors': [(\"the National Weather Service's\", 202, 'Q1066823'), ('the National Weather Service', 497, 'Q1066823'), ('U.S', 592, 'Q30'), ('Gulf Coast', 1033, 'Q55241'), ('Midcontinent', 1107, 'Q6840693')], 'fn_errors': [('NEW YORK', 52, 'Q60'), ('National Weather Service', 206, 'Q1066823'), ('British', 333, 'Q145'), ('National Weather Service', 501, 'Q1066823'), ('U.S.', 592, 'Q30')]}, {'doc_title': 'U.S. barges lightly ', 'fp_errors': [('St. Louis Merchants Exchange', 116, 'Q6818436')], 'fn_errors': [('St. Louis', 116, 'Q38022')]}, {'doc_title': 'CBOT grain / oilseed', 'fp_errors': [('the Chicago Board of Trade', 183, 'Q1071867'), ('Wheat', 231, 'Q15645384'), ('Corn', 284, 'Q11575'), ('Oats', 354, 'Q12104'), ('Chicago', 480, 'Q2963283')], 'fn_errors': [('Chicago Board of Trade', 187, 'Q1071867')]}, {'doc_title': 'Clinton to have more', 'fp_errors': [('the White House', 172, 'Q35525')], 'fn_errors': [('White House', 176, 'Q35525')]}, {'doc_title': 'Action Performance t', 'fp_errors': [('Ariz', 44, 'Q816')], 'fn_errors': []}, {'doc_title': 'Half of dog bites pr', 'fp_errors': [('the United States', 113, 'Q30'), ('Humane Society of the United States', 240, 'Q1636612'), ('Columbus, Ohio', 536, 'Q16567'), ('chow chows', 1279, 'Q29013'), ('Rottweilers', 1291, 'Q39093')], 'fn_errors': [('United States', 117, 'Q30'), ('United States', 262, 'Q30'), ('Columbus', 536, 'Q16567'), ('Ohio', 546, 'Q1397')]}, {'doc_title': 'Iowa-S Minn feedlot ', 'fp_errors': [], 'fn_errors': [('Minn', 7, 'Q1527'), ('DES MOINES', 52, 'Q39709'), ('Chicago', 206, 'Q1297')]}, {'doc_title': 'Nebraska fed cattle ', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Four Africans said t', 'fp_errors': [('U.N. General Assembly', 527, 'Q47423'), ('the Ivory Coast', 716, 'Q1008'), ('U.N. General Assembly', 995, 'Q47423'), ('The United States', 1392, 'Q30'), ('The Security Council', 1722, 'Q37470')], 'fn_errors': [('Ivory Coast', 720, 'Q1008'), ('United States', 1396, 'Q30'), ('Security Council', 1726, 'Q37470')]}, {'doc_title': \"Spain's police seize\", 'fp_errors': [('Basque', 206, 'Q3995'), ('Herri Batasuna', 362, 'Q2748435'), ('Basque', 400, 'Q8752'), ('ETA', 424, 'Q42814')], 'fn_errors': [('Basque', 206, 'Q47588'), ('Herri Batasuna', 362, 'Q209546'), ('Basque', 400, 'Q47588')]}, {'doc_title': \"Mussolini's granddau\", 'fp_errors': [('Fascist', 118, 'Q6223'), ('AN', 218, 'Q662849'), ('AN', 327, 'Q662849'), ('Mussolini', 524, 'Q23559'), ('Giuseppe Tatarella', 564, 'Q2847139')], 'fn_errors': [('Mussolini', 524, 'Q285543'), ('Mussolini', 674, 'Q285543'), ('Mussolini', 913, 'Q285543')]}, {'doc_title': 'German Santa in bank', 'fp_errors': [], 'fn_errors': [('German', 0, 'Q183'), ('Santa', 7, 'Q315796')]}, {'doc_title': 'Italy commission con', 'fp_errors': [('Senate', 92, 'Q633872'), ('Senate', 266, 'Q633872')], 'fn_errors': []}, {'doc_title': 'EU, Poland agree on ', 'fp_errors': [('EU', 0, 'Q458'), ('EU', 199, 'Q458'), ('Europe Agreement', 378, 'Q4426710'), ('EU', 407, 'Q458'), ('EU', 535, 'Q458')], 'fn_errors': [('Europe', 378, 'Q46')]}, {'doc_title': 'Hindu party forces I', 'fp_errors': [('Hindu', 0, 'Q10090'), ('Hindu', 69, 'Q10090'), ('Hindu', 253, 'Q10090'), ('Hindu', 287, 'Q10090'), ('communist', 381, 'Q6186')], 'fn_errors': [('Hindu', 0, 'Q1307223'), ('Hindu', 69, 'Q1307223'), ('Hindu', 287, 'Q1307223'), ('Moslem', 863, 'Q432'), ('Hindu', 1002, 'Q1307223')]}, {'doc_title': 'Indian Sept crude oi', 'fp_errors': [], 'fn_errors': [('Indian', 0, 'Q668')]}, {'doc_title': 'LUXEMBOURG CHRISTMAS', 'fp_errors': [('Brussels', 374, 'Q240')], 'fn_errors': [('LUXEMBOURG', 0, 'Q32')]}, {'doc_title': 'London coal / ore fi', 'fp_errors': [('COAL', 46, 'Q24489'), ('ORE', 323, 'Q102798')], 'fn_errors': [('Fos', 253, 'Q455657')]}, {'doc_title': 'UK bookmakers length', 'fp_errors': [('UK', 0, 'Q145'), ('UK', 68, 'Q145'), ('London News', 377, 'Q4834834')], 'fn_errors': []}, {'doc_title': 'Italy tops week of m', 'fp_errors': [('Salomon', 41, 'Q2034767'), ('Salomon', 1515, 'Q2034767')], 'fn_errors': [('Salomon Brothers', 1072, 'Q2034767')]}, {'doc_title': 'OPEC basket price $ ', 'fp_errors': [('Bonny Light', 305, 'Q4035310'), ('Tia Juana', 378, 'Q124739'), ('Isthmus', 401, 'Q93267'), ('London News', 412, 'Q4834834')], 'fn_errors': [('Isthmus', 401, 'Q392250')]}, {'doc_title': 'Relations between Cl', 'fp_errors': [('Chancellor of', 86, 'Q61061'), ('quer', 109, 'Q1766541')], 'fn_errors': [('Clarke', 18, 'Q271889'), ('European', 205, 'Q458')]}, {'doc_title': 'Two dead after execu', 'fp_errors': [('Newfoundland', 40, 'Q2003'), ('STEPHENVILLE', 54, 'Q626279'), ('Newfoundland', 68, 'Q2003'), ('Ireland', 149, 'Q22890'), ('Stephenville', 208, 'Q626279')], 'fn_errors': [('Newfoundland', 40, 'Q48335'), ('Newfoundland', 68, 'Q48335'), ('Ireland', 149, 'Q27'), ('Stephenville', 208, 'Q3506282'), ('Newfoundland', 222, 'Q48335')]}, {'doc_title': 'PLO says Arafat, Net', 'fp_errors': [('PLO', 0, 'Q26683'), ('PLO', 69, 'Q26683'), ('Palestinian', 100, 'Q201190'), ('PLO', 305, 'Q26683'), ('PLO', 465, 'Q26683')], 'fn_errors': [('JERUSALEM', 48, 'Q1218'), ('Israelis', 1223, 'Q801'), ('Moslem', 1307, 'Q432'), ('Israeli', 1675, 'Q801')]}, {'doc_title': 'Turkey hindered by o', 'fp_errors': [('Turkey', 0, 'Q43'), ('Syrian', 36, 'Q878607'), ('Turkey', 69, 'Q43'), ('Kurdish', 97, 'Q12223'), ('Turkey', 998, 'Q43')], 'fn_errors': [('Syrian', 36, 'Q858'), ('Kurdish', 97, 'Q41470'), ('Kurdish', 1047, 'Q41470'), ('Damascus', 1086, 'Q858')]}, {'doc_title': 'Three dead in Kurd m', 'fp_errors': [('Kurd', 14, 'Q12223'), ('Turkey', 41, 'Q43'), ('DIYARBAKIR', 49, 'Q83387'), ('Turkey', 61, 'Q43'), ('Turkish', 216, 'Q43')], 'fn_errors': [('Kurd', 14, 'Q41470'), ('Kurdish', 399, 'Q41470'), ('Kurdish', 549, 'Q41470'), ('Kurdish', 987, 'Q41470')]}, {'doc_title': 'Texas / w Okla fed c', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Kansas feedlot cattl', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Delphis Hanover week', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'ACCESS energy future', 'fp_errors': [('NYMEX', 132, 'Q120233'), ('Northeastern', 219, 'Q24460')], 'fn_errors': [('U.S.', 74, 'Q30')]}, {'doc_title': 'U.S. blasts release ', 'fp_errors': [('Palestinian', 135, 'Q201190'), ('Korydallos', 1031, 'Q659042'), ('Palestine Liberation Organisation', 1207, 'Q26683'), ('The United States', 1680, 'Q30'), ('Palestinian', 1812, 'Q201190')], 'fn_errors': [('U.S.', 0, 'Q30'), ('Palestinian', 135, 'Q219060'), ('United States', 1684, 'Q30'), ('Palestinian', 1740, 'Q219060'), ('Palestinian', 1812, 'Q219060')]}, {'doc_title': 'School football play', 'fp_errors': [('N.M', 67, 'Q1522'), ('St Pius X High School', 303, 'Q7591559'), ('the New Mexico Activities Association', 536, 'Q7010145'), ('Cito', 589, 'Q745619'), ('Cito', 689, 'Q745619')], 'fn_errors': [('N.M.', 67, 'Q1522'), ('New Mexico Activities Association', 540, 'Q7010145')]}, {'doc_title': 'Cyberspace squabbles', 'fp_errors': [('Western', 889, 'Q160381'), ('James Love', 1426, 'Q6138244'), ('Washington-based', 1470, 'Q1223'), ('Consumer Project on Technology', 1487, 'Q3198053'), ('Berne Convention', 1922, 'Q217398')], 'fn_errors': [('Internet', 144, 'Q466'), ('Internet', 1085, 'Q466'), ('Internet', 2213, 'Q466'), ('Internet', 2427, 'Q466'), ('Moscow', 2533, 'Q159')]}, {'doc_title': 'Italy evacuates 17 n', 'fp_errors': [('Zaire', 41, 'Q6500954'), ('Zaire', 142, 'Q6500954'), ('The Foreign Ministry', 241, 'Q789842'), ('Europeans', 274, 'Q1464982'), ('Africans', 294, 'Q3037005')], 'fn_errors': [('Zaire', 41, 'Q974'), ('Zaire', 142, 'Q974'), ('Europeans', 274, 'Q46'), ('Africans', 294, 'Q15'), ('Garamba', 334, 'Q308893')]}, {'doc_title': 'Third Paris blast vi', 'fp_errors': [('Canadian', 344, 'Q1196645'), ('Moslem', 678, 'Q47740')], 'fn_errors': [('Canadian', 344, 'Q16'), ('Moslem', 678, 'Q432')]}, {'doc_title': 'Italian President ur', 'fp_errors': [('MANTUA', 50, 'Q6247'), ('Mantua', 310, 'Q6247'), ('Mantua', 805, 'Q6247'), ('Italians', 918, 'Q50001'), ('Italians', 1144, 'Q50001')], 'fn_errors': [('Mantua', 805, 'Q16204'), ('Italians', 918, 'Q38'), ('Italians', 1144, 'Q38'), ('Italia', 1233, 'Q38')]}, {'doc_title': \"Denmark's Radiometer\", 'fp_errors': [('Radiometer', 10, 'Q2126439'), ('Reuter', 66, 'Q130879'), ('Radiometer', 119, 'Q2126439')], 'fn_errors': [('Wednesday', 218, 'Q128')]}, {'doc_title': 'Moslem fundamentalis', 'fp_errors': [('Moslem', 0, 'Q2855987'), ('Algerians', 31, 'Q2087341'), ('Moslem', 68, 'Q47740'), ('Blida', 124, 'Q216990'), ('APS', 258, 'Q1162323')], 'fn_errors': [('Moslem', 0, 'Q432'), ('Algerians', 31, 'Q262'), ('Moslem', 68, 'Q432'), ('Blida', 124, 'Q233637')]}, {'doc_title': 'Belgian police smash', 'fp_errors': [('Turkish', 594, 'Q43'), ('Turkish', 722, 'Q43'), ('Turkey', 755, 'Q43'), ('European', 923, 'Q46')], 'fn_errors': [('Belgian', 337, 'Q31'), ('European', 923, 'Q458'), ('Belgian', 997, 'Q31')]}, {'doc_title': 'Port conditions upda', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'German Jan-August co', 'fp_errors': [('EU', 111, 'Q458'), ('DKV', 214, 'Q1204993')], 'fn_errors': []}, {'doc_title': 'Munich Re says to sp', 'fp_errors': [(\"Munich Re's\", 470, 'Q166637'), (\"Munich Re's\", 582, 'Q166637'), ('Frankfurt', 687, 'Q1794')], 'fn_errors': [('Munich Re', 470, 'Q166637'), ('Munich Re', 582, 'Q166637')]}, {'doc_title': 'EU experts postpone ', 'fp_errors': [('EU', 0, 'Q458'), ('EU', 216, 'Q458'), ('EU', 233, 'Q458'), ('European', 454, 'Q46'), ('Brussels', 608, 'Q240')], 'fn_errors': [('European', 454, 'Q458')]}, {'doc_title': 'Frankfurt dollar fix', 'fp_errors': [('Frankfurt', 0, 'Q155718'), ('Frankfurt', 96, 'Q1794')], 'fn_errors': [('Frankfurt', 0, 'Q151139'), ('Frankfurt', 96, 'Q151139')]}, {'doc_title': 'John Lewis UK store ', 'fp_errors': [('The John Lewis Partnership', 62, 'Q6244782'), ('UK', 98, 'Q145'), ('London', 437, 'Q84')], 'fn_errors': [('John Lewis', 66, 'Q6244782')]}, {'doc_title': 'Timah at 15.625 in L', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'British \"Euro-scepti', 'fp_errors': [('Parliament', 288, 'Q11010'), ('Conservatives', 396, 'Q9626'), ('Cabinet', 511, 'Q112014'), ('Parliament', 940, 'Q11010'), ('pro-European', 1276, 'Q3781399')], 'fn_errors': [('British', 0, 'Q145'), ('Euro-sceptic', 9, 'Q223200'), ('Clarke', 28, 'Q271889'), ('Euro-sceptic', 71, 'Q223200'), ('European', 259, 'Q458')]}, {'doc_title': 'Court ejects head of', 'fp_errors': [('Australian', 21, 'Q1318423'), ('Australian', 75, 'Q1318423'), ('Chris Hunt', 307, 'Q5106947'), ('the Foreign Affairs Department', 885, 'Q5260317'), (\"Pamela O'Neil\", 1195, 'Q7128964')], 'fn_errors': [('Australian', 21, 'Q408'), ('Australian', 75, 'Q408'), ('Australian', 1305, 'Q408'), ('Cambodian', 1377, 'Q424'), ('Australian', 1522, 'Q408')]}, {'doc_title': 'Australian hitman ki', 'fp_errors': [('Australian', 0, 'Q1318423'), ('Australian', 60, 'Q1318423')], 'fn_errors': [('Australian', 0, 'Q408'), ('Australian', 60, 'Q408')]}, {'doc_title': \"NZ's Bolger says Nat\", 'fp_errors': [('NZ', 0, 'Q843881'), ('Nats', 17, 'Q142530'), ('NZ First', 30, 'Q180059')], 'fn_errors': []}, {'doc_title': \"NZ's Peters says Nat\", 'fp_errors': [('NZ', 0, 'Q664')], 'fn_errors': [('Peters', 5, 'Q1396178')]}, {'doc_title': 'RTRS - Australian MP', 'fp_errors': [('Australian', 7, 'Q1318423'), ('Australian', 73, 'Q1318423'), ('House of Representatives', 177, 'Q783401'), ('House of Representatives', 363, 'Q783401'), ('Fraser', 418, 'Q2973584')], 'fn_errors': [('RTRS', 0, 'Q2280893'), ('Australian', 7, 'Q408'), ('Australian', 73, 'Q408'), ('Fraser', 418, 'Q1003684'), ('Fraser', 1028, 'Q1003684')]}, {'doc_title': 'Burmese students mar', 'fp_errors': [('YIT', 152, 'Q2300228'), ('YIT', 436, 'Q2300228'), ('State Law and Order Restoration Council', 897, 'Q1062377'), ('SLORC', 940, 'Q1062377')], 'fn_errors': []}, {'doc_title': 'Thai rice vessels lo', 'fp_errors': [('Iran', 202, 'Q794')], 'fn_errors': [('Thai', 74, 'Q869'), ('Iran', 227, 'Q794')]}, {'doc_title': 'Chinese girl nearly ', 'fp_errors': [('Chinese', 0, 'Q6501380')], 'fn_errors': [('Chinese', 0, 'Q148')]}, {'doc_title': 'South Korean won clo', 'fp_errors': [('U.S.', 94, 'Q4917')], 'fn_errors': [('South Korean', 0, 'Q884'), ('SEOUL', 52, 'Q8684'), ('U.S.', 94, 'Q30')]}, {'doc_title': 'Foreign planes to la', 'fp_errors': [('ING', 54, 'Q645708'), (\"the State Council's\", 247, 'Q59261'), ('Port Office', 267, 'Q19817784'), ('the Civil Aviation Administration of China', 280, 'Q1329619'), ('the General Administration of Customs', 324, 'Q5531667')], 'fn_errors': [('BEIJING', 50, 'Q956'), ('State Council', 251, 'Q59261'), ('Civil Aviation Administration of China', 284, 'Q1329619'), ('General Administration of Customs', 328, 'Q5531667')]}, {'doc_title': 'EPA says economic as', 'fp_errors': [('EPA', 0, 'Q460173'), ('Economic Planning Agency', 77, 'Q1197264'), ('EPA', 245, 'Q460173')], 'fn_errors': []}, {'doc_title': 'Sangetsu - 96/97 par', 'fp_errors': [], 'fn_errors': []}, {'doc_title': 'Bre-X, Barrick said ', 'fp_errors': [('Busang', 32, 'Q5001279'), ('Bre-X Minerals Ltd', 85, 'Q1250245'), ('Barrick Gold Corp', 108, 'Q808908'), ('Busang', 220, 'Q5001279'), ('Mines and Energy Ministry', 667, 'Q2602051')], 'fn_errors': []}, {'doc_title': 'Honda RV exceeds sal', 'fp_errors': [('Honda Motor Co Ltd', 48, 'Q9584'), ('S-MX', 134, 'Q1626663'), ('S-MX', 220, 'Q1626663')], 'fn_errors': []}, {'doc_title': 'FEATURE - Singapore ', 'fp_errors': [('ISEAS', 1213, 'Q6040872'), ('Uruguay Round', 1769, 'Q1136965'), ('General Agreement on Tariffs and Trade', 1832, 'Q194284'), ('GATT', 1872, 'Q194284'), ('the European Union', 1946, 'Q458')], 'fn_errors': [('SINGAPORE', 66, 'Q334'), ('Institute of Policy Studies', 1184, 'Q6040758'), ('Uruguay', 1769, 'Q77'), ('European Union', 1950, 'Q458')]}, {'doc_title': 'Japan NTT says hopes', 'fp_errors': [('NTT', 6, 'Q1054787'), ('Nippon Telegraph and Telephone Corp', 68, 'Q1054787'), ('NTT', 105, 'Q1054787'), ('NTT', 263, 'Q1054787'), ('NTT', 536, 'Q1054787')], 'fn_errors': []}, {'doc_title': 'Ahold launches Asian', 'fp_errors': [('Asian', 15, 'Q2035701'), ('BILO', 205, 'Q4835622'), ('BILO', 248, 'Q4835622'), ('BILO', 384, 'Q4835622'), ('BILO', 576, 'Q4835622')], 'fn_errors': [('Asian', 15, 'Q48'), ('US$', 861, 'Q4917')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors': [('WORLD CUP', 22, 'Q982'), ('Svetlana Gladishiva', 158, 'Q267942'), ('Gladishiva', 253, 'Q267942'), ('Lillehammer Winter Olympics', 306, 'Q9663'), ('World Championships', 377, 'Q943691')], 'fn_errors': [('Lillehammer', 306, 'Q101341'), ('Winter Olympics', 318, 'Q257484'), ('World Championships', 377, 'Q1344963')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors': [('Svetlana Gladishiva', 147, 'Q267942'), ('Warwara Zelenskaja', 342, 'Q462628'), ('Stefanie Schuster', 544, 'Q450093'), ('Bibiana Perez', 584, 'Q451766'), ('Barbara Merlin', 618, 'Q454190')], 'fn_errors': [('U.S.', 939, 'Q30'), ('U.S.', 1045, 'Q30'), ('U.S.', 1077, 'Q30')]}, {'doc_title': 'ALPINE SKIING-GLADIS', 'fp_errors': [('Svetlana Gladishiva', 75, 'Q267942')], 'fn_errors': []}, {'doc_title': 'GOLF - THIRD ROUND O', 'fp_errors': [('Florida', 67, 'Q812'), ('PGA', 377, 'Q1363321'), ('U.S. Amateur', 624, 'Q2388111')], 'fn_errors': [('PGA', 377, 'Q910409'), ('LPGA', 385, 'Q281917'), ('U.S.', 624, 'Q30')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors': [('World Cup', 117, 'Q982'), ('World Cup', 329, 'Q982'), ('Europa Cup', 354, 'Q627360'), ('Goetschl', 386, 'Q78573')], 'fn_errors': []}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors': [('WORLD CUP', 22, 'Q982'), ('Megan Gerety', 461, 'Q6808660'), ('U.S', 475, 'Q30'), ('Warwara Zelenskaja', 488, 'Q462628'), ('Florence Masnada', 523, 'Q450072')], 'fn_errors': [('U.S.', 475, 'Q30'), ('Florence', 523, 'Q450072'), ('Masnada', 532, 'Q450072'), ('U.S.', 571, 'Q30'), ('Florence', 1266, 'Q450072')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors': [('WORLD CUP', 22, 'Q982'), ('World Cup', 120, 'Q982'), ('Megan Gerety', 317, 'Q6808660'), ('U.S', 331, 'Q30'), ('Stefanie Schuster', 381, 'Q450093')], 'fn_errors': [('U.S.', 331, 'Q30')]}, {'doc_title': 'NORDIC SKIING-WORLD ', 'fp_errors': [], 'fn_errors': [('World Cup', 94, 'Q855631'), ('World Cup', 365, 'Q855631'), ('World Cup', 695, 'Q855631')]}, {'doc_title': 'ALPINE SKIING-GOETCH', 'fp_errors': [('WORLD CUP', 27, 'Q982')], 'fn_errors': []}, {'doc_title': 'BOBSLEIGH-SHIMER PIL', 'fp_errors': [('IGLS', 49, 'Q1735'), ('Olympic', 292, 'Q5389'), ('Canada', 509, 'Q16'), ('La Plagne', 762, 'Q3389261'), ('USA', 864, 'Q30')], 'fn_errors': [('Olympic', 292, 'Q9651'), ('La Plagne', 762, 'Q969723')]}, {'doc_title': 'SKIING-CHINESE MAKE ', 'fp_errors': [('Alexis Blanc', 453, 'Q9147326'), ('Blanc', 565, 'Q9147326'), ('Foucras', 678, 'Q3510084')], 'fn_errors': [('World Cup', 600, 'Q1453654'), ('World Cup', 699, 'Q1453654'), ('World Cup', 831, 'Q1453654')]}, {'doc_title': 'BOBSLEIGH-WORLD CUP ', 'fp_errors': [('IGLS', 37, 'Q1735'), ('United States', 126, 'Q30'), ('Italy', 216, 'Q38'), ('Canada', 287, 'Q16'), ('German', 357, 'Q183')], 'fn_errors': []}, {'doc_title': 'CRICKET - WOOLMER MA', 'fp_errors': [('WOOLMER', 10, 'Q5126834')], 'fn_errors': [('WOOLMER', 10, 'Q281268'), ('United Province', 731, 'Q1498')]}, {'doc_title': 'FREESTYLE SKIING-WOR', 'fp_errors': [('Alexis Blanc', 155, 'Q9147326'), ('Christian Rijavec', 290, 'Q89008'), ('Andy Capicik', 407, 'Q4756535'), ('Trace Worthington', 439, 'Q9360646'), ('U.S', 458, 'Q30')], 'fn_errors': [('World Cup', 85, 'Q1453654'), ('U.S.', 458, 'Q30')]}, {'doc_title': 'SKI JUMPING-LEADING ', 'fp_errors': [('WORLD CUP', 20, 'Q74804'), ('Saitoh', 823, 'Q3273175')], 'fn_errors': []}, {'doc_title': 'BADMINTON - WORLD GR', 'fp_errors': [('BADMINTON', 0, 'Q7291'), ('Indra Wijaya', 189, 'Q1661820')], 'fn_errors': [('WORLD GRAND PRIX', 12, 'Q1507281'), ('World Grand Prix', 110, 'Q1507281')]}, {'doc_title': 'SPEED SKATING-RESULT', 'fp_errors': [('CHONJU', 56, 'Q42140'), ('Jaegal Sung-Yeol', 241, 'Q497685'), ('Grunde Njos', 283, 'Q2163288'), ('US', 445, 'Q30'), ('Jin Hua', 817, 'Q14863975')], 'fn_errors': [('World Cup', 119, 'Q143692'), ('U.S.', 1551, 'Q30'), ('U.S.', 1685, 'Q30')]}, {'doc_title': 'ALPINE SKIING-OFFICI', 'fp_errors': [('WORLD CUP', 40, 'Q982'), ('Canadian', 750, 'Q1196645')], 'fn_errors': [('WHISTLER', 59, 'Q203122')]}, {'doc_title': 'SOCCER - LEADING SCO', 'fp_errors': [('Scottish', 98, 'Q22')], 'fn_errors': [('SCOTTISH PREMIER DIVISION', 17, 'Q187304')]}, {'doc_title': 'SOCCER - LEADING ENG', 'fp_errors': [('ENGLISH', 17, 'Q1478144')], 'fn_errors': [('ENGLISH', 17, 'Q21')]}, {'doc_title': 'SOCCER - NORTHERN IR', 'fp_errors': [('Coleraine', 229, 'Q5012743'), ('Coleraine', 326, 'Q5012743')], 'fn_errors': [('NORTHERN IRELAND', 9, 'Q26'), ('Crusaders', 156, 'Q840567'), ('Coleraine', 229, 'Q1108181'), ('Coleraine', 326, 'Q1108181'), ('Crusaders', 381, 'Q840567')]}, {'doc_title': 'RUGBY UNION - BRITIS', 'fp_errors': [('Llanelli', 316, 'Q538747'), ('Newport', 341, 'Q1521264')], 'fn_errors': [('RUGBY UNION', 0, 'Q5849'), ('British', 60, 'Q145'), ('Llanelli', 316, 'Q1517603'), ('Newport', 341, 'Q82216')]}, {'doc_title': 'SOCCER - SCOTTISH PR', 'fp_errors': [('SOCCER', 0, 'Q2736'), ('Millar', 148, 'Q2462519'), ('Windass', 205, 'Q1181147'), ('Olafsson', 306, 'Q445884'), ('Davies', 349, 'Q6846500')], 'fn_errors': [('SCOTTISH', 9, 'Q22'), ('Miller', 183, 'Q6211375'), ('Davies', 349, 'Q863076'), ('Hay', 379, 'Q5106833'), ('Ferguson', 411, 'Q3147261')]}, {'doc_title': 'RUGBY UNION - RETIRI', 'fp_errors': [('England', 125, 'Q21'), ('New South Wales', 681, 'Q534417'), ('Super 12', 704, 'Q855988'), ('England', 803, 'Q378628'), ('England', 848, 'Q21')], 'fn_errors': [('RUGBY UNION', 0, 'Q5849'), ('England', 125, 'Q145'), ('New South Wales', 681, 'Q3590280'), ('England', 803, 'Q145'), ('England', 848, 'Q145')]}, {'doc_title': 'SOCCER - ENGLISH PRE', 'fp_errors': [('CCER', 2, 'Q4222422'), ('Sturridge', 161, 'Q7519843'), ('Coventry', 303, 'Q6225'), ('Leicester', 378, 'Q1071691'), ('Whittingham', 476, 'Q631125')], 'fn_errors': [('ENGLISH', 9, 'Q21'), ('Adams', 131, 'Q299391'), ('Vieira', 141, 'Q46347'), ('Sturridge', 161, 'Q1181137'), ('Powell', 175, 'Q713078')]}, {'doc_title': 'SOCCER - SCOTTISH LE', 'fp_errors': [('ER', 4, 'Q207375'), ('SCOTTISH LEAGUE', 9, 'Q2261276'), ('Airdrieonians', 544, 'Q1345161'), ('Albion', 1224, 'Q568435'), (\"Queen's Park\", 1274, 'Q852753')], 'fn_errors': [('SCOTTISH', 9, 'Q22'), ('GLASGOW', 36, 'Q4093'), ('Scottish', 55, 'Q22'), ('Airdrieonians', 544, 'Q408554'), ('Albion', 1224, 'Q18744')]}, {'doc_title': 'SOCCER - ENGLISH LEA', 'fp_errors': [('SOCCER', 0, 'Q2736'), ('ENGLISH LEAGUE', 9, 'Q213347'), ('Division One', 783, 'Q754839'), ('Barnsley', 858, 'Q19442'), ('Crewe', 1752, 'Q648810')], 'fn_errors': [('ENGLISH', 9, 'Q21'), ('Premier league', 188, 'Q9448'), ('Barnsley', 858, 'Q19458'), ('Crewe', 1752, 'Q19587'), ('Shrewsbury', 1841, 'Q19626')]}, {'doc_title': 'SOCCER - VIEIRA SAVE', 'fp_errors': [], 'fn_errors': [('VIEIRA', 9, 'Q46347'), ('ARSENAL', 22, 'Q9617')]}, {'doc_title': 'SOCCER - SCOTTISH LE', 'fp_errors': [('CUP', 29, 'Q308822'), ('Dundee', 270, 'Q335483'), ('Airdrieonians', 334, 'Q1345161'), (\"Queen's Park\", 583, 'Q852753'), ('Hawick', 629, 'Q407183')], 'fn_errors': [('SCOTTISH', 9, 'Q22'), ('Dundee', 270, 'Q192873'), ('Airdrieonians', 334, 'Q408554'), ('Hawick', 629, 'Q930661'), ('Albion', 675, 'Q18744')]}, {'doc_title': 'SOCCER - ENGLISH LEA', 'fp_errors': [('SOCCER', 0, 'Q2736'), ('Grimsby', 374, 'Q5609311'), ('Enfield', 858, 'Q19654407')], 'fn_errors': [('ENGLISH', 9, 'Q21'), ('English', 70, 'Q145'), ('Premier league', 115, 'Q9448'), ('Grimsby', 374, 'Q18515'), ('Bolton', 648, 'Q19451')]}, {'doc_title': 'RUGBY UNION - CAMPES', 'fp_errors': [('GB', 2, 'Q79738')], 'fn_errors': [('RUGBY UNION', 0, 'Q5849')]}, {'doc_title': 'RUGBY UNION - AUSTRA', 'fp_errors': [('BARBARIANS', 29, 'Q807749'), ('Alan Bateman', 327, 'Q5662239')], 'fn_errors': [('BARBARIANS', 29, 'Q7015235')]}, {'doc_title': 'GOLF - ZIMBABWE OPEN', 'fp_errors': [('Greg Reid', 422, 'Q5606179'), ('Schalk van der Merwe', 501, 'Q7430937'), ('U.S', 579, 'Q30'), ('Sean Farrell', 598, 'Q16186225'), ('Nic Henning', 665, 'Q16338077')], 'fn_errors': [('U.S.', 579, 'Q30')]}, {'doc_title': 'SOCCER - REINSTATED ', 'fp_errors': [('TIRANA', 59, 'Q210170'), ('Albanian', 77, 'Q179248'), ('Astrit Hafizi', 92, 'Q13037205'), ('Albania', 341, 'Q186262'), ('Albania', 464, 'Q186262')], 'fn_errors': [('TIRANA', 59, 'Q19689'), ('Albanian', 77, 'Q186262'), ('Albania', 341, 'Q222'), ('Albania', 464, 'Q222')]}, {'doc_title': 'CRICKET - JONES HITS', 'fp_errors': [('JONES', 10, 'Q7519069'), ('Australia', 61, 'Q142555'), ('Australia', 89, 'Q142555'), ('Jones', 416, 'Q5246258'), ('Jones', 552, 'Q5246258')], 'fn_errors': [('Australia', 61, 'Q408'), ('Australia', 89, 'Q408')]}, {'doc_title': 'CRICKET - SHEFFIELD ', 'fp_errors': [('Australia', 42, 'Q142555')], 'fn_errors': [('Australia', 42, 'Q408')]}, {'doc_title': 'SOCCER - SOUTH KOREA', 'fp_errors': [('SOUTH KOREA', 9, 'Q543842'), ('South Korea', 77, 'Q884'), ('South Korea', 253, 'Q884'), ('South Korea', 418, 'Q884'), ('Koreans', 654, 'Q484464')], 'fn_errors': [('SOUTH KOREA', 9, 'Q884'), ('South Korea', 77, 'Q543842'), ('South Korea', 253, 'Q543842'), ('South Korea', 418, 'Q543842'), ('Koreans', 654, 'Q884')]}, {'doc_title': 'SOCCER - ISRAELI FIR', 'fp_errors': [('ISRAELI', 9, 'Q875556'), ('Ironi Rishon Lezion', 317, 'Q1584246'), (\"Hapoel Beit She'an\", 358, 'Q2057411'), ('Ironi Rishon Lezion', 858, 'Q1584246'), (\"Hapoel Beit She'an\", 993, 'Q2057411')], 'fn_errors': [('ISRAELI', 9, 'Q801'), ('JERUSALEM', 53, 'Q1218')]}, {'doc_title': 'SOCCER - ASIAN CUP R', 'fp_errors': [('Hassan Ahmed', 163, 'Q5678094'), ('South Korea', 269, 'Q884'), ('Ronny Wabia', 394, 'Q7366064')], 'fn_errors': [('South Korea', 269, 'Q543842')]}, {'doc_title': 'NBA BASKETBALL - STA', 'fp_errors': [('NEW JERSEY', 356, 'Q1408'), ('BOSTON', 382, 'Q100'), ('MILWAUKEE', 514, 'Q37836'), ('PACIFIC DIVISION', 804, 'Q206201'), ('SAT', 997, 'Q334113')], 'fn_errors': [('NBA', 0, 'Q155223'), ('ATLANTIC', 223, 'Q638908'), ('NEW YORK', 269, 'Q131364'), ('WASHINGTON', 307, 'Q169165'), ('NEW JERSEY', 356, 'Q572134')]}, {'doc_title': 'NBA BASKETBALL - FRI', 'fp_errors': [('Cleveland', 178, 'Q162990'), ('Indiana', 315, 'Q6023245')], 'fn_errors': [('NBA', 0, 'Q155223'), ('Cleveland', 178, 'Q642553'), ('Indiana', 315, 'Q170329')]}, {'doc_title': 'NHL ICE HOCKEY - STA', 'fp_errors': [('OCKEY', 9, 'Q7965743'), ('HARTFORD', 263, 'Q830968'), ('PITTSBURGH', 364, 'Q1342'), ('ATLANTIC DIVISION', 415, 'Q756394'), ('FLORIDA', 449, 'Q812')], 'fn_errors': [('NHL', 0, 'Q1215892'), ('HARTFORD', 263, 'Q883425'), ('PITTSBURGH', 364, 'Q193643'), ('OTTAWA', 392, 'Q203013'), ('ATLANTIC', 415, 'Q756394')]}, {'doc_title': 'NHL ICE HOCKEY - FRI', 'fp_errors': [('CAP', 119, 'Q179304'), ('Toronto', 140, 'Q7222210'), ('COLORADO', 257, 'Q868358')], 'fn_errors': [('NHL', 0, 'Q1215892'), ('Toronto', 140, 'Q203384'), ('WASHINGTON', 188, 'Q204627'), ('COLORADO', 257, 'Q206297')]}, {'doc_title': 'NHL ICE HOCKEY - CAN', 'fp_errors': [('Burke', 899, 'Q364739')], 'fn_errors': [('NHL', 0, 'Q1215892'), ('NEW YORK', 57, 'Q60')]}, {'doc_title': 'BOXING - SCHULZ DEFE', 'fp_errors': [('SCHULZ', 9, 'Q5700860'), ('RIBALTA', 24, 'Q104857299'), ('IBF', 35, 'Q742944'), ('German', 76, 'Q42884'), ('Jose Ribalta', 113, 'Q16692080')], 'fn_errors': [('SCHULZ', 9, 'Q72828'), ('German', 76, 'Q183')]}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors': [], 'fn_errors': [('SPANISH', 9, 'Q29')]}, {'doc_title': 'SOCCER - BALKAN STRI', 'fp_errors': [(\"Real Madrid's\", 75, 'Q8682'), ('Spain', 193, 'Q42267'), ('New Year', 353, 'Q34812'), ('Croatian', 479, 'Q134479'), ('Montenegrin', 546, 'Q189018')], 'fn_errors': [('Real Madrid', 75, 'Q8682'), ('Spain', 193, 'Q29'), ('Croatian', 479, 'Q224'), ('Montenegrin', 546, 'Q236')]}, {'doc_title': 'SOCCER - PSV HIT VOL', 'fp_errors': [('Marcelo', 74, 'Q38136'), ('UEFA Cup', 688, 'Q18760'), ('Doetinchem', 791, 'Q145845')], 'fn_errors': [('Marcelo', 74, 'Q928137'), ('UEFA Cup', 688, 'Q756060')]}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors': [('Spanish', 96, 'Q324867'), ('Deportivo Coruna', 301, 'Q8760'), ('Sporting Gijon', 696, 'Q12278'), ('Logrones', 729, 'Q657865'), ('Extremadura', 865, 'Q994224')], 'fn_errors': [('SPANISH', 9, 'Q29'), ('Spanish', 96, 'Q29'), ('Sporting', 696, 'Q12278'), ('Extremadura', 865, 'Q732742')]}, {'doc_title': 'SOCCER - ENGLISHMAN ', 'fp_errors': [('ENGLISHMAN', 9, 'Q42406'), ('CHARLTON', 20, 'Q7597582'), ('IRISHMAN', 49, 'Q170826'), ('Ireland', 125, 'Q22890'), ('Englishman', 167, 'Q21')], 'fn_errors': [('ENGLISHMAN', 9, 'Q21'), ('CHARLTON', 20, 'Q313674'), ('IRISHMAN', 49, 'Q27'), ('Ireland', 125, 'Q27'), ('Englishman', 167, 'Q42406')]}], example_errors_md=[{'doc_title': 'SOCCER - JAPAN GET L', 'fp_errors_md': [('Nadim Ladki AL-AIN', 56, 'MENTION')], 'fn_errors_md': [('Nadim Ladki', 56, 'MENTION'), ('AL-AIN', 68, 'MENTION')]}, {'doc_title': 'RUGBY UNION - CUTTIT', 'fp_errors_md': [('GB', 2, 'MENTION'), ('World Cup', 681, 'MENTION')], 'fn_errors_md': [('RUGBY UNION', 0, 'MENTION'), ('ITALY', 32, 'MENTION'), ('1995 World Cup', 676, 'MENTION')]}, {'doc_title': 'SOCCER - LATE GOALS ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'FREESTYLE SKIING-WOR', 'fp_errors_md': [('CUP', 23, 'MENTION'), ('U.S', 373, 'MENTION'), ('U.S', 472, 'MENTION'), ('U.S', 637, 'MENTION'), ('U.S', 670, 'MENTION')], 'fn_errors_md': [('SKIING-WORLD CUP', 10, 'MENTION'), ('U.S.', 373, 'MENTION'), ('U.S.', 472, 'MENTION'), ('U.S.', 637, 'MENTION'), ('U.S.', 670, 'MENTION')]}, {'doc_title': 'SOCCER - ASIAN CUP G', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'CRICKET - PAKISTAN V', 'fp_errors_md': [('Young', 885, 'MENTION')], 'fn_errors_md': [('B. Young', 882, 'MENTION')]}, {'doc_title': 'SOCCER - ENGLISH F.A', 'fp_errors_md': [('English', 78, 'MENTION'), ('F.A. Challenge Cup', 86, 'MENTION')], 'fn_errors_md': [('English F.A. Challenge Cup', 78, 'MENTION')]}, {'doc_title': 'SOCCER - BLINKER BAN', 'fp_errors_md': [], 'fn_errors_md': [('Swiss', 712, 'MENTION')]}, {'doc_title': \"SOCCER - LEEDS ' BOW\", 'fp_errors_md': [('England under-21', 86, 'MENTION')], 'fn_errors_md': [('England', 86, 'MENTION')]}, {'doc_title': 'BASKETBALL - EUROLEA', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'RUGBY UNION - LITTLE', 'fp_errors_md': [('RUGBY', 0, 'MENTION'), ('CAMPESE FAREWELL', 29, 'MENTION')], 'fn_errors_md': [('RUGBY UNION', 0, 'MENTION'), ('LITTLE', 14, 'MENTION'), ('CAMPESE', 29, 'MENTION')]}, {'doc_title': 'GOLF - ZIMBABWE OPEN', 'fp_errors_md': [('U.S', 337, 'MENTION'), ('U.S', 695, 'MENTION')], 'fn_errors_md': [('U.S.', 337, 'MENTION'), ('U.S.', 695, 'MENTION')]}, {'doc_title': 'SOCCER - UNCAPPED PL', 'fp_errors_md': [], 'fn_errors_md': [('BUCHAREST', 52, 'MENTION'), ('REUTER', 1311, 'MENTION')]}, {'doc_title': 'SOCCER - BRAZILIAN C', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'CRICKET - LARA ENDUR', 'fp_errors_md': [('Robert Galvin MELBOURNE', 46, 'MENTION')], 'fn_errors_md': [('Robert Galvin', 46, 'MENTION'), ('MELBOURNE', 60, 'MENTION')]}, {'doc_title': 'CRICKET - AUSTRALIA ', 'fp_errors_md': [('I', 1046, 'MENTION'), ('Healy', 1049, 'MENTION')], 'fn_errors_md': [('I. Healy', 1046, 'MENTION')]}, {'doc_title': 'CRICKET - AUSTRALIA ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'CRICKET - WEST INDIE', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'CRICKET - SHEFFIELD ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'CRICKET - LARA SUFFE', 'fp_errors_md': [('AUSTRALIAN', 28, 'MENTION'), ('MELBOURNE 1996-12-06', 52, 'MENTION')], 'fn_errors_md': [('MELBOURNE', 52, 'MENTION')]}, {'doc_title': 'CRICKET - WEST INDIE', 'fp_errors_md': [('-', 67, 'MENTION'), ('-06', 70, 'MENTION'), ('Melbourne Cricket Ground', 237, 'MENTION')], 'fn_errors_md': [('Melbourne', 237, 'MENTION')]}, {'doc_title': 'BADMINTON - WORLD GR', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - ARAB CONTRA', 'fp_errors_md': [('ARAB CONTRACTORS', 9, 'MENTION'), ('National', 145, 'MENTION'), ('Contractors', 291, 'MENTION')], 'fn_errors_md': [('ARAB', 9, 'MENTION'), ('National stadium', 145, 'MENTION')]}, {'doc_title': 'NHL ICE HOCKEY - STA', 'fp_errors_md': [('NHL ICE HOCKEY', 0, 'MENTION'), ('EASTERN CONFERENCE NORTHEAST DIVISION', 213, 'MENTION'), ('ATLANTIC DIVISION', 418, 'MENTION'), ('WESTERN CONFERENCE CENTRAL DIVISION', 645, 'MENTION'), ('PACIFIC DIVISION', 844, 'MENTION')], 'fn_errors_md': [('NHL', 0, 'MENTION'), ('ATLANTIC', 418, 'MENTION'), ('CENTRAL DIVISION', 664, 'MENTION'), ('PACIFIC', 844, 'MENTION'), ('NY RANGERS PITTSBURGH', 1108, 'MENTION')]}, {'doc_title': 'NHL ICE HOCKEY - THU', 'fp_errors_md': [('NHL ICE HOCKEY', 0, 'MENTION'), ('CAP', 255, 'MENTION')], 'fn_errors_md': [('NHL', 0, 'MENTION')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors_md': [('NFL AMERICAN', 0, 'MENTION'), ('TS', 25, 'MENTION'), ('AGLES', 37, 'MENTION'), ('AFC', 183, 'MENTION'), ('NFC East', 845, 'MENTION')], 'fn_errors_md': [('NFL', 0, 'MENTION'), ('EAGLES', 36, 'MENTION')]}, {'doc_title': 'NBA BASKETBALL - STA', 'fp_errors_md': [('THUR', 33, 'MENTION'), ('EASTERN CONFERENCE ATLANTIC DIV', 208, 'MENTION'), ('CENTRAL DIVISION', 404, 'MENTION'), ('WESTERN CONFERENCE MIDWEST D', 596, 'MENTION'), ('ISION', 626, 'MENTION')], 'fn_errors_md': [('NBA', 0, 'MENTION'), ('ATLANTIC', 227, 'MENTION'), ('PACIFIC', 794, 'MENTION'), ('UTAH', 1114, 'MENTION'), ('CHARLOTTE', 1119, 'MENTION')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors_md': [('NFL AMERICAN', 0, 'MENTION'), ('AMERICAN FOOT', 198, 'MENTION'), ('CONFERENCE', 216, 'MENTION'), ('EASTERN DIVISION', 227, 'MENTION'), ('PA', 253, 'MENTION')], 'fn_errors_md': [('NFL', 0, 'MENTION'), ('AMERICAN', 198, 'MENTION'), ('PA PITTSBURGH', 400, 'MENTION'), ('MIAMI', 1327, 'MENTION'), ('ATLANTA', 1333, 'MENTION')]}, {'doc_title': 'NFL AMERICAN FOOTBAL', 'fp_errors_md': [('NFL AMERICAN FOOT', 0, 'MENTION'), ('National Football League', 71, 'MENTION')], 'fn_errors_md': [('NFL', 0, 'MENTION'), ('National', 71, 'MENTION'), ('Football League', 80, 'MENTION')]}, {'doc_title': 'NCAA AMERICAN FOOTBA', 'fp_errors_md': [(\"NCAA AMERICAN FOOTBALL-OHIO STATE'S\", 0, 'MENTION'), ('the Lombardi Award', 166, 'MENTION'), ('the Rotary Club', 205, 'MENTION'), ('the Rose Bowl', 360, 'MENTION'), ('The Lombardi Award', 772, 'MENTION')], 'fn_errors_md': [('NCAA', 0, 'MENTION'), ('FOOTBALL-OHIO STATE', 14, 'MENTION'), ('Lombardi Award', 170, 'MENTION'), ('Rotary Club', 209, 'MENTION'), ('Rose Bowl', 364, 'MENTION')]}, {'doc_title': 'SOCCER - DUTCH FIRST', 'fp_errors_md': [], 'fn_errors_md': [('DUTCH', 9, 'MENTION')]}, {'doc_title': 'SOCCER - GERMAN FIRS', 'fp_errors_md': [('FC Cologne', 525, 'MENTION')], 'fn_errors_md': [('BONN', 52, 'MENTION'), ('1. FC Cologne', 522, 'MENTION')]}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - DUTCH FIRST', 'fp_errors_md': [('Starbuck', 142, 'MENTION')], 'fn_errors_md': [('DUTCH', 9, 'MENTION')]}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors_md': [('UE', 20, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'SOCCER - FRENCH LEAG', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - GERMAN FIRS', 'fp_errors_md': [], 'fn_errors_md': [('BONN', 42, 'MENTION')]}, {'doc_title': 'TENNIS - GRAND SLAM ', 'fp_errors_md': [('U.S', 273, 'MENTION')], 'fn_errors_md': [('U.S.', 273, 'MENTION')]}, {'doc_title': 'SOCCER - WEAH HEAD-B', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER SHOWCASE-BETT', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER SHOWCASE-FANS', 'fp_errors_md': [('Santiago Bernabeu', 133, 'MENTION'), ('Real Madrid', 204, 'MENTION'), ('Barcelona', 216, 'MENTION')], 'fn_errors_md': [('Santiago Bernabeu stadium', 133, 'MENTION'), ('Real Madrid-Barcelona', 204, 'MENTION')]}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors_md': [('Sporting Gijon', 665, 'MENTION')], 'fn_errors_md': [('Sporting', 665, 'MENTION')]}, {'doc_title': 'SOCCER - SPAIN PICK ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - FIFA BOSS H', 'fp_errors_md': [('world soccer', 159, 'MENTION'), ('fair play', 174, 'MENTION'), ('Fair Play award', 457, 'MENTION')], 'fn_errors_md': [('HAVELANGE', 19, 'MENTION')]}, {'doc_title': 'GUNMEN WOUND TWO MAN', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - ITALIAN FIR', 'fp_errors_md': [('Italian Serie A', 70, 'MENTION')], 'fn_errors_md': [('Italian', 70, 'MENTION'), ('Serie A', 78, 'MENTION')]}, {'doc_title': 'BASKETBALL - EUROLEA', 'fp_errors_md': [('Kinder', 483, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'SQUASH - EYLES WITHI', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SQUASH - MAHINDRA IN', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'GUNMEN KILL FOUR IN ', 'fp_errors_md': [(\"South Africa's\", 157, 'MENTION')], 'fn_errors_md': [('South Africa', 157, 'MENTION')]}, {'doc_title': 'HAVEL PRAISES CZECH ', 'fp_errors_md': [(\"the United States '\", 200, 'MENTION'), ('State', 245, 'MENTION'), ('the United States', 481, 'MENTION'), ('State', 566, 'MENTION'), ('velvet revolution', 657, 'MENTION')], 'fn_errors_md': [('United States', 204, 'MENTION'), ('United States', 485, 'MENTION'), ('United States', 1042, 'MENTION'), ('United Nations', 1229, 'MENTION'), ('United Nations', 1840, 'MENTION')]}, {'doc_title': 'RADIO ROMANIA AFTERN', 'fp_errors_md': [('BUCHAR', 42, 'MENTION'), ('The Democratic Convention', 96, 'MENTION'), ('the Social Democratic Union', 210, 'MENTION'), ('Bucharest', 724, 'MENTION')], 'fn_errors_md': [('BUCHAREST', 42, 'MENTION'), ('Democratic Convention', 100, 'MENTION'), ('Social Democratic Union', 214, 'MENTION'), ('Bucharest Newsroom', 724, 'MENTION')]}, {'doc_title': 'CZECH VICE-PM SEES W', 'fp_errors_md': [('elections', 1348, 'MENTION'), ('elections', 1575, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'POLAND GOT MONEY FRO', 'fp_errors_md': [('Marcin Grajewski WARSAW', 47, 'MENTION'), ('the World War Two', 263, 'MENTION'), ('communists', 1260, 'MENTION')], 'fn_errors_md': [('Marcin Grajewski', 47, 'MENTION'), ('WARSAW', 64, 'MENTION'), ('World War Two', 267, 'MENTION'), ('Swiss', 438, 'MENTION'), ('Swiss', 2278, 'MENTION')]}, {'doc_title': 'INTERVIEW-ZYWIEC SEE', 'fp_errors_md': [('ZYWIEC', 10, 'MENTION'), ('Steven Silber WARSAW', 42, 'MENTION'), ('van Boxmeer', 1128, 'MENTION'), ('Elbrewery Company Ltd', 1966, 'MENTION'), ('van Boxmeer', 2578, 'MENTION')], 'fn_errors_md': [('INTERVIEW-ZYWIEC', 0, 'MENTION'), ('Steven Silber', 42, 'MENTION'), ('WARSAW', 56, 'MENTION'), ('Boxmeer', 1132, 'MENTION'), ('Elbrewery Company Ltd.', 1966, 'MENTION')]}, {'doc_title': 'HAVEL HAS TRAECHEOTO', 'fp_errors_md': [('acheotomy', 100, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'UK-US open skies tal', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Tambang Timah at $ 1', 'fp_errors_md': [('One Global Depository Receipt', 224, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Telkom at $ 35 in Lo', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Woman charged over N', 'fp_errors_md': [], 'fn_errors_md': [('BELFAST', 41, 'MENTION')]}, {'doc_title': 'Britain sets conditi', 'fp_errors_md': [('Atlantic', 161, 'MENTION'), ('the United States', 503, 'MENTION'), ('U.S', 1014, 'MENTION'), ('AMR Corp.,', 1472, 'MENTION'), (\"British Airways's\", 1664, 'MENTION')], 'fn_errors_md': [('trans-Atlantic', 155, 'MENTION'), ('United States', 507, 'MENTION'), ('U.S.', 1014, 'MENTION'), ('AMR Corp.', 1472, 'MENTION'), ('British Airways', 1664, 'MENTION')]}, {'doc_title': 'Med oil products mos', 'fp_errors_md': [('Med', 0, 'MENTION'), ('Mediterranean', 68, 'MENTION'), ('Med', 888, 'MENTION'), ('cif Med', 1321, 'MENTION'), ('Med', 1541, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'New meningitis scare', 'fp_errors_md': [('Lanarkshire county', 1239, 'MENTION')], 'fn_errors_md': [('Lanarkshire', 1239, 'MENTION')]}, {'doc_title': \"Major's office-Conse\", 'fp_errors_md': [], 'fn_errors_md': [('office-Conservatives', 8, 'MENTION')]}, {'doc_title': 'Electronic Data bags', 'fp_errors_md': [('Private Finance Initiative', 218, 'MENTION'), ('the Oceanic Control Centre', 395, 'MENTION'), ('the Civil Aviation Authority', 518, 'MENTION'), ('London News', 752, 'MENTION')], 'fn_errors_md': [('Oceanic Control Centre', 399, 'MENTION'), ('Civil Aviation Authority', 522, 'MENTION'), ('London Newsroom', 752, 'MENTION')]}, {'doc_title': 'RTRS - Cricket - Pla', 'fp_errors_md': [('TR', 1, 'MENTION')], 'fn_errors_md': [('RTRS', 0, 'MENTION')]}, {'doc_title': 'Cricket - Pakistan b', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Manitoba Pork forwar', 'fp_errors_md': [('Manitoba Government', 672, 'MENTION')], 'fn_errors_md': [('Manitoba', 672, 'MENTION'), ('C$', 705, 'MENTION')]}, {'doc_title': 'Canadian West Coast ', 'fp_errors_md': [('Canadian West Coast', 0, 'MENTION'), ('CWB', 38, 'MENTION'), ('The Canadian Wheat Board', 63, 'MENTION'), ('the Canadian West Coast', 143, 'MENTION'), ('the West Coast', 210, 'MENTION')], 'fn_errors_md': [('Canadian', 0, 'MENTION'), ('Canadian Wheat Board', 67, 'MENTION'), ('Canadian', 147, 'MENTION')]}, {'doc_title': 'New York timecharter', 'fp_errors_md': [('New York Commod', 101, 'MENTION')], 'fn_errors_md': [('New York Commodities Desk', 101, 'MENTION')]}, {'doc_title': 'New York coal / ore ', 'fp_errors_md': [('ORE', 66, 'MENTION'), ('New York Commodities Desk', 172, 'MENTION')], 'fn_errors_md': [('New York Commodities', 172, 'MENTION')]}, {'doc_title': 'Clean tankers fixtur', 'fp_errors_md': [('WESTERN', 80, 'MENTION'), ('New York Commodities Desk', 145, 'MENTION')], 'fn_errors_md': [('Caribs', 119, 'MENTION'), ('Mobil', 136, 'MENTION'), ('New York Commodities', 145, 'MENTION')]}, {'doc_title': 'Dirty tanker fixture', 'fp_errors_md': [('MIDEAST', 68, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'NYC Jan refunding ha', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'USDA gross cutout hi', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Wall St speculates a', 'fp_errors_md': [('St', 5, 'MENTION'), ('Wall', 105, 'MENTION'), (\"Santa Fe's\", 1566, 'MENTION'), ('the United States', 1796, 'MENTION'), (\"Santa Fe's\", 3418, 'MENTION')], 'fn_errors_md': [('Wall St', 0, 'MENTION'), ('Wall Street', 105, 'MENTION'), ('Santa Fe', 1566, 'MENTION'), ('United States', 1800, 'MENTION'), ('Santa Fe', 3418, 'MENTION')]}, {'doc_title': 'Russ Berrie presiden', 'fp_errors_md': [('N.J', 50, 'MENTION')], 'fn_errors_md': [('N.J.', 50, 'MENTION')]}, {'doc_title': 'Zimbabwe executes co', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Multinational comman', 'fp_errors_md': [('Chapter Seven', 2630, 'MENTION'), ('Chapter Seven', 2680, 'MENTION'), ('U.N. charter', 2701, 'MENTION'), ('the Security Council', 2715, 'MENTION'), ('Masisi', 3398, 'MENTION')], 'fn_errors_md': [('U.N.', 2701, 'MENTION'), ('Security Council', 2719, 'MENTION')]}, {'doc_title': 'Mauritius put on cyc', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'U.N. evacuates staff', 'fp_errors_md': [('The United Nations', 71, 'MENTION'), ('the Central African Republic', 113, 'MENTION')], 'fn_errors_md': [('United Nations', 75, 'MENTION'), ('Central African Republic', 117, 'MENTION')]}, {'doc_title': 'Senegal proposes for', 'fp_errors_md': [('The United States', 410, 'MENTION'), ('the United Nations', 737, 'MENTION')], 'fn_errors_md': [('United States', 414, 'MENTION'), ('United Nations', 741, 'MENTION')]}, {'doc_title': 'Ex-minister, son kil', 'fp_errors_md': [(\"Central Africa's\", 2589, 'MENTION')], 'fn_errors_md': [('Central Africa', 2589, 'MENTION')]}, {'doc_title': 'Five die as SAfrican', 'fp_errors_md': [(\"South Africa's\", 183, 'MENTION')], 'fn_errors_md': [('South Africa', 183, 'MENTION')]}, {'doc_title': 'WEATHER - Conditions', 'fp_errors_md': [('Moscow', 188, 'MENTION')], 'fn_errors_md': [('Moscow Newsroom', 188, 'MENTION')]}, {'doc_title': 'Skinheads attack Bra', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Albanian jailed for ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Polish ex-communist ', 'fp_errors_md': [('Pope', 39, 'MENTION'), ('Polish-born', 137, 'MENTION'), ('Pope', 149, 'MENTION'), ('the Catholic Church', 910, 'MENTION')], 'fn_errors_md': [('Catholic Church', 914, 'MENTION')]}, {'doc_title': 'Russia warns Norilsk', 'fp_errors_md': [('RAO Norilsky Nikel 0#', 641, 'MENTION'), ('UO', 668, 'MENTION'), ('Far North', 1606, 'MENTION')], 'fn_errors_md': [('RAO Norilsky Nikel', 641, 'MENTION')]}, {'doc_title': 'Estonian Tallinna Pa', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Russia ready for con', 'fp_errors_md': [('State', 215, 'MENTION'), ('the United Nations', 895, 'MENTION')], 'fn_errors_md': [('United Nations', 899, 'MENTION')]}, {'doc_title': 'Yeltsin plans return', 'fp_errors_md': [('the Soviet Union', 759, 'MENTION')], 'fn_errors_md': [('Soviet Union', 763, 'MENTION')]}, {'doc_title': 'Bomb explodes outsid', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Bomb explodes at mos', 'fp_errors_md': [('Ottoman', 491, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Hungary o / n rates ', 'fp_errors_md': [('social security', 186, 'MENTION'), (\"Budapest Bank's\", 319, 'MENTION'), ('social security', 729, 'MENTION')], 'fn_errors_md': [('BUDAPEST', 54, 'MENTION'), ('Budapest', 319, 'MENTION')]}, {'doc_title': 'Mexico stocks off lo', 'fp_errors_md': [], 'fn_errors_md': [('Dow', 230, 'MENTION'), ('ADRs', 1317, 'MENTION')]}, {'doc_title': 'Plastic surgery gets', 'fp_errors_md': [('the Brazilian Plastic Surgery Society', 497, 'MENTION'), (\"Latin America's\", 1089, 'MENTION'), ('liposuction', 1967, 'MENTION'), ('the United States', 2398, 'MENTION')], 'fn_errors_md': [('Brazilian Plastic Surgery Society', 501, 'MENTION'), ('Latin America', 1089, 'MENTION'), ('United States', 2402, 'MENTION')]}, {'doc_title': 'Daily Argentine grai', 'fp_errors_md': [('Camaras Arbitrales', 32, 'MENTION')], 'fn_errors_md': [('Quequen', 116, 'MENTION')]}, {'doc_title': 'Mexican daily port, ', 'fp_errors_md': [('the Communications and Transportation Ministry', 125, 'MENTION')], 'fn_errors_md': [('Communications and Transportation Ministry', 129, 'MENTION')]}, {'doc_title': 'Brazil exam cheats c', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Chile, Mexico to see', 'fp_errors_md': [('Chilean Congress', 930, 'MENTION'), ('Congress', 976, 'MENTION')], 'fn_errors_md': [('Finance', 191, 'MENTION'), ('Chilean', 930, 'MENTION')]}, {'doc_title': \"Indonesia's Belo lea\", 'fp_errors_md': [('The United Nations', 1455, 'MENTION'), ('the Nobel Peace Prize', 1552, 'MENTION'), ('Pope', 1915, 'MENTION')], 'fn_errors_md': [('United Nations', 1459, 'MENTION'), ('Nobel Peace Prize', 1556, 'MENTION')]}, {'doc_title': 'China to open port i', 'fp_errors_md': [('Qinglan port', 255, 'MENTION')], 'fn_errors_md': [('Qinglan', 255, 'MENTION')]}, {'doc_title': 'Government disperses', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Burmese students mar', 'fp_errors_md': [('Vithoon Amorn RANGOON', 46, 'MENTION'), ('the University of Yangon', 592, 'MENTION'), (\"Suu Kyi's\", 2131, 'MENTION'), ('the Yangon institute', 2601, 'MENTION'), (\"Suu Kyi's\", 2840, 'MENTION')], 'fn_errors_md': [('Vithoon Amorn', 46, 'MENTION'), ('RANGOON', 60, 'MENTION'), ('University of Yangon', 596, 'MENTION'), ('Suu Kyi', 2131, 'MENTION'), ('Yangon', 2605, 'MENTION')]}, {'doc_title': 'Union leaders outrag', 'fp_errors_md': [('Hansenne', 727, 'MENTION'), ('the ILO Workers Group', 1384, 'MENTION')], 'fn_errors_md': [('ILO Workers Group', 1388, 'MENTION')]}, {'doc_title': 'Indian rubber demand', 'fp_errors_md': [('the Rubber Board of India', 234, 'MENTION'), ('Asia Rubber Markets', 301, 'MENTION')], 'fn_errors_md': [('Rubber Board of India', 238, 'MENTION'), ('Asia Rubber Markets meeting', 301, 'MENTION')]}, {'doc_title': \"Japan's authorities \", 'fp_errors_md': [('Robert) Rubin', 953, 'MENTION'), ('the United States', 1204, 'MENTION'), ('Yen', 2172, 'MENTION')], 'fn_errors_md': [('Robert', 953, 'MENTION'), ('Rubin', 961, 'MENTION'), ('United States', 1208, 'MENTION'), ('Mr Yen', 2169, 'MENTION')]}, {'doc_title': 'Lebanon sentences pr', 'fp_errors_md': [('Haitham Haddadin BEIRUT', 48, 'MENTION'), ('absent', 141, 'MENTION')], 'fn_errors_md': [('Haitham Haddadin', 48, 'MENTION'), ('BEIRUT', 65, 'MENTION')]}, {'doc_title': 'Texas / w Okla fed c', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'USDA daily cattle an', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'BALANCE - Hartford, ', 'fp_errors_md': [('BALANCE', 0, 'MENTION'), ('CITY OF HARTFORD', 37, 'MENTION'), ('State Street Bank and Trust Company', 606, 'MENTION'), ('Prudential Securities Incorporated', 642, 'MENTION'), ('PaineWebber Incorporated', 677, 'MENTION')], 'fn_errors_md': [('HARTFORD', 45, 'MENTION'), (\"MOODY'S\", 110, 'MENTION'), ('S&P', 129, 'MENTION'), ('State Street Bank and Trust Company Prudential Securities Incorporated PaineWebber Incorporated First Union Capital Markets Corp.', 606, 'MENTION'), ('U.S. Municipal Desk', 743, 'MENTION')]}, {'doc_title': '14 years later, Flor', 'fp_errors_md': [('Fla', 59, 'MENTION'), ('John Mills Jr', 163, 'MENTION'), ('the U.S. Supreme Court', 1108, 'MENTION'), ('the Florida Supreme Court', 1489, 'MENTION'), ('11th Circuit U.S. Court of Appeals', 1533, 'MENTION')], 'fn_errors_md': [('Fla.', 59, 'MENTION'), ('John Mills', 163, 'MENTION'), ('God', 677, 'MENTION'), ('Allah', 685, 'MENTION'), ('God', 756, 'MENTION')]}, {'doc_title': 'New York grain freig', 'fp_errors_md': [('New York Commodities', 143, 'MENTION')], 'fn_errors_md': [('New York Commodities Desk', 143, 'MENTION')]}, {'doc_title': 'Iowa-S Minn fed catt', 'fp_errors_md': [('Iowa-S Minn', 0, 'MENTION'), ('USDA', 46, 'MENTION'), ('DES MO', 52, 'MENTION')], 'fn_errors_md': [('Iowa-S', 0, 'MENTION'), ('Minn', 7, 'MENTION'), ('sales-USDA', 40, 'MENTION'), ('DES MOINES', 52, 'MENTION'), ('Chicago', 757, 'MENTION')]}, {'doc_title': 'Man stole pigs, tipp', 'fp_errors_md': [('Outagmie County Circuit Court', 316, 'MENTION'), ('Luebke', 445, 'MENTION')], 'fn_errors_md': [('Outagmie County', 316, 'MENTION')]}, {'doc_title': 'Canadian grain stati', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'NYMEX natgas ends sh', 'fp_errors_md': [(\"the National Weather Service's\", 202, 'MENTION'), ('the National Weather Service', 497, 'MENTION'), ('U.S', 592, 'MENTION'), ('Midcontinent', 1107, 'MENTION'), ('Hub', 1266, 'MENTION')], 'fn_errors_md': [('National Weather Service', 206, 'MENTION'), ('National Weather Service', 501, 'MENTION'), ('U.S.', 592, 'MENTION'), ('NYMEX', 1334, 'MENTION'), ('Alberta', 1340, 'MENTION')]}, {'doc_title': 'U.S. barges lightly ', 'fp_errors_md': [('St. Louis Merchants Exchange', 116, 'MENTION'), ('south', 554, 'MENTION')], 'fn_errors_md': [('St. Louis', 116, 'MENTION')]}, {'doc_title': 'CBOT grain / oilseed', 'fp_errors_md': [('the Chicago Board of Trade', 183, 'MENTION'), ('Wheat', 231, 'MENTION'), ('Corn', 284, 'MENTION'), ('Oats', 354, 'MENTION'), ('Chicago', 480, 'MENTION')], 'fn_errors_md': [('Chicago Board of Trade', 187, 'MENTION'), ('Chicago Newsdesk', 480, 'MENTION')]}, {'doc_title': 'Clinton to have more', 'fp_errors_md': [('the White House', 172, 'MENTION')], 'fn_errors_md': [('White House', 176, 'MENTION')]}, {'doc_title': 'Action Performance t', 'fp_errors_md': [('Action Performance', 0, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Half of dog bites pr', 'fp_errors_md': [('the United States', 113, 'MENTION'), ('Humane Society of the United States', 240, 'MENTION'), ('the Glencoe Animal Hospital', 505, 'MENTION'), ('Columbus, Ohio', 536, 'MENTION'), ('chow chows', 1279, 'MENTION')], 'fn_errors_md': [('United States', 117, 'MENTION'), ('United States', 262, 'MENTION'), ('Glencoe Animal Hospital', 509, 'MENTION'), ('Columbus', 536, 'MENTION'), ('Ohio', 546, 'MENTION')]}, {'doc_title': 'Iowa-S Minn feedlot ', 'fp_errors_md': [('Iowa-S Minn', 0, 'MENTION'), ('DES', 52, 'MENTION')], 'fn_errors_md': [('Iowa-S', 0, 'MENTION'), ('Minn', 7, 'MENTION'), ('DES MOINES', 52, 'MENTION'), ('Chicago', 206, 'MENTION')]}, {'doc_title': 'Nebraska fed cattle ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Four Africans said t', 'fp_errors_md': [('the Ivory Coast', 716, 'MENTION'), ('The United States', 1392, 'MENTION'), ('The Security Council', 1722, 'MENTION')], 'fn_errors_md': [('Ivory Coast', 720, 'MENTION'), ('United States', 1396, 'MENTION'), ('Security Council', 1726, 'MENTION')]}, {'doc_title': \"Spain's police seize\", 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': \"Mussolini's granddau\", 'fp_errors_md': [('Fascist', 118, 'MENTION'), ('Duce', 1124, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'German Santa in bank', 'fp_errors_md': [], 'fn_errors_md': [('Santa', 7, 'MENTION')]}, {'doc_title': 'Italy commission con', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'EU, Poland agree on ', 'fp_errors_md': [('The', 60, 'MENTION'), ('Europe Agreement', 378, 'MENTION')], 'fn_errors_md': [('Europe', 378, 'MENTION')]}, {'doc_title': 'Hindu party forces I', 'fp_errors_md': [('communist', 381, 'MENTION'), ('Babri mosque', 438, 'MENTION'), ('Hindu-Moslem violence', 758, 'MENTION'), ('bombings', 913, 'MENTION'), ('Lord', 1109, 'MENTION')], 'fn_errors_md': [('Hindu-Moslem', 758, 'MENTION')]}, {'doc_title': 'Indian Sept crude oi', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'LUXEMBOURG CHRISTMAS', 'fp_errors_md': [('LUXEMBOURG CHRISTMAS MARK', 0, 'MENTION'), ('Brussels', 374, 'MENTION')], 'fn_errors_md': [('LUXEMBOURG', 0, 'MENTION'), ('Brussels Newsroom', 374, 'MENTION')]}, {'doc_title': 'London coal / ore fi', 'fp_errors_md': [('COAL', 46, 'MENTION'), ('Coe', 306, 'MENTION'), ('Clerici', 314, 'MENTION'), ('ORE', 323, 'MENTION'), ('IMC TBN', 329, 'MENTION')], 'fn_errors_md': [('Coe and Clerici', 306, 'MENTION')]}, {'doc_title': 'UK bookmakers length', 'fp_errors_md': [('London News', 377, 'MENTION')], 'fn_errors_md': [('London Newsroom', 377, 'MENTION')]}, {'doc_title': 'Italy tops week of m', 'fp_errors_md': [(\"Salomon Brothers '\", 1072, 'MENTION')], 'fn_errors_md': [('Treasuries', 637, 'MENTION'), ('Salomon Brothers', 1072, 'MENTION'), ('International Bonds', 1836, 'MENTION')]}, {'doc_title': 'OPEC basket price $ ', 'fp_errors_md': [('London News', 412, 'MENTION')], 'fn_errors_md': [('London Newsroom', 412, 'MENTION')]}, {'doc_title': 'Relations between Cl', 'fp_errors_md': [('Chancellor of', 86, 'MENTION'), ('quer', 109, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Two dead after execu', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'PLO says Arafat, Net', 'fp_errors_md': [('Arafat-Netanyahu', 1549, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Turkey hindered by o', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Three dead in Kurd m', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Texas / w Okla fed c', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Kansas feedlot cattl', 'fp_errors_md': [('Inquiry good', 259, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Delphis Hanover week', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'ACCESS energy future', 'fp_errors_md': [('NYMEX', 132, 'MENTION'), ('Northeastern', 219, 'MENTION')], 'fn_errors_md': [('NYMEX ACCESS', 132, 'MENTION')]}, {'doc_title': 'U.S. blasts release ', 'fp_errors_md': [('The United States', 1680, 'MENTION'), ('May 15 Palestinian', 1733, 'MENTION')], 'fn_errors_md': [('United States', 1684, 'MENTION'), ('Palestinian', 1740, 'MENTION')]}, {'doc_title': 'School football play', 'fp_errors_md': [('N.M', 67, 'MENTION'), ('the New Mexico Activities Association', 536, 'MENTION')], 'fn_errors_md': [('N.M.', 67, 'MENTION'), ('New Mexico Activities Association', 540, 'MENTION')]}, {'doc_title': 'Cyberspace squabbles', 'fp_errors_md': [('Western', 889, 'MENTION'), ('Consumer Project on Technology', 1487, 'MENTION')], 'fn_errors_md': [('Internet', 144, 'MENTION'), ('Internet', 1085, 'MENTION'), ('Consumer Project', 1487, 'MENTION'), ('Internet', 2213, 'MENTION'), ('Internet', 2427, 'MENTION')]}, {'doc_title': 'Italy evacuates 17 n', 'fp_errors_md': [('The Foreign Ministry', 241, 'MENTION'), ('Garamba national', 334, 'MENTION')], 'fn_errors_md': [('Foreign Ministry', 245, 'MENTION'), ('Garamba', 334, 'MENTION')]}, {'doc_title': 'Third Paris blast vi', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Italian President ur', 'fp_errors_md': [('MANTUA', 50, 'MENTION'), ('Mantua', 310, 'MENTION'), ('Po River', 1464, 'MENTION')], 'fn_errors_md': [('Let', 540, 'MENTION'), ('Po', 1464, 'MENTION')]}, {'doc_title': \"Denmark's Radiometer\", 'fp_errors_md': [('Radiometer', 10, 'MENTION')], 'fn_errors_md': [('Wednesday', 218, 'MENTION')]}, {'doc_title': 'Moslem fundamentalis', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Belgian police smash', 'fp_errors_md': [], 'fn_errors_md': [('Belgian', 337, 'MENTION'), ('Belgian', 997, 'MENTION')]}, {'doc_title': 'Port conditions upda', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'German Jan-August co', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Munich Re says to sp', 'fp_errors_md': [('Muenchener Rueckversicherungs AG', 58, 'MENTION'), (\"Munich Re's\", 470, 'MENTION'), (\"Munich Re's\", 582, 'MENTION'), ('Frankfurt', 687, 'MENTION')], 'fn_errors_md': [('Muenchener', 58, 'MENTION'), ('Rueckversicherungs AG', 69, 'MENTION'), ('Munich Re', 470, 'MENTION'), ('Munich Re', 582, 'MENTION'), ('Frankfurt Newsroom', 687, 'MENTION')]}, {'doc_title': 'EU experts postpone ', 'fp_errors_md': [('Brussels', 608, 'MENTION')], 'fn_errors_md': [('Brussels Newsroom', 608, 'MENTION')]}, {'doc_title': 'Frankfurt dollar fix', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'John Lewis UK store ', 'fp_errors_md': [('The John Lewis Partnership', 62, 'MENTION'), ('London', 437, 'MENTION')], 'fn_errors_md': [('John Lewis', 66, 'MENTION'), ('London Newsroom', 437, 'MENTION')]}, {'doc_title': 'Timah at 15.625 in L', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'British \"Euro-scepti', 'fp_errors_md': [('Parliament', 288, 'MENTION'), ('Conservatives', 396, 'MENTION'), ('Parliament', 940, 'MENTION')], 'fn_errors_md': [('British', 0, 'MENTION'), ('Euro-sceptic', 9, 'MENTION'), ('Euro-sceptic', 71, 'MENTION')]}, {'doc_title': 'Court ejects head of', 'fp_errors_md': [('the Foreign Affairs Department', 885, 'MENTION')], 'fn_errors_md': [('Foreign Affairs Department', 889, 'MENTION')]}, {'doc_title': 'Australian hitman ki', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': \"NZ's Bolger says Nat\", 'fp_errors_md': [('NZ First', 30, 'MENTION')], 'fn_errors_md': [('NZ', 30, 'MENTION')]}, {'doc_title': \"NZ's Peters says Nat\", 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'RTRS - Australian MP', 'fp_errors_md': [('Labor', 1011, 'MENTION')], 'fn_errors_md': [('RTRS', 0, 'MENTION')]}, {'doc_title': 'Burmese students mar', 'fp_errors_md': [('the', 211, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Thai rice vessels lo', 'fp_errors_md': [('Thai Commerce Ministry', 74, 'MENTION'), ('Iran', 202, 'MENTION'), ('r', 210, 'MENTION'), ('Iran Princess of Loine', 227, 'MENTION'), ('Seagramd ace', 311, 'MENTION')], 'fn_errors_md': [('Thai', 74, 'MENTION'), ('Commerce Ministry', 79, 'MENTION'), ('Iran Sabr', 202, 'MENTION'), ('Iran', 227, 'MENTION'), ('Princess of Loine', 232, 'MENTION')]}, {'doc_title': 'Chinese girl nearly ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'South Korean won clo', 'fp_errors_md': [('OUL', 54, 'MENTION')], 'fn_errors_md': [('SEOUL', 52, 'MENTION')]}, {'doc_title': 'Foreign planes to la', 'fp_errors_md': [('BE', 50, 'MENTION'), ('ING', 54, 'MENTION'), (\"the State Council's\", 247, 'MENTION'), ('Port Office', 267, 'MENTION'), ('the Civil Aviation Administration of China', 280, 'MENTION')], 'fn_errors_md': [('BEIJING', 50, 'MENTION'), ('State Council', 251, 'MENTION'), ('Civil Aviation Administration of China', 284, 'MENTION'), ('General Administration of Customs', 328, 'MENTION')]}, {'doc_title': 'EPA says economic as', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Sangetsu - 96/97 par', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'Bre-X, Barrick said ', 'fp_errors_md': [('the Indonesian Mines and Energy Ministry', 868, 'MENTION'), ('the Mines and Energy Ministry', 1930, 'MENTION'), ('the Panutan Group', 2776, 'MENTION'), ('the Citra Group', 3016, 'MENTION')], 'fn_errors_md': [('Indonesian Mines and Energy Ministry', 872, 'MENTION'), ('Mines and Energy Ministry', 1934, 'MENTION'), ('Panutan Group', 2780, 'MENTION'), ('Citra Group', 3020, 'MENTION')]}, {'doc_title': 'Honda RV exceeds sal', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'FEATURE - Singapore ', 'fp_errors_md': [('Ramthan Hussain SINGAPORE', 50, 'MENTION'), ('the', 124, 'MENTION'), ('U.S.', 942, 'MENTION'), ('Uruguay Round', 1769, 'MENTION'), ('the European Union', 1946, 'MENTION')], 'fn_errors_md': [('Ramthan Hussain', 50, 'MENTION'), ('SINGAPORE', 66, 'MENTION'), ('then-U.S.', 937, 'MENTION'), ('Uruguay', 1769, 'MENTION'), ('European Union', 1950, 'MENTION')]}, {'doc_title': 'Japan NTT says hopes', 'fp_errors_md': [('Posts and Telecommunications', 581, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'Ahold launches Asian', 'fp_errors_md': [], 'fn_errors_md': [('US$', 861, 'MENTION')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors_md': [('ALPINE', 0, 'MENTION'), ('Lillehammer Winter Olympics', 306, 'MENTION')], 'fn_errors_md': [('Lillehammer', 306, 'MENTION'), ('Winter Olympics', 318, 'MENTION')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors_md': [('ALPINE', 0, 'MENTION'), ('U.S', 939, 'MENTION'), ('U.S', 1045, 'MENTION'), ('U.S', 1077, 'MENTION'), ('Ingeborg', 1225, 'MENTION')], 'fn_errors_md': [('U.S.', 939, 'MENTION'), ('U.S.', 1045, 'MENTION'), ('U.S.', 1077, 'MENTION'), ('Ingeborg Helen Marken', 1225, 'MENTION')]}, {'doc_title': 'ALPINE SKIING-GLADIS', 'fp_errors_md': [('ALPINE SKIING-GLADISHIVA', 0, 'MENTION'), ('WORLD CUP SUPER G', 30, 'MENTION'), ('World Cup Super G', 121, 'MENTION')], 'fn_errors_md': [('SKIING-GLADISHIVA', 7, 'MENTION'), ('WORLD CUP', 30, 'MENTION'), ('World Cup', 121, 'MENTION')]}, {'doc_title': 'GOLF - THIRD ROUND O', 'fp_errors_md': [('LPGA Tours', 385, 'MENTION'), ('U.S. Amateur', 624, 'MENTION')], 'fn_errors_md': [('LPGA', 385, 'MENTION'), ('U.S.', 624, 'MENTION')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors_md': [('World Cup', 329, 'MENTION')], 'fn_errors_md': [('1993 World Cup', 324, 'MENTION')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors_md': [('ALPINE', 0, 'MENTION'), ('Ingeborg', 422, 'MENTION'), ('Helen Markein', 431, 'MENTION'), ('U.S', 475, 'MENTION'), ('Florence Masnada', 523, 'MENTION')], 'fn_errors_md': [('Ingeborg Helen', 422, 'MENTION'), ('U.S.', 475, 'MENTION'), ('Florence', 523, 'MENTION'), ('Masnada', 532, 'MENTION'), ('U.S.', 571, 'MENTION')]}, {'doc_title': \"ALPINE SKIING-WOMEN'\", 'fp_errors_md': [('ALPINE', 0, 'MENTION'), ('U.S', 331, 'MENTION'), ('Ingeborg', 420, 'MENTION'), ('Helen Marken', 429, 'MENTION'), ('Germay', 1163, 'MENTION')], 'fn_errors_md': [('U.S.', 331, 'MENTION'), ('Ingeborg Helen Marken', 420, 'MENTION')]}, {'doc_title': 'NORDIC SKIING-WORLD ', 'fp_errors_md': [('NORDIC', 0, 'MENTION'), ('IING-WORLD CUP', 9, 'MENTION')], 'fn_errors_md': [('SKIING-WORLD CUP', 7, 'MENTION')]}, {'doc_title': 'ALPINE SKIING-GOETCH', 'fp_errors_md': [('-GOETCHL', 13, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'BOBSLEIGH-SHIMER PIL', 'fp_errors_md': [('Canada', 509, 'MENTION'), ('USA', 864, 'MENTION')], 'fn_errors_md': [('BOBSLEIGH-SHIMER', 0, 'MENTION'), ('Canada I', 509, 'MENTION'), ('USA I', 864, 'MENTION')]}, {'doc_title': 'SKIING-CHINESE MAKE ', 'fp_errors_md': [('CHINESE', 7, 'MENTION'), ('world cup', 133, 'MENTION')], 'fn_errors_md': [('SKIING-CHINESE', 0, 'MENTION')]}, {'doc_title': 'BOBSLEIGH-WORLD CUP ', 'fp_errors_md': [('CUP', 16, 'MENTION'), ('United States', 126, 'MENTION'), ('Italy', 216, 'MENTION'), ('Canada', 287, 'MENTION'), ('German', 357, 'MENTION')], 'fn_errors_md': [('BOBSLEIGH-WORLD CUP', 0, 'MENTION'), ('United States III', 126, 'MENTION'), ('Italy I', 216, 'MENTION'), ('Canada I', 287, 'MENTION'), ('German I', 357, 'MENTION')]}, {'doc_title': 'CRICKET - WOOLMER MA', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'FREESTYLE SKIING-WOR', 'fp_errors_md': [('CUP', 23, 'MENTION'), ('U.S', 458, 'MENTION')], 'fn_errors_md': [('SKIING-WORLD CUP', 10, 'MENTION'), ('U.S.', 458, 'MENTION')]}, {'doc_title': 'SKI JUMPING-LEADING ', 'fp_errors_md': [('SK', 0, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'BADMINTON - WORLD GR', 'fp_errors_md': [('BADMINTON', 0, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'SPEED SKATING-RESULT', 'fp_errors_md': [('U.S', 1551, 'MENTION'), ('U.S', 1685, 'MENTION')], 'fn_errors_md': [('U.S.', 1551, 'MENTION'), ('U.S.', 1685, 'MENTION')]}, {'doc_title': 'ALPINE SKIING-OFFICI', 'fp_errors_md': [('WHISTLER,', 59, 'MENTION')], 'fn_errors_md': [('WHISTLER', 59, 'MENTION')]}, {'doc_title': 'SOCCER - LEADING SCO', 'fp_errors_md': [('SCOTTISH', 17, 'MENTION'), ('Scottish', 98, 'MENTION')], 'fn_errors_md': [('SCOTTISH PREMIER DIVISION', 17, 'MENTION'), ('Scottish premier', 98, 'MENTION')]}, {'doc_title': 'SOCCER - LEADING ENG', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - NORTHERN IR', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'RUGBY UNION - BRITIS', 'fp_errors_md': [('UGBY UNION', 1, 'MENTION'), ('BRITISH', 14, 'MENTION')], 'fn_errors_md': [('RUGBY UNION', 0, 'MENTION')]}, {'doc_title': 'SOCCER - SCOTTISH PR', 'fp_errors_md': [('SOCCER', 0, 'MENTION'), ('Windass', 205, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'RUGBY UNION - RETIRI', 'fp_errors_md': [('GB', 2, 'MENTION'), ('Super 12', 704, 'MENTION')], 'fn_errors_md': [('RUGBY UNION', 0, 'MENTION')]}, {'doc_title': 'SOCCER - ENGLISH PRE', 'fp_errors_md': [('CCER', 2, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'SOCCER - SCOTTISH LE', 'fp_errors_md': [('ER', 4, 'MENTION'), ('SCOTTISH LEAGUE', 9, 'MENTION')], 'fn_errors_md': [('SCOTTISH', 9, 'MENTION')]}, {'doc_title': 'SOCCER - ENGLISH LEA', 'fp_errors_md': [('SOCCER', 0, 'MENTION'), ('ENGLISH LEAGUE', 9, 'MENTION'), ('Division One', 783, 'MENTION')], 'fn_errors_md': [('ENGLISH', 9, 'MENTION'), ('Premier league', 188, 'MENTION')]}, {'doc_title': 'SOCCER - VIEIRA SAVE', 'fp_errors_md': [], 'fn_errors_md': [('ARSENAL', 22, 'MENTION')]}, {'doc_title': 'SOCCER - SCOTTISH LE', 'fp_errors_md': [('CUP', 29, 'MENTION')], 'fn_errors_md': []}, {'doc_title': 'SOCCER - ENGLISH LEA', 'fp_errors_md': [('SOCCER', 0, 'MENTION'), ('CUP', 28, 'MENTION'), ('Premier', 115, 'MENTION'), ('Bolton F.A. Challenge Cup', 648, 'MENTION')], 'fn_errors_md': [('Premier league', 115, 'MENTION'), ('Bolton', 648, 'MENTION'), ('F.A. Challenge Cup', 655, 'MENTION')]}, {'doc_title': 'RUGBY UNION - CAMPES', 'fp_errors_md': [('GB', 2, 'MENTION'), ('Y', 50, 'MENTION')], 'fn_errors_md': [('RUGBY UNION', 0, 'MENTION'), ('WALLABY', 44, 'MENTION')]}, {'doc_title': 'RUGBY UNION - AUSTRA', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'GOLF - ZIMBABWE OPEN', 'fp_errors_md': [('U.S', 579, 'MENTION')], 'fn_errors_md': [('U.S.', 579, 'MENTION')]}, {'doc_title': 'SOCCER - REINSTATED ', 'fp_errors_md': [('World Cup', 243, 'MENTION')], 'fn_errors_md': [(\"Saturday'sWorld Cup\", 233, 'MENTION')]}, {'doc_title': 'CRICKET - JONES HITS', 'fp_errors_md': [], 'fn_errors_md': [('Pace', 977, 'MENTION')]}, {'doc_title': 'CRICKET - SHEFFIELD ', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - SOUTH KOREA', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - ISRAELI FIR', 'fp_errors_md': [('Ironi Rishon Lezion', 858, 'MENTION')], 'fn_errors_md': [('JERUSALEM', 53, 'MENTION'), ('Ironi Rishon', 858, 'MENTION')]}, {'doc_title': 'SOCCER - ASIAN CUP R', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'NBA BASKETBALL - STA', 'fp_errors_md': [('EASTERN CONFERENCE ATLANTIC', 204, 'MENTION'), ('WESTERN CONFERENCE MIDWEST DIV', 600, 'MENTION'), ('PACIFIC DIVISION', 804, 'MENTION'), ('SAT', 997, 'MENTION'), ('NEW JERSEY MIAMI', 1105, 'MENTION')], 'fn_errors_md': [('NBA', 0, 'MENTION'), ('ATLANTIC', 223, 'MENTION'), ('PACIFIC', 804, 'MENTION'), ('NEW JERSEY', 1105, 'MENTION'), ('MIAMI', 1116, 'MENTION')]}, {'doc_title': 'NBA BASKETBALL - FRI', 'fp_errors_md': [], 'fn_errors_md': [('NBA', 0, 'MENTION')]}, {'doc_title': 'NHL ICE HOCKEY - STA', 'fp_errors_md': [('NHL ICE', 0, 'MENTION'), ('OCKEY', 9, 'MENTION'), ('EASTERN CONFERENCE NORTHEAST D', 209, 'MENTION'), ('ISION', 241, 'MENTION'), ('ATLANTIC DIVISION', 415, 'MENTION')], 'fn_errors_md': [('NHL', 0, 'MENTION'), ('ATLANTIC', 415, 'MENTION'), ('PACIFIC', 842, 'MENTION'), ('BOSTON', 1121, 'MENTION'), ('BUFFALO', 1128, 'MENTION')]}, {'doc_title': 'NHL ICE HOCKEY - FRI', 'fp_errors_md': [('NHL ICE HOCKEY', 0, 'MENTION'), ('CAP', 119, 'MENTION')], 'fn_errors_md': [('NHL', 0, 'MENTION')]}, {'doc_title': 'NHL ICE HOCKEY - CAN', 'fp_errors_md': [('NHL ICE HOCKEY', 0, 'MENTION')], 'fn_errors_md': [('NHL', 0, 'MENTION')]}, {'doc_title': 'BOXING - SCHULZ DEFE', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - BALKAN STRI', 'fp_errors_md': [(\"Real Madrid's\", 75, 'MENTION'), ('New Year', 353, 'MENTION')], 'fn_errors_md': [('Real Madrid', 75, 'MENTION')]}, {'doc_title': 'SOCCER - PSV HIT VOL', 'fp_errors_md': [], 'fn_errors_md': []}, {'doc_title': 'SOCCER - SPANISH FIR', 'fp_errors_md': [('Sporting Gijon', 696, 'MENTION')], 'fn_errors_md': [('Sporting', 696, 'MENTION')]}, {'doc_title': 'SOCCER - ENGLISHMAN ', 'fp_errors_md': [('the Republic of Ireland', 506, 'MENTION'), ('1988 European championship', 1057, 'MENTION')], 'fn_errors_md': [('Republic of Ireland', 510, 'MENTION'), ('European', 1062, 'MENTION')]}]),\n",
       " 'MSNBC': Metrics(el=True, num_gold_spans=651, tp=503, fp=216, fn=148, tp_md=615, fp_md=189, fn_md=124, gold_entity_in_cand=648, num_docs=20, example_errors=[{'doc_title': 'Stocks end back-and-', 'fp_errors': [('the New York Stock Exchange', 307, 'Q13677'), ('U.S.', 1769, 'Q30'), ('Fed', 1878, 'Q53536'), (\"The Labor Department's\", 2125, 'Q628807'), ('Dow Jones industrial', 2517, 'Q180816')], 'fn_errors': [('New York Stock Exchange', 311, 'Q13677'), ('Home Depot Inc.', 1102, 'Q864407'), ('The Fed', 1874, 'Q53536'), ('Labor Department', 2129, 'Q628807'), ('Oklahoma City', 2415, 'Q34863')]}, {'doc_title': 'Home Depot CEO Narde', 'fp_errors': [('Nardelli', 263, 'Q1409655'), (\"The Home Depot Inc.'s\", 288, 'Q864407'), ('Atlanta-based', 561, 'Q23556'), ('D-', 829, 'Q29552'), ('Mass', 831, 'Q771')], 'fn_errors': [('The Home Depot Inc.', 288, 'Q864407'), ('Atlanta', 561, 'Q23556'), ('Home Depot', 1144, 'Q864407'), ('General Electric Co.', 2671, 'Q54173'), ('Home Depot', 3168, 'Q864407')]}, {'doc_title': 'Timberlake, Diaz rep', 'fp_errors': [('Star', 179, 'Q3496935'), ('Colo', 264, 'Q1261')], 'fn_errors': [('Timberlake', 0, 'Q43432'), ('Star magazine', 179, 'Q3496935'), ('Christmas', 229, 'Q19809'), ('Colo.', 264, 'Q1261'), ('Finn', 825, 'Q1532145')]}, {'doc_title': 'Barbara Walters stan', 'fp_errors': [('View', 43, 'Q1197928'), ('Donald', 731, 'Q22686')], 'fn_errors': [('The Donald', 727, 'Q22686')]}, {'doc_title': 'Resolution to imbibe', 'fp_errors': [('the Mayo Clinic', 799, 'Q1130172'), ('New York', 1543, 'Q1384'), ('the Goteborg University', 2015, 'Q371522'), (\"non-Hodgkin's lymphoma\", 2480, 'Q1138590'), ('the University of Missouri', 2744, 'Q579968')], 'fn_errors': [('Mayo Clinic', 803, 'Q1130172'), ('New York', 1543, 'Q60'), ('Goteborg University', 2019, 'Q371522'), (\"Hodgkin's lymphoma\", 2484, 'Q209369'), ('University of Missouri', 2748, 'Q579968')]}, {'doc_title': 'Health insurance bri', 'fp_errors': [('Ala', 129, 'Q173'), ('U.S.', 287, 'Q30'), ('Rohling', 317, 'Q72137'), ('Rohling', 620, 'Q72137'), ('Rohling', 629, 'Q72137')], 'fn_errors': [('Ala.', 129, 'Q173'), ('U.S. government', 287, 'Q48525'), ('United States', 1117, 'Q30'), ('Washington', 1502, 'Q61'), ('U.S. Congress', 1564, 'Q11268')]}, {'doc_title': 'TUSCALOOSA, Ala. - N', 'fp_errors': [('Ala', 12, 'Q173'), ('Alabama', 108, 'Q4705216'), ('Crimson Tide', 311, 'Q4705216'), ('Alabama', 749, 'Q4705216'), ('Tide', 882, 'Q4705216')], 'fn_errors': [('Ala.', 12, 'Q173'), ('Alabama', 108, 'Q492318'), ('Crimson Tide', 311, 'Q971195'), ('Alabama', 749, 'Q173'), ('Tide', 882, 'Q971195')]}, {'doc_title': 'Riley to have surger', 'fp_errors': [('Riles', 1847, 'Q335762'), ('Heat', 1964, 'Q169138'), ('NBA', 2121, 'Q155223'), ('NBA', 2368, 'Q155223'), ('Showtime-era', 4350, 'Q5099587')], 'fn_errors': [('MIAMI', 36, 'Q8652'), ('Detroit Pistons', 2157, 'Q169661'), ('MVP', 3679, 'Q652965')]}, {'doc_title': '30 panda cubs born i', 'fp_errors': [('the State Forestry Administration', 382, 'Q54870074'), ('the Xinhua News Agency', 441, 'Q204839'), ('the Chengdu Research Base', 812, 'Q1067861')], 'fn_errors': [('State Forestry Administration', 386, 'Q54870074'), ('Xinhua News Agency', 445, 'Q204839'), ('Giant pandas', 1064, 'Q33602')]}, {'doc_title': 'Upgrade makes aging ', 'fp_errors': [('Mars', 20, 'Q111'), ('Mars', 131, 'Q111'), ('the Red Planet', 409, 'Q111'), ('John Callas', 497, 'Q56290136'), ('Callas', 1511, 'Q1702745')], 'fn_errors': [('Mars rovers', 20, 'Q389459'), ('Mars rovers', 131, 'Q389459'), ('Red Planet', 413, 'Q111'), ('Martian', 2077, 'Q913850')]}, {'doc_title': '5 charged in Texas a', 'fp_errors': [('Houston', 570, 'Q16555'), ('Carlos Osorio', 713, 'Q887685'), ('Erick Perez', 732, 'Q60685231'), ('Osorio', 815, 'Q887685'), ('Perez', 826, 'Q60685231')], 'fn_errors': [('Police', 389, 'Q35535')]}, {'doc_title': 'Thousands of holiday', 'fp_errors': [('London', 72, 'Q84'), ('Heathrow Airport', 81, 'Q8691'), ('London', 230, 'Q84'), ('Heathrow Airport', 239, 'Q8691'), ('Terminal 4', 387, 'Q6670470')], 'fn_errors': [(\"London's Heathrow Airport\", 72, 'Q8691'), (\"London's Heathrow Airport\", 230, 'Q8691'), ('Christmas holiday', 735, 'Q1857341')]}, {'doc_title': 'Five healthy resolut', 'fp_errors': [(\"New Year's\", 116, 'Q34812'), ('the New Year', 484, 'Q34812'), ('the American Journal of Clinical Nutrition', 1240, 'Q7713500'), ('Sara Lee Food & Beverage', 1887, 'Q660309'), ('Annual Scientific Meeting', 2400, 'Q2020153')], 'fn_errors': [(\"New Year's resolution\", 116, 'Q2155091'), ('Nutritionist', 186, 'Q2576499'), ('New Year', 488, 'Q34812'), ('LDL-Cholesterol', 813, 'Q28749'), ('HDL-Cholesterol', 845, 'Q410020')]}, {'doc_title': 'U.S. mines still not', 'fp_errors': [('Sago Mine', 61, 'Q7399333'), ('W. Va.', 126, 'Q1371'), ('the Sago Mine', 234, 'Q7399333'), ('Davitt McAteer', 1146, 'Q51754267'), (\"West Virginia's\", 1261, 'Q1371')], 'fn_errors': [('Sago Mine accident', 61, 'Q7399333'), ('W. Va', 126, 'Q1371'), ('Sago Mine', 238, 'Q7399333'), ('West Virginia', 1261, 'Q1371'), ('Sago', 1603, 'Q7399333')]}, {'doc_title': 'Chertoff pledges to ', 'fp_errors': [('Chertoff', 0, 'Q104879523'), ('Sept. 11, 2001', 977, 'Q10806'), ('Sept. 11', 1302, 'Q10806'), ('Wyo', 2101, 'Q1214'), ('La', 2165, 'Q1588')], 'fn_errors': [('Chertoff', 0, 'Q733612'), ('Washington', 1989, 'Q61'), ('D.C.', 2001, 'Q61'), ('S.D.', 2075, 'Q1211'), ('Wyo.', 2101, 'Q1214')]}, {'doc_title': 'Muslim with U.S. fam', 'fp_errors': [('Calif', 129, 'Q99'), ('German', 140, 'Q183'), ('anti-Muslim', 426, 'Q486296'), ('Shehadeh', 454, 'Q6836562'), ('Bakersfield, California', 558, 'Q49256')], 'fn_errors': [('Calif.', 129, 'Q99'), ('Bakersfield', 558, 'Q49256'), ('California', 571, 'Q99'), ('Islamic scholar', 1245, 'Q189459'), ('U.S. war', 1482, 'Q7892570')]}, {'doc_title': 'Gerald Ford laid to ', 'fp_errors': [('Mich', 119, 'Q1166'), ('California', 291, 'Q99'), ('American', 674, 'Q42537'), ('Ford', 1067, 'Q213122'), ('Bush', 1486, 'Q207')], 'fn_errors': [('Mich.', 119, 'Q1166'), ('California desert', 291, 'Q5264114'), ('Vice President', 599, 'Q11699'), ('American flag', 674, 'Q42537'), ('Ford', 1067, 'Q9582')]}, {'doc_title': \"What we'll want in a\", 'fp_errors': [('American', 40, 'Q30'), ('George W. Bush', 453, 'Q207'), ('Americans', 766, 'Q846570'), (\"Richard Nixon's\", 1229, 'Q9588'), ('Americans', 1334, 'Q846570')], 'fn_errors': [('President George W. Bush', 443, 'Q207'), ('Richard Nixon', 1229, 'Q9588'), ('American people', 1453, 'Q846570'), ('Washington', 1662, 'Q61'), ('Washington', 2218, 'Q61')]}, {'doc_title': 'Al-Maliki adviser sa', 'fp_errors': [(\"Saddam Hussein's\", 224, 'Q1316'), ('Iraqi', 384, 'Q796'), ('The Associated Press', 1125, 'Q40469'), ('U.S.', 1463, 'Q30'), ('the United States', 1504, 'Q30')], 'fn_errors': [('Saddam Hussein', 224, 'Q1316'), ('Iraqi forces', 858, 'Q897614'), ('Internet', 1074, 'Q75'), ('Associated Press', 1129, 'Q40469'), ('U.S. military', 1463, 'Q11211')]}, {'doc_title': 'Hindus throng to Gan', 'fp_errors': [('the Ganges river', 247, 'Q5089'), ('India', 276, 'Q668'), ('Hindu', 795, 'Q10090'), ('the \"Maha Kumbh Mela', 971, 'Q10283'), ('Hindus', 1056, 'Q10090')], 'fn_errors': [('Pilgrims', 45, 'Q542704'), ('Ganges river', 251, 'Q5089'), ('northern India', 267, 'Q1058785'), ('Hindu scriptures', 795, 'Q1194040'), ('Maha Kumbh Mela', 976, 'Q10283')]}], example_errors_md=[{'doc_title': 'Stocks end back-and-', 'fp_errors_md': [('the New York Stock Exchange', 307, 'MENTION'), ('U.S.', 751, 'MENTION'), ('Home Depot Inc.,', 1102, 'MENTION'), ('U.S.', 1769, 'MENTION'), ('Fed', 1878, 'MENTION')], 'fn_errors_md': [('New York Stock Exchange', 311, 'MENTION'), ('Home Depot Inc.', 1102, 'MENTION'), ('The Fed', 1874, 'MENTION'), ('Labor Department', 2129, 'MENTION'), ('Oklahoma City', 2415, 'MENTION')]}, {'doc_title': 'Home Depot CEO Narde', 'fp_errors_md': [('Nardelli', 263, 'MENTION'), (\"The Home Depot Inc.'s\", 288, 'MENTION'), ('Atlanta-based', 561, 'MENTION'), ('D-', 829, 'MENTION'), ('Mass', 831, 'MENTION')], 'fn_errors_md': [('The Home Depot Inc.', 288, 'MENTION'), ('Atlanta', 561, 'MENTION'), ('Home Depot', 1144, 'MENTION'), ('General Electric Co.', 2671, 'MENTION'), ('Home Depot', 3168, 'MENTION')]}, {'doc_title': 'Timberlake, Diaz rep', 'fp_errors_md': [('Star', 179, 'MENTION'), ('Colo', 264, 'MENTION')], 'fn_errors_md': [('Star magazine', 179, 'MENTION'), ('Christmas', 229, 'MENTION'), ('Colo.', 264, 'MENTION')]}, {'doc_title': 'Barbara Walters stan', 'fp_errors_md': [('View', 43, 'MENTION'), ('Donald', 731, 'MENTION')], 'fn_errors_md': [('The Donald', 727, 'MENTION')]}, {'doc_title': 'Resolution to imbibe', 'fp_errors_md': [('the Mayo Clinic', 799, 'MENTION'), ('the Goteborg University', 2015, 'MENTION'), ('r', 2175, 'MENTION'), (\"non-Hodgkin's lymphoma\", 2480, 'MENTION'), ('the University of Missouri', 2744, 'MENTION')], 'fn_errors_md': [('Mayo Clinic', 803, 'MENTION'), ('Goteborg University', 2019, 'MENTION'), (\"Hodgkin's lymphoma\", 2484, 'MENTION'), ('University of Missouri', 2748, 'MENTION')]}, {'doc_title': 'Health insurance bri', 'fp_errors_md': [('Ala', 129, 'MENTION'), ('U.S.', 287, 'MENTION'), ('the Child Caring Foundation', 673, 'MENTION'), ('the United States', 1113, 'MENTION'), ('the Kaiser Commission on Medicaid and the Uninsured', 1447, 'MENTION')], 'fn_errors_md': [('Ala.', 129, 'MENTION'), ('U.S. government', 287, 'MENTION'), ('Child Caring Foundation', 677, 'MENTION'), ('United States', 1117, 'MENTION'), ('Washington', 1502, 'MENTION')]}, {'doc_title': 'TUSCALOOSA, Ala. - N', 'fp_errors_md': [('Ala', 12, 'MENTION'), ('the Western Division', 1379, 'MENTION'), ('D-', 2156, 'MENTION'), ('Centre', 2158, 'MENTION'), ('House', 2180, 'MENTION')], 'fn_errors_md': [('Ala.', 12, 'MENTION'), ('University of Alabama', 2710, 'MENTION'), ('Quarterback', 3096, 'MENTION')]}, {'doc_title': 'Riley to have surger', 'fp_errors_md': [('Riles', 1847, 'MENTION'), ('Heat', 1964, 'MENTION'), ('NBA', 2121, 'MENTION'), ('1992-93 Detroit Pistons', 2149, 'MENTION'), ('NBA', 2368, 'MENTION')], 'fn_errors_md': [('Detroit Pistons', 2157, 'MENTION'), ('MVP', 3679, 'MENTION')]}, {'doc_title': '30 panda cubs born i', 'fp_errors_md': [('the State Forestry Administration', 382, 'MENTION'), ('the Xinhua News Agency', 441, 'MENTION'), ('the Wolong Giant Panda Protection and Research Center', 748, 'MENTION'), ('the Chengdu Research Base', 812, 'MENTION')], 'fn_errors_md': [('State Forestry Administration', 386, 'MENTION'), ('Xinhua News Agency', 445, 'MENTION'), ('Chengdu Research Base', 816, 'MENTION'), ('Giant pandas', 1064, 'MENTION')]}, {'doc_title': 'Upgrade makes aging ', 'fp_errors_md': [('Mars', 20, 'MENTION'), ('Mars', 131, 'MENTION'), ('the Red Planet', 409, 'MENTION')], 'fn_errors_md': [('Mars rovers', 20, 'MENTION'), ('Mars rovers', 131, 'MENTION'), ('Red Planet', 413, 'MENTION')]}, {'doc_title': '5 charged in Texas a', 'fp_errors_md': [('Houston', 570, 'MENTION'), ('Aguilar', 797, 'MENTION'), ('Harris County', 855, 'MENTION')], 'fn_errors_md': [('Police', 389, 'MENTION'), ('Harris County Jail', 855, 'MENTION')]}, {'doc_title': 'Thousands of holiday', 'fp_errors_md': [('London', 72, 'MENTION'), ('Heathrow Airport', 81, 'MENTION'), ('London', 230, 'MENTION'), ('Heathrow Airport', 239, 'MENTION'), ('Terminal 4', 387, 'MENTION')], 'fn_errors_md': [(\"London's Heathrow Airport\", 72, 'MENTION'), (\"London's Heathrow Airport\", 230, 'MENTION'), ('Christmas holiday', 735, 'MENTION')]}, {'doc_title': 'Five healthy resolut', 'fp_errors_md': [(\"New Year's\", 116, 'MENTION'), ('the', 299, 'MENTION'), ('the New Year', 484, 'MENTION'), ('the American Journal of Clinical Nutrition', 1240, 'MENTION'), ('Sara Lee Food & Beverage', 1887, 'MENTION')], 'fn_errors_md': [(\"New Year's resolution\", 116, 'MENTION'), ('Nutritionist', 186, 'MENTION'), ('New Year', 488, 'MENTION'), ('LDL-Cholesterol', 813, 'MENTION'), ('HDL-Cholesterol', 845, 'MENTION')]}, {'doc_title': 'U.S. mines still not', 'fp_errors_md': [('Sago Mine', 61, 'MENTION'), ('W. Va.', 126, 'MENTION'), ('the Sago Mine', 234, 'MENTION'), (\"West Virginia's\", 1261, 'MENTION')], 'fn_errors_md': [('Sago Mine accident', 61, 'MENTION'), ('W. Va', 126, 'MENTION'), ('Sago Mine', 238, 'MENTION'), ('West Virginia', 1261, 'MENTION')]}, {'doc_title': 'Chertoff pledges to ', 'fp_errors_md': [('Homeland', 43, 'MENTION'), ('Sept. 11, 2001', 977, 'MENTION'), ('Sept. 11', 1302, 'MENTION'), ('Washington, D.C.,', 1989, 'MENTION'), ('S.D', 2075, 'MENTION')], 'fn_errors_md': [('Washington', 1989, 'MENTION'), ('D.C.', 2001, 'MENTION'), ('S.D.', 2075, 'MENTION'), ('Wyo.', 2101, 'MENTION'), ('La.', 2165, 'MENTION')]}, {'doc_title': 'Muslim with U.S. fam', 'fp_errors_md': [('Calif', 129, 'MENTION'), ('German', 140, 'MENTION'), ('anti-Muslim', 426, 'MENTION'), ('Bakersfield, California', 558, 'MENTION'), ('American-born', 593, 'MENTION')], 'fn_errors_md': [('Calif.', 129, 'MENTION'), ('Bakersfield', 558, 'MENTION'), ('California', 571, 'MENTION'), ('Islamic scholar', 1245, 'MENTION'), ('U.S. war', 1482, 'MENTION')]}, {'doc_title': 'Gerald Ford laid to ', 'fp_errors_md': [('Mich', 119, 'MENTION'), ('California', 291, 'MENTION'), ('American', 674, 'MENTION'), ('Bush', 1486, 'MENTION'), ('Navy', 1683, 'MENTION')], 'fn_errors_md': [('Mich.', 119, 'MENTION'), ('California desert', 291, 'MENTION'), ('Vice President', 599, 'MENTION'), ('American flag', 674, 'MENTION'), ('President Bush', 1476, 'MENTION')]}, {'doc_title': \"What we'll want in a\", 'fp_errors_md': [('American', 40, 'MENTION'), ('George W. Bush', 453, 'MENTION'), ('Americans', 766, 'MENTION'), (\"Richard Nixon's\", 1229, 'MENTION'), ('Americans', 1334, 'MENTION')], 'fn_errors_md': [('President George W. Bush', 443, 'MENTION'), ('Richard Nixon', 1229, 'MENTION'), ('American people', 1453, 'MENTION'), ('Washington', 1662, 'MENTION'), ('Bush campaign', 2801, 'MENTION')]}, {'doc_title': 'Al-Maliki adviser sa', 'fp_errors_md': [(\"Saddam Hussein's\", 224, 'MENTION'), ('Iraqi', 384, 'MENTION'), ('Iraqi', 858, 'MENTION'), ('The Associated Press', 1125, 'MENTION'), ('U.S.', 1463, 'MENTION')], 'fn_errors_md': [('Saddam Hussein', 224, 'MENTION'), ('Iraqi forces', 858, 'MENTION'), ('Internet', 1074, 'MENTION'), ('Associated Press', 1129, 'MENTION'), ('U.S. military', 1463, 'MENTION')]}, {'doc_title': 'Hindus throng to Gan', 'fp_errors_md': [('the Ganges river', 247, 'MENTION'), ('India', 276, 'MENTION'), ('Hindu', 795, 'MENTION'), ('the \"Maha Kumbh Mela', 971, 'MENTION'), ('the Great Pitcher Festival', 996, 'MENTION')], 'fn_errors_md': [('Pilgrims', 45, 'MENTION'), ('Ganges river', 251, 'MENTION'), ('northern India', 267, 'MENTION'), ('Hindu scriptures', 795, 'MENTION'), ('Maha Kumbh Mela', 976, 'MENTION')]}])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined = Refined.from_pretrained(model_name='wikipedia_model',\n",
    "                                  entity_set='wikipedia',\n",
    "                                  use_precomputed_descriptions=True)\n",
    "print('EL results (with model fine-tuned on Wikipedia model)')\n",
    "eval_all(refined=refined, el=True, filter_nil_spans=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Disambiguation Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that the paper is based on with wikipedia entity set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-03 16:11:37.087168: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-03 16:11:37.120470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-03 16:11:37.120483: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Evaluating on AIDA: 0it [00:00, ?it/s]/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Evaluating on AIDA: 231it [00:59,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8744\n",
      "accuracy: 0.8483\n",
      "gold_recall: 0.9785\n",
      "p: 0.9021\n",
      "r: 0.8483\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:13,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9450\n",
      "accuracy: 0.9370\n",
      "gold_recall: 0.9954\n",
      "p: 0.9531\n",
      "r: 0.9370\n",
      "num_gold_spans: 651\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AQUAINT: 50it [00:13,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AQUAINT\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9191\n",
      "accuracy: 0.8892\n",
      "gold_recall: 0.9515\n",
      "p: 0.9511\n",
      "r: 0.8892\n",
      "num_gold_spans: 722\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on ACE2004: 36it [00:13,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: ACE2004\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9139\n",
      "accuracy: 0.8814\n",
      "gold_recall: 0.9091\n",
      "p: 0.9489\n",
      "r: 0.8814\n",
      "num_gold_spans: 253\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on CWEB: 186it [04:08,  1.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrefined\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eval_all\n\u001b[1;32m      4\u001b[0m refined \u001b[38;5;241m=\u001b[39m Refined\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwikipedia_model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                   entity_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m results_numbers \u001b[38;5;241m=\u001b[39m \u001b[43meval_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/evaluation/evaluation.py:180\u001b[0m, in \u001b[0;36meval_all\u001b[0;34m(refined, data_dir, datasets_dir, additional_data_dir, include_spans, filter_not_in_kb, ed_threshold, el, download, apply_class_check, filter_nil_spans)\u001b[0m\n\u001b[1;32m    174\u001b[0m datasets \u001b[38;5;241m=\u001b[39m get_datasets_obj(preprocessor\u001b[38;5;241m=\u001b[39mrefined\u001b[38;5;241m.\u001b[39mpreprocessor,\n\u001b[1;32m    175\u001b[0m                             data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m    176\u001b[0m                             datasets_dir\u001b[38;5;241m=\u001b[39mdatasets_dir,\n\u001b[1;32m    177\u001b[0m                             additional_data_dir\u001b[38;5;241m=\u001b[39madditional_data_dir,\n\u001b[1;32m    178\u001b[0m                             download\u001b[38;5;241m=\u001b[39mdownload)\n\u001b[1;32m    179\u001b[0m dataset_name_to_docs \u001b[38;5;241m=\u001b[39m get_standard_datasets(datasets, el, filter_not_in_kb, include_spans)\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_on_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefined\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset_name_to_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name_to_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mapply_class_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_class_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                            \u001b[49m\u001b[43med_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43med_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfilter_nil_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_nil_spans\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/evaluation/evaluation.py:261\u001b[0m, in \u001b[0;36mevaluate_on_datasets\u001b[0;34m(refined, dataset_name_to_docs, el, apply_class_check, ed_threshold, return_special_spans, filter_nil_spans)\u001b[0m\n\u001b[1;32m    259\u001b[0m dataset_name_to_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset_docs \u001b[38;5;129;01min\u001b[39;00m dataset_name_to_docs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 261\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_on_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefined\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43med_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43med_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_class_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_class_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_nil_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_nil_spans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter model predictions that align with md_spans that have no\u001b[39;49;00m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# gold_entity_id but are annotated/labelled as mentions in the dataset.\u001b[39;49;00m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_spans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     dataset_name_to_metrics[dataset_name] \u001b[38;5;241m=\u001b[39m metrics\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****************************\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/evaluation/evaluation.py:145\u001b[0m, in \u001b[0;36mevaluate_on_docs\u001b[0;34m(refined, docs, progress_bar, dataset_name, ed_threshold, apply_class_check, el, sample_size, filter_nil_spans, return_special_spans)\u001b[0m\n\u001b[1;32m    141\u001b[0m overall_metrics \u001b[38;5;241m=\u001b[39m Metrics\u001b[38;5;241m.\u001b[39mzeros(el\u001b[38;5;241m=\u001b[39mel)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_idx, doc \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(docs)), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress_bar, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m ):\n\u001b[0;32m--> 145\u001b[0m     doc_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_annotated_document\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefined\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43med_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43med_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_class_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_class_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_nil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_nil_spans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_spans\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     overall_metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m doc_metrics\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m doc_idx \u001b[38;5;241m>\u001b[39m sample_size:\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/evaluation/evaluation.py:56\u001b[0m, in \u001b[0;36mprocess_annotated_document\u001b[0;34m(refined, doc, el, ed_threshold, force_prediction, apply_class_check, filter_nil, return_special_spans)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m span\u001b[38;5;241m.\u001b[39mgold_entity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m span\u001b[38;5;241m.\u001b[39mgold_entity\u001b[38;5;241m.\u001b[39mwikidata_entity_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m             nil_spans\u001b[38;5;241m.\u001b[39madd((span\u001b[38;5;241m.\u001b[39mtext, span\u001b[38;5;241m.\u001b[39mstart))\n\u001b[0;32m---> 56\u001b[0m predicted_spans \u001b[38;5;241m=\u001b[39m \u001b[43mrefined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspans\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapply_class_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_class_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprune_ner_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_spans\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# only set to True if the dataset has special spans (e.g. dates)\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m pred_spans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m predicted_spans:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# skip dates and numbers, only consider entities that are linked to a KB\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# pred_spans is used for linkable mentions only\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/inference/processor.py:180\u001b[0m, in \u001b[0;36mRefined.process_text\u001b[0;34m(self, text, spans, ner_threshold, prune_ner_types, max_batch_size, apply_class_check, return_special_spans)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tns):\n\u001b[0;32m--> 180\u001b[0m     batch_spans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mner_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mner_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mreturn_special_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_spans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     all_spans\u001b[38;5;241m.\u001b[39mextend(batch_spans)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prune_ner_types:\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/inference/processor.py:303\u001b[0m, in \u001b[0;36mRefined.process_tensors\u001b[0;34m(self, batch, ner_threshold, return_special_spans)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_mode():\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;66;03m# if not end to end then spans do not need to be returned\u001b[39;00m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m (spans \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(spans) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), (\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gpu must be 1 when spans are not \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         )\n\u001b[0;32m--> 303\u001b[0m         output: ModelReturn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m spans \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mentity_spans\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_special_spans:\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/refined/model_components/refined_model.py:210\u001b[0m, in \u001b[0;36mRefinedModel.forward\u001b[0;34m(self, batch, batch_elements_included)\u001b[0m\n\u001b[1;32m    206\u001b[0m current_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(batch\u001b[38;5;241m.\u001b[39mtoken_id_values\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# forward pass of transformer's (e.g. BERT) layers\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# unpacking does not work for object\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m output: BaseModelOutputWithPoolingAndCrossAttentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_id_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_mask_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_type_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m contextualised_embeddings \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# forward pass of mention detection layer\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:851\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    842\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    844\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    845\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    846\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    849\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    850\u001b[0m )\n\u001b[0;32m--> 851\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    864\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:526\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    517\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    518\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    519\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:453\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    450\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    451\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 453\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:466\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    465\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 466\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:378\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    377\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 378\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(hidden_states)\n\u001b[1;32m    379\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/nn/modules/module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1698\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "from refined.evaluation.evaluation import eval_all\n",
    "\n",
    "refined = Refined.from_pretrained(model_name='wikipedia_model',\n",
    "                                  entity_set=\"wikipedia\")\n",
    "\n",
    "results_numbers = eval_all(refined=refined, el=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that the paper is based on with wikidata entity set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-16 17:34:38.786231: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-16 17:34:38.788973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-16 17:34:38.788982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Downloading /home/gplsi/.cache/refined/wikidata_data/qcode_to_wiki.lmdb: 100%|██████████| 580M/580M [00:53<00:00, 10.9MB/s] \n",
      "Downloading /home/gplsi/.cache/refined/wikidata_data/nltk_sentence_splitter_english.pickle: 100%|██████████| 407k/407k [00:00<00:00, 729kB/s]\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Evaluating on AIDA: 231it [00:17, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8570\n",
      "accuracy: 0.8150\n",
      "gold_recall: 0.9787\n",
      "p: 0.9036\n",
      "r: 0.8150\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:02,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9297\n",
      "accuracy: 0.9140\n",
      "gold_recall: 0.9923\n",
      "p: 0.9459\n",
      "r: 0.9140\n",
      "num_gold_spans: 651\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AQUAINT: 50it [00:03, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AQUAINT\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9041\n",
      "accuracy: 0.8684\n",
      "gold_recall: 0.9418\n",
      "p: 0.9429\n",
      "r: 0.8684\n",
      "num_gold_spans: 722\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on ACE2004: 36it [00:01, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: ACE2004\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9110\n",
      "accuracy: 0.8696\n",
      "gold_recall: 0.9130\n",
      "p: 0.9565\n",
      "r: 0.8696\n",
      "num_gold_spans: 253\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on CWEB: 320it [00:57,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: CWEB\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7669\n",
      "accuracy: 0.7061\n",
      "gold_recall: 0.9490\n",
      "p: 0.8392\n",
      "r: 0.7061\n",
      "num_gold_spans: 11038\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on WIKI: 320it [00:37,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: WIKI\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8814\n",
      "accuracy: 0.8435\n",
      "gold_recall: 0.9356\n",
      "p: 0.9228\n",
      "r: 0.8435\n",
      "num_gold_spans: 6773\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "from refined.evaluation.evaluation import eval_all\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "refined = Refined.from_pretrained(model_name='wikipedia_model',\n",
    "                                  entity_set=\"wikidata\")\n",
    "\n",
    "results_numbers = eval_all(refined=refined, el=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that the paper is based on with spacy types and wikipedia entity set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Evaluating on AIDA: 231it [00:11, 20.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8525\n",
      "accuracy: 0.8432\n",
      "gold_recall: 0.9785\n",
      "p: 0.8621\n",
      "r: 0.8432\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:01, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9375\n",
      "accuracy: 0.9339\n",
      "gold_recall: 0.9954\n",
      "p: 0.9412\n",
      "r: 0.9339\n",
      "num_gold_spans: 651\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AQUAINT: 50it [00:01, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AQUAINT\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9086\n",
      "accuracy: 0.8809\n",
      "gold_recall: 0.9515\n",
      "p: 0.9381\n",
      "r: 0.8809\n",
      "num_gold_spans: 722\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on ACE2004: 36it [00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: ACE2004\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9165\n",
      "accuracy: 0.8893\n",
      "gold_recall: 0.9091\n",
      "p: 0.9454\n",
      "r: 0.8893\n",
      "num_gold_spans: 253\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on CWEB: 320it [00:28, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: CWEB\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7718\n",
      "accuracy: 0.7473\n",
      "gold_recall: 0.9587\n",
      "p: 0.7979\n",
      "r: 0.7473\n",
      "num_gold_spans: 11038\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on WIKI: 320it [00:17, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: WIKI\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8956\n",
      "accuracy: 0.8769\n",
      "gold_recall: 0.9374\n",
      "p: 0.9151\n",
      "r: 0.8769\n",
      "num_gold_spans: 6773\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "from refined.evaluation.evaluation import eval_all\n",
    "\n",
    "refined = Refined.from_pretrained(model_name='wikipedia_model_with_numbers',\n",
    "                                  entity_set=\"wikipedia\")\n",
    "\n",
    "results_numbers = eval_all(refined=refined, el=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that the paper is based on with spacy types and wikidata entity set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading /home/gplsi/.cache/refined/wikipedia_model_with_numbers/precomputed_entity_descriptions_emb_wikidata_33831487-300.np: 100%|██████████| 20.3G/20.3G [29:32<00:00, 11.5MB/s]  \n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Evaluating on AIDA: 231it [00:17, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AIDA\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8501\n",
      "accuracy: 0.8374\n",
      "gold_recall: 0.9787\n",
      "p: 0.8633\n",
      "r: 0.8374\n",
      "num_gold_spans: 4464\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on MSNBC: 20it [00:02,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: MSNBC\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9396\n",
      "accuracy: 0.9324\n",
      "gold_recall: 0.9923\n",
      "p: 0.9470\n",
      "r: 0.9324\n",
      "num_gold_spans: 651\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on AQUAINT: 50it [00:04, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: AQUAINT\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9005\n",
      "accuracy: 0.8712\n",
      "gold_recall: 0.9418\n",
      "p: 0.9319\n",
      "r: 0.8712\n",
      "num_gold_spans: 722\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on ACE2004: 36it [00:02, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: ACE2004\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.9139\n",
      "accuracy: 0.8814\n",
      "gold_recall: 0.9130\n",
      "p: 0.9489\n",
      "r: 0.8814\n",
      "num_gold_spans: 253\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on CWEB: 320it [01:02,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: CWEB\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.7628\n",
      "accuracy: 0.7311\n",
      "gold_recall: 0.9490\n",
      "p: 0.7973\n",
      "r: 0.7311\n",
      "num_gold_spans: 11038\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on WIKI: 320it [00:40,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "\n",
      "\n",
      "Dataset name: WIKI\n",
      "\n",
      "****************\n",
      "************\n",
      "f1: 0.8884\n",
      "accuracy: 0.8671\n",
      "gold_recall: 0.9356\n",
      "p: 0.9108\n",
      "r: 0.8671\n",
      "num_gold_spans: 6773\n",
      "************\n",
      "\n",
      "*****************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "from refined.evaluation.evaluation import eval_all\n",
    "\n",
    "refined = Refined.from_pretrained(model_name='wikipedia_model_with_numbers',\n",
    "                                  entity_set=\"wikidata\")\n",
    "\n",
    "results_numbers = eval_all(refined=refined, el=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Relation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonando en 'rebel'...\n",
      "remote: Enumerating objects: 150, done.\u001b[K\n",
      "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
      "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
      "remote: Total 150 (delta 55), reused 30 (delta 29), pack-reused 73\u001b[K\n",
      "Recibiendo objetos: 100% (150/150), 788.75 KiB | 3.81 MiB/s, listo.\n",
      "Resolviendo deltas: 100% (75/75), listo.\n"
     ]
    }
   ],
   "source": [
    "#! git clone https://github.com/Babelscape/rebel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env bash\n",
    "\"\"\"\n",
    "curr_dir=$(pwd)\n",
    "\n",
    "wget -r -nH --cut-dirs=100 --reject \"index.html*\" --no-parent http://lavis.cs.hs-rm.de/storage/spert/public/datasets/conll04/ -P ${curr_dir}/data/conll04\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./fetch_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ! pip install --upgrade huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning==1.1.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning with CONLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebel/src/train.py:105: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../conf', config_name='root')\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Global seed set to 42\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[2024-05-22 12:22:52,093][datasets.builder][WARNING] - Using custom data configuration default-3e0c71a39afdfa4e\n",
      "[2024-05-22 12:22:52,094][datasets.builder][WARNING] - Reusing dataset conl_l04 (/home/gplsi/.cache/huggingface/datasets/conl_l04/default-3e0c71a39afdfa4e/0.0.0/87090529d4f9584f9643d0dff3797eec01bcdb028753cb95de9e0445c48d8b32)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "[2024-05-22 12:22:53,346][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/conll04/conll04_train.jsonconll04_typed.cache\n",
      "[2024-05-22 12:22:54,502][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/conll04/conll04_dev.jsonconll04_typed.cache\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name    | Type                         | Params\n",
      "---------------------------------------------------------\n",
      "0 | model   | BartForConditionalGeneration | 406 M \n",
      "1 | loss_fn | CrossEntropyLoss             | 0     \n",
      "---------------------------------------------------------\n",
      "406 M     Trainable params\n",
      "0         Non-trainable params\n",
      "406 M     Total params\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:01<00:00,  1.80it/s]RE Evaluation in *** STRICT *** mode\n",
      "processed 16 sentences with 22 relations; found: 0 relations; correct: 0.\n",
      "\tALL\t TP: 0;\tFP: 0;\tFN: 22\n",
      "\t\t(m avg): precision: 0.00;\trecall: 0.00;\tf1: 0.00 (micro)\n",
      "\t\t(M avg): precision: 0.00;\trecall: 0.00;\tf1: 0.00 (Macro)\n",
      "\n",
      "\tkilled by: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tresidence: \tTP: 0;\tFP: 0;\tFN: 7;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation: \tTP: 0;\tFP: 0;\tFN: 8;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\theadquarters location: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\temployer: \tTP: 0;\tFP: 0;\tFN: 3;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   1%|           | 1/145 [00:00<00:21,  6.64it/s, loss=12.4, v_num=WYaV]/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch 0:  49%|████▉     | 71/145 [00:15<00:16,  4.53it/s, loss=1.79, v_num=WYaV]^C\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint...\n",
      "Error executing job with overrides: ['data=conll04_data', 'train=conll04_train']\n",
      "Traceback (most recent call last):\n",
      "  File \"rebel/src/train.py\", line 111, in <module>\n",
      "    main()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"rebel/src/train.py\", line 107, in main\n",
      "    train(conf)\n",
      "  File \"rebel/src/train.py\", line 103, in train\n",
      "    trainer.fit(pl_module, datamodule=pl_data_module)\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 510, in fit\n",
      "    results = self.accelerator_backend.train()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 57, in train\n",
      "    return self.train_or_test()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 74, in train_or_test\n",
      "    results = self.trainer.train()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 592, in train\n",
      "    self.train_loop.on_train_end()\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 156, in on_train_end\n",
      "    self.check_checkpoint_callback(should_save=True, is_last=True)\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 190, in check_checkpoint_callback\n",
      "    callback.on_validation_end(self.trainer, model)\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 204, in on_validation_end\n",
      "    self.save_checkpoint(trainer, pl_module)\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 239, in save_checkpoint\n",
      "    self._validate_monitor_key(trainer)\n",
      "  File \"/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 517, in _validate_monitor_key\n",
      "    raise MisconfigurationException(m)\n",
      "pytorch_lightning.utilities.exceptions.MisconfigurationException: ModelCheckpoint(monitor='val_F1_micro') not found in the returned metrics: ['loss']. HINT: Did you call self.log('val_F1_micro', tensor) in the LightningModule?\n",
      "Epoch 0:  49%|████▉     | 71/145 [00:15<00:16,  4.48it/s, loss=1.79, v_num=WYaV]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'  # or 'true', depending on your preference\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "os.environ[\"HYDRA_FULL_ERROR\"]=\"1\"\n",
    "! python3 rebel/src/train.py  data=conll04_data train=conll04_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebel/src/test.py:112: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../conf', config_name='root')\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Global seed set to 42\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-05-22 12:23:45,316][datasets.builder][WARNING] - Using custom data configuration default-3e0c71a39afdfa4e\n",
      "[2024-05-22 12:23:45,317][datasets.builder][WARNING] - Reusing dataset conl_l04 (/home/gplsi/.cache/huggingface/datasets/conl_l04/default-3e0c71a39afdfa4e/0.0.0/87090529d4f9584f9643d0dff3797eec01bcdb028753cb95de9e0445c48d8b32)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "[2024-05-22 12:23:49,386][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/conll04/conll04_train.jsonconll04_typed.cache\n",
      "[2024-05-22 12:23:50,614][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/conll04/conll04_dev.jsonconll04_typed.cache\n",
      "[2024-05-22 12:23:51,833][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/conll04/conll04_test.jsonconll04_typed.cache\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Testing: 100%|██████████████████████████████████| 36/36 [00:20<00:00,  2.47it/s]RE Evaluation in *** STRICT *** mode\n",
      "processed 288 sentences with 421 relations; found: 369 relations; correct: 272.\n",
      "\tALL\t TP: 272;\tFP: 96;\tFN: 134\n",
      "\t\t(m avg): precision: 73.91;\trecall: 67.00;\tf1: 70.28 (micro)\n",
      "\t\t(M avg): precision: 75.50;\trecall: 69.39;\tf1: 72.00 (Macro)\n",
      "\n",
      "\tkilled by: \tTP: 42;\tFP: 5;\tFN: 5;\tprecision: 89.36;\trecall: 89.36;\tf1: 89.36;\t47\n",
      "\tresidence: \tTP: 68;\tFP: 32;\tFN: 30;\tprecision: 68.00;\trecall: 69.39;\tf1: 68.69;\t100\n",
      "\tlocation: \tTP: 60;\tFP: 13;\tFN: 29;\tprecision: 82.19;\trecall: 67.42;\tf1: 74.07;\t73\n",
      "\theadquarters location: \tTP: 49;\tFP: 21;\tFN: 47;\tprecision: 70.00;\trecall: 51.04;\tf1: 59.04;\t70\n",
      "\temployer: \tTP: 53;\tFP: 25;\tFN: 23;\tprecision: 67.95;\trecall: 69.74;\tf1: 68.83;\t78\n",
      "Testing: 100%|██████████████████████████████████| 36/36 [00:20<00:00,  1.79it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_F1_micro': 70.2842377260982,\n",
      " 'test_loss': 0.1828836053609848,\n",
      " 'test_prec_micro': 73.91304347826087,\n",
      " 'test_recall_micro': 66.99507389162562}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "!python3 rebel/src/test.py model=rebel_model data=conll04_data train=conll04_train do_predict=True checkpoint_path=\"/home/gplsi/Escritorio/experiments/conll04/last.ckpt\"\n",
    "#python3 test.py model=rebel_model data=conll04_data train=conll04_train do_predict=True checkpoint_path=\"/home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/experiments/conll04/last.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning with DOCRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebel/src/train.py:105: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../conf', config_name='root')\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Global seed set to 42\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[2024-05-22 12:59:44,341][datasets.builder][WARNING] - Using custom data configuration default-74034df2e7d75055\n",
      "[2024-05-22 12:59:44,342][datasets.builder][WARNING] - Reusing dataset doc_red (/home/gplsi/.cache/huggingface/datasets/doc_red/default-74034df2e7d75055/0.0.0/2cc6999b276b6aa2b2af5101b416c33155e5f19e6f0b26864a2312d1aa57b175)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "[2024-05-22 12:59:45,639][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/docred/train_joint.jsondocred_typed.cache\n",
      "[2024-05-22 12:59:46,810][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/docred/dev_joint.jsondocred_typed.cache\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name    | Type                         | Params\n",
      "---------------------------------------------------------\n",
      "0 | model   | BartForConditionalGeneration | 406 M \n",
      "1 | loss_fn | CrossEntropyLoss             | 0     \n",
      "---------------------------------------------------------\n",
      "406 M     Trainable params\n",
      "0         Non-trainable params\n",
      "406 M     Total params\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:04<00:00,  2.41s/it]RE Evaluation in *** STRICT *** mode\n",
      "processed 8 sentences with 95 relations; found: 0 relations; correct: 0.\n",
      "\tALL\t TP: 0;\tFP: 0;\tFN: 95\n",
      "\t\t(m avg): precision: 0.00;\trecall: 0.00;\tf1: 0.00 (micro)\n",
      "\t\t(M avg): precision: 0.00;\trecall: 0.00;\tf1: 0.00 (Macro)\n",
      "\n",
      "\thead of government: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry: \tTP: 0;\tFP: 0;\tFN: 22;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tplace of birth: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tplace of death: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfather: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmother: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tspouse: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry of citizenship: \tTP: 0;\tFP: 0;\tFN: 20;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcontinent: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tinstance of: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thead of state: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcapital: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tofficial language: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tposition held: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tchild: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tauthor: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmember of sports team: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdirector: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tscreenwriter: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\teducated at: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcomposer: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmember of political party: \tTP: 0;\tFP: 0;\tFN: 3;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\temployer: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfounded by: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tleague: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpublisher: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\towned by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in the administrative territorial entity: \tTP: 0;\tFP: 0;\tFN: 13;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tgenre: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toperator: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treligion: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcontains administrative territorial entity: \tTP: 0;\tFP: 0;\tFN: 7;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfollows: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfollowed by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\theadquarters location: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcast member: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproducer: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\taward received: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcreator: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparent taxon: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tethnic group: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tperformer: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmanufacturer: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdeveloper: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tseries: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsister city: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlegislative body: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tbasin country: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in or next to body of water: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmilitary branch: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\trecord label: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproduction company: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubclass of: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubsidiary: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpart of: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toriginal language of work: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tplatform: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmouth of the watercourse: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toriginal network: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmember of: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tchairperson: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry of origin: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thas part: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tresidence: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdate of birth: \tTP: 0;\tFP: 0;\tFN: 7;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdate of death: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tinception: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdissolved, abolished or demolished: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpublication date: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tstart time: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tend time: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpoint in time: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tconflict: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcharacters: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlyrics by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated on terrain feature: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparticipant: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tinfluenced by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation of formation: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparent organization: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnotable work: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tseparated from: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnarrative location: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\twork location: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tapplies to jurisdiction: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproduct or material produced: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tunemployment rate: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tterritory claimed by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparticipant of: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treplaces: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treplaced by: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcapital of: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlanguages spoken, written or signed: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpresent in work: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsibling: \tTP: 0;\tFP: 0;\tFN: 0;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|          | 1/1579 [00:00<04:07,  6.37it/s, loss=7.93, v_num=k39m]/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch 0:  95%|██████▋| 1504/1579 [05:34<00:16,  4.50it/s, loss=0.45, v_num=k39m]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/75 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  95%|██████▋| 1506/1579 [05:37<00:16,  4.47it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:   3%|▊                               | 2/75 [00:04<02:39,  2.18s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1508/1579 [05:41<00:16,  4.41it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:   5%|█▋                              | 4/75 [00:09<02:39,  2.25s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1510/1579 [05:46<00:15,  4.36it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:   8%|██▌                             | 6/75 [00:14<02:42,  2.36s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1512/1579 [05:51<00:15,  4.30it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  11%|███▍                            | 8/75 [00:19<02:49,  2.54s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1514/1579 [05:56<00:15,  4.24it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  13%|████▏                          | 10/75 [00:24<02:41,  2.49s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1516/1579 [06:01<00:15,  4.19it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  16%|████▉                          | 12/75 [00:29<02:42,  2.57s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1518/1579 [06:06<00:14,  4.14it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  19%|█████▊                         | 14/75 [00:34<02:36,  2.57s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1520/1579 [06:12<00:14,  4.09it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  21%|██████▌                        | 16/75 [00:40<02:31,  2.57s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 1522/1579 [06:17<00:14,  4.04it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  24%|███████▍                       | 18/75 [00:45<02:26,  2.57s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1524/1579 [06:22<00:13,  3.99it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  27%|████████▎                      | 20/75 [00:50<02:19,  2.54s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1526/1579 [06:27<00:13,  3.94it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  29%|█████████                      | 22/75 [00:55<02:16,  2.58s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1528/1579 [06:32<00:13,  3.89it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  32%|█████████▉                     | 24/75 [01:00<02:10,  2.56s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1530/1579 [06:37<00:12,  3.85it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  35%|██████████▋                    | 26/75 [01:05<01:58,  2.42s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1532/1579 [06:42<00:12,  3.81it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  37%|███████████▌                   | 28/75 [01:10<01:58,  2.52s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1534/1579 [06:47<00:11,  3.76it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  40%|████████████▍                  | 30/75 [01:15<01:54,  2.54s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1536/1579 [06:52<00:11,  3.72it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 32/75 [01:20<01:50,  2.57s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 1538/1579 [06:57<00:11,  3.68it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  45%|██████████████                 | 34/75 [01:25<01:42,  2.51s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1540/1579 [07:02<00:10,  3.64it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  48%|██████████████▉                | 36/75 [01:31<01:42,  2.63s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1542/1579 [07:08<00:10,  3.60it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  51%|███████████████▋               | 38/75 [01:36<01:35,  2.57s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1544/1579 [07:13<00:09,  3.56it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  53%|████████████████▌              | 40/75 [01:41<01:29,  2.57s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1546/1579 [07:18<00:09,  3.53it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  56%|█████████████████▎             | 42/75 [01:45<01:18,  2.39s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1548/1579 [07:23<00:08,  3.49it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 44/75 [01:51<01:17,  2.50s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 1550/1579 [07:28<00:08,  3.46it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  61%|███████████████████            | 46/75 [01:56<01:12,  2.51s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▉| 1552/1579 [07:33<00:07,  3.42it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  64%|███████████████████▊           | 48/75 [02:01<01:08,  2.53s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▉| 1554/1579 [07:38<00:07,  3.39it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 50/75 [02:06<01:04,  2.59s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1556/1579 [07:43<00:06,  3.36it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 52/75 [02:11<00:59,  2.57s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1558/1579 [07:47<00:06,  3.33it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  72%|██████████████████████▎        | 54/75 [02:15<00:49,  2.34s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1560/1579 [07:52<00:05,  3.30it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  75%|███████████████████████▏       | 56/75 [02:20<00:43,  2.32s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1562/1579 [07:57<00:05,  3.27it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  77%|███████████████████████▉       | 58/75 [02:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1564/1579 [08:01<00:04,  3.25it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  80%|████████████████████████▊      | 60/75 [02:29<00:36,  2.43s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1566/1579 [08:07<00:04,  3.21it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  83%|█████████████████████████▋     | 62/75 [02:34<00:31,  2.43s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1568/1579 [08:11<00:03,  3.19it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  85%|██████████████████████████▍    | 64/75 [02:39<00:27,  2.47s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 1570/1579 [08:16<00:02,  3.16it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  88%|███████████████████████████▎   | 66/75 [02:44<00:21,  2.38s/it]\u001b[A\n",
      "Epoch 0: 100%|██████▉| 1572/1579 [08:21<00:02,  3.13it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  91%|████████████████████████████   | 68/75 [02:49<00:17,  2.49s/it]\u001b[A\n",
      "Epoch 0: 100%|██████▉| 1574/1579 [08:26<00:01,  3.11it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  93%|████████████████████████████▉  | 70/75 [02:54<00:12,  2.51s/it]\u001b[A\n",
      "Epoch 0: 100%|██████▉| 1576/1579 [08:31<00:00,  3.08it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  96%|█████████████████████████████▊ | 72/75 [02:59<00:07,  2.48s/it]\u001b[A\n",
      "Epoch 0: 100%|██████▉| 1578/1579 [08:36<00:00,  3.06it/s, loss=0.45, v_num=k39m]\u001b[A\n",
      "Validating:  99%|██████████████████████████████▌| 74/75 [03:04<00:02,  2.46s/it]\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 75/75 [03:06<00:00,  2.46s/it]\u001b[ARE Evaluation in *** STRICT *** mode\n",
      "processed 300 sentences with 3515 relations; found: 242 relations; correct: 100.\n",
      "\tALL\t TP: 100;\tFP: 134;\tFN: 3404\n",
      "\t\t(m avg): precision: 42.74;\trecall: 2.85;\tf1: 5.35 (micro)\n",
      "\t\t(M avg): precision: 15.11;\trecall: 2.72;\tf1: 4.04 (Macro)\n",
      "\n",
      "\thead of government: \tTP: 0;\tFP: 1;\tFN: 20;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tcountry: \tTP: 12;\tFP: 31;\tFN: 734;\tprecision: 27.91;\trecall: 1.61;\tf1: 3.04;\t43\n",
      "\tplace of birth: \tTP: 4;\tFP: 2;\tFN: 52;\tprecision: 66.67;\trecall: 7.14;\tf1: 12.90;\t6\n",
      "\tplace of death: \tTP: 1;\tFP: 0;\tFN: 25;\tprecision: 100.00;\trecall: 3.85;\tf1: 7.41;\t1\n",
      "\tfather: \tTP: 0;\tFP: 5;\tFN: 17;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t5\n",
      "\tmother: \tTP: 0;\tFP: 1;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tspouse: \tTP: 0;\tFP: 0;\tFN: 30;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry of citizenship: \tTP: 5;\tFP: 15;\tFN: 257;\tprecision: 25.00;\trecall: 1.91;\tf1: 3.55;\t20\n",
      "\tcontinent: \tTP: 9;\tFP: 4;\tFN: 26;\tprecision: 69.23;\trecall: 25.71;\tf1: 37.50;\t13\n",
      "\tinstance of: \tTP: 0;\tFP: 0;\tFN: 19;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thead of state: \tTP: 0;\tFP: 0;\tFN: 29;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcapital: \tTP: 0;\tFP: 0;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tofficial language: \tTP: 0;\tFP: 0;\tFN: 8;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tposition held: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tchild: \tTP: 0;\tFP: 2;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t2\n",
      "\tauthor: \tTP: 0;\tFP: 3;\tFN: 36;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t3\n",
      "\tmember of sports team: \tTP: 1;\tFP: 1;\tFN: 19;\tprecision: 50.00;\trecall: 5.00;\tf1: 9.09;\t2\n",
      "\tdirector: \tTP: 0;\tFP: 1;\tFN: 36;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tscreenwriter: \tTP: 0;\tFP: 4;\tFN: 22;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t4\n",
      "\teducated at: \tTP: 2;\tFP: 2;\tFN: 38;\tprecision: 50.00;\trecall: 5.00;\tf1: 9.09;\t4\n",
      "\tcomposer: \tTP: 0;\tFP: 0;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmember of political party: \tTP: 0;\tFP: 0;\tFN: 38;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\temployer: \tTP: 1;\tFP: 0;\tFN: 20;\tprecision: 100.00;\trecall: 4.76;\tf1: 9.09;\t1\n",
      "\tfounded by: \tTP: 0;\tFP: 0;\tFN: 7;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tleague: \tTP: 5;\tFP: 0;\tFN: 8;\tprecision: 100.00;\trecall: 38.46;\tf1: 55.56;\t5\n",
      "\tpublisher: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\towned by: \tTP: 0;\tFP: 0;\tFN: 14;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in the administrative territorial entity: \tTP: 1;\tFP: 7;\tFN: 353;\tprecision: 12.50;\trecall: 0.28;\tf1: 0.55;\t8\n",
      "\tgenre: \tTP: 0;\tFP: 0;\tFN: 9;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toperator: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treligion: \tTP: 0;\tFP: 0;\tFN: 21;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcontains administrative territorial entity: \tTP: 0;\tFP: 2;\tFN: 204;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t2\n",
      "\tfollows: \tTP: 0;\tFP: 0;\tFN: 18;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfollowed by: \tTP: 0;\tFP: 0;\tFN: 17;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\theadquarters location: \tTP: 0;\tFP: 0;\tFN: 21;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcast member: \tTP: 0;\tFP: 0;\tFN: 74;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproducer: \tTP: 0;\tFP: 0;\tFN: 11;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\taward received: \tTP: 0;\tFP: 0;\tFN: 11;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcreator: \tTP: 0;\tFP: 0;\tFN: 19;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparent taxon: \tTP: 1;\tFP: 1;\tFN: 1;\tprecision: 50.00;\trecall: 50.00;\tf1: 50.00;\t2\n",
      "\tethnic group: \tTP: 0;\tFP: 0;\tFN: 11;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tperformer: \tTP: 1;\tFP: 2;\tFN: 92;\tprecision: 33.33;\trecall: 1.08;\tf1: 2.08;\t3\n",
      "\tmanufacturer: \tTP: 0;\tFP: 0;\tFN: 12;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdeveloper: \tTP: 1;\tFP: 0;\tFN: 34;\tprecision: 100.00;\trecall: 2.86;\tf1: 5.56;\t1\n",
      "\tseries: \tTP: 0;\tFP: 0;\tFN: 24;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsister city: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlegislative body: \tTP: 0;\tFP: 0;\tFN: 12;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tbasin country: \tTP: 0;\tFP: 0;\tFN: 9;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in or next to body of water: \tTP: 0;\tFP: 0;\tFN: 12;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmilitary branch: \tTP: 0;\tFP: 0;\tFN: 8;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\trecord label: \tTP: 2;\tFP: 0;\tFN: 55;\tprecision: 100.00;\trecall: 3.51;\tf1: 6.78;\t2\n",
      "\tproduction company: \tTP: 0;\tFP: 0;\tFN: 8;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation: \tTP: 0;\tFP: 0;\tFN: 13;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubclass of: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubsidiary: \tTP: 0;\tFP: 0;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpart of: \tTP: 1;\tFP: 0;\tFN: 33;\tprecision: 100.00;\trecall: 2.94;\tf1: 5.71;\t1\n",
      "\toriginal language of work: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tplatform: \tTP: 0;\tFP: 0;\tFN: 47;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmouth of the watercourse: \tTP: 0;\tFP: 0;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toriginal network: \tTP: 0;\tFP: 0;\tFN: 13;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmember of: \tTP: 0;\tFP: 4;\tFN: 27;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t4\n",
      "\tchairperson: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry of origin: \tTP: 0;\tFP: 0;\tFN: 34;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thas part: \tTP: 0;\tFP: 0;\tFN: 55;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tresidence: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdate of birth: \tTP: 23;\tFP: 15;\tFN: 94;\tprecision: 60.53;\trecall: 19.66;\tf1: 29.68;\t38\n",
      "\tdate of death: \tTP: 14;\tFP: 16;\tFN: 76;\tprecision: 46.67;\trecall: 15.56;\tf1: 23.33;\t30\n",
      "\tinception: \tTP: 1;\tFP: 3;\tFN: 30;\tprecision: 25.00;\trecall: 3.23;\tf1: 5.71;\t4\n",
      "\tdissolved, abolished or demolished: \tTP: 0;\tFP: 0;\tFN: 8;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpublication date: \tTP: 10;\tFP: 5;\tFN: 117;\tprecision: 66.67;\trecall: 7.87;\tf1: 14.08;\t15\n",
      "\tstart time: \tTP: 0;\tFP: 0;\tFN: 7;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tend time: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpoint in time: \tTP: 1;\tFP: 1;\tFN: 9;\tprecision: 50.00;\trecall: 10.00;\tf1: 16.67;\t2\n",
      "\tconflict: \tTP: 0;\tFP: 1;\tFN: 15;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tcharacters: \tTP: 0;\tFP: 0;\tFN: 22;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlyrics by: \tTP: 2;\tFP: 1;\tFN: 6;\tprecision: 66.67;\trecall: 25.00;\tf1: 36.36;\t3\n",
      "\tlocated on terrain feature: \tTP: 1;\tFP: 1;\tFN: 10;\tprecision: 50.00;\trecall: 9.09;\tf1: 15.38;\t2\n",
      "\tparticipant: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tinfluenced by: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation of formation: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparent organization: \tTP: 0;\tFP: 0;\tFN: 16;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnotable work: \tTP: 0;\tFP: 1;\tFN: 23;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tseparated from: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnarrative location: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\twork location: \tTP: 0;\tFP: 0;\tFN: 11;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tapplies to jurisdiction: \tTP: 0;\tFP: 0;\tFN: 17;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproduct or material produced: \tTP: 1;\tFP: 0;\tFN: 5;\tprecision: 100.00;\trecall: 16.67;\tf1: 28.57;\t1\n",
      "\tunemployment rate: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tterritory claimed by: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparticipant of: \tTP: 0;\tFP: 0;\tFN: 17;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treplaces: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treplaced by: \tTP: 0;\tFP: 0;\tFN: 3;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcapital of: \tTP: 0;\tFP: 0;\tFN: 5;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlanguages spoken, written or signed: \tTP: 0;\tFP: 0;\tFN: 23;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpresent in work: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsibling: \tTP: 0;\tFP: 2;\tFN: 26;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t2\n",
      "Epoch 0, global step 1503: val_F1_micro reached 5.35045 (best 5.35045), saving model to \"experiments/docred/epoch=0-step=1503.ckpt\" as top 3\n",
      "Epoch 0: 100%|███████| 1579/1579 [08:52<00:00,  2.96it/s, loss=0.45, v_num=k39m]\n",
      "Epoch 1:  31%|██▏    | 496/1579 [01:46<03:51,  4.67it/s, loss=0.327, v_num=k39m]Saving latest checkpoint...\n",
      "Epoch 1, global step 1999: val_F1_micro reached 5.35045 (best 5.35045), saving model to \"experiments/docred/epoch=1-step=1999.ckpt\" as top 3\n",
      "Epoch 1:  31%|██▏    | 496/1579 [01:57<04:17,  4.21it/s, loss=0.327, v_num=k39m]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'  # or 'true', depending on your preference\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "os.environ[\"HYDRA_FULL_ERROR\"]=\"1\"\n",
    "! python3 rebel/src/train.py  data=docred_data train=docred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebel/src/test.py:112: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../conf', config_name='root')\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Global seed set to 42\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-05-22 13:50:00,709][datasets.builder][WARNING] - Using custom data configuration default-74034df2e7d75055\n",
      "[2024-05-22 13:50:00,710][datasets.builder][WARNING] - Reusing dataset doc_red (/home/gplsi/.cache/huggingface/datasets/doc_red/default-74034df2e7d75055/0.0.0/2cc6999b276b6aa2b2af5101b416c33155e5f19e6f0b26864a2312d1aa57b175)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "[2024-05-22 13:50:04,829][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/docred/train_joint.jsondocred_typed.cache\n",
      "[2024-05-22 13:50:05,764][datasets.arrow_dataset][WARNING] - Loading cached processed dataset at /home/gplsi/Documentos/Master Ciencia de Datos/Minería de textos/entrega2/pruebas/rebel/data/docred/dev_joint.jsondocred_typed.cache\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.72ba/s]\n",
      "/home/gplsi/anaconda3/envs/ReBeL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Testing: 100%|████████████████████████████████| 117/117 [12:17<00:00,  5.67s/it]RE Evaluation in *** STRICT *** mode\n",
      "processed 700 sentences with 8301 relations; found: 531 relations; correct: 317.\n",
      "\tALL\t TP: 317;\tFP: 210;\tFN: 7923\n",
      "\t\t(m avg): precision: 60.15;\trecall: 3.85;\tf1: 7.23 (micro)\n",
      "\t\t(M avg): precision: 25.36;\trecall: 2.39;\tf1: 4.16 (Macro)\n",
      "\n",
      "\thead of government: \tTP: 1;\tFP: 1;\tFN: 29;\tprecision: 50.00;\trecall: 3.33;\tf1: 6.25;\t2\n",
      "\tcountry: \tTP: 44;\tFP: 28;\tFN: 1793;\tprecision: 61.11;\trecall: 2.40;\tf1: 4.61;\t72\n",
      "\tplace of birth: \tTP: 12;\tFP: 8;\tFN: 112;\tprecision: 60.00;\trecall: 9.68;\tf1: 16.67;\t20\n",
      "\tplace of death: \tTP: 1;\tFP: 0;\tFN: 37;\tprecision: 100.00;\trecall: 2.63;\tf1: 5.13;\t1\n",
      "\tfather: \tTP: 2;\tFP: 2;\tFN: 43;\tprecision: 50.00;\trecall: 4.44;\tf1: 8.16;\t4\n",
      "\tmother: \tTP: 0;\tFP: 0;\tFN: 18;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tspouse: \tTP: 2;\tFP: 4;\tFN: 55;\tprecision: 33.33;\trecall: 3.51;\tf1: 6.35;\t6\n",
      "\tcountry of citizenship: \tTP: 13;\tFP: 29;\tFN: 491;\tprecision: 30.95;\trecall: 2.58;\tf1: 4.76;\t42\n",
      "\tcontinent: \tTP: 5;\tFP: 13;\tFN: 65;\tprecision: 27.78;\trecall: 7.14;\tf1: 11.36;\t18\n",
      "\tinstance of: \tTP: 0;\tFP: 0;\tFN: 27;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thead of state: \tTP: 0;\tFP: 1;\tFN: 24;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tcapital: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tofficial language: \tTP: 0;\tFP: 0;\tFN: 32;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tposition held: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tchild: \tTP: 1;\tFP: 1;\tFN: 67;\tprecision: 50.00;\trecall: 1.47;\tf1: 2.86;\t2\n",
      "\tauthor: \tTP: 5;\tFP: 2;\tFN: 58;\tprecision: 71.43;\trecall: 7.94;\tf1: 14.29;\t7\n",
      "\tmember of sports team: \tTP: 9;\tFP: 6;\tFN: 102;\tprecision: 60.00;\trecall: 8.11;\tf1: 14.29;\t15\n",
      "\tdirector: \tTP: 2;\tFP: 0;\tFN: 52;\tprecision: 100.00;\trecall: 3.70;\tf1: 7.14;\t2\n",
      "\tscreenwriter: \tTP: 0;\tFP: 1;\tFN: 20;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\teducated at: \tTP: 4;\tFP: 2;\tFN: 54;\tprecision: 66.67;\trecall: 6.90;\tf1: 12.50;\t6\n",
      "\tcomposer: \tTP: 1;\tFP: 0;\tFN: 47;\tprecision: 100.00;\trecall: 2.08;\tf1: 4.08;\t1\n",
      "\tmember of political party: \tTP: 0;\tFP: 1;\tFN: 71;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\temployer: \tTP: 1;\tFP: 7;\tFN: 38;\tprecision: 12.50;\trecall: 2.56;\tf1: 4.26;\t8\n",
      "\tfounded by: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tleague: \tTP: 5;\tFP: 1;\tFN: 46;\tprecision: 83.33;\trecall: 9.80;\tf1: 17.54;\t6\n",
      "\tpublisher: \tTP: 2;\tFP: 0;\tFN: 27;\tprecision: 100.00;\trecall: 6.90;\tf1: 12.90;\t2\n",
      "\towned by: \tTP: 0;\tFP: 0;\tFN: 56;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in the administrative territorial entity: \tTP: 20;\tFP: 16;\tFN: 817;\tprecision: 55.56;\trecall: 2.39;\tf1: 4.58;\t36\n",
      "\tgenre: \tTP: 0;\tFP: 0;\tFN: 27;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toperator: \tTP: 0;\tFP: 0;\tFN: 26;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treligion: \tTP: 0;\tFP: 0;\tFN: 34;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcontains administrative territorial entity: \tTP: 5;\tFP: 5;\tFN: 428;\tprecision: 50.00;\trecall: 1.15;\tf1: 2.26;\t10\n",
      "\tfollows: \tTP: 0;\tFP: 0;\tFN: 58;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tfollowed by: \tTP: 0;\tFP: 0;\tFN: 51;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\theadquarters location: \tTP: 0;\tFP: 2;\tFN: 51;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t2\n",
      "\tcast member: \tTP: 30;\tFP: 2;\tFN: 107;\tprecision: 93.75;\trecall: 21.90;\tf1: 35.50;\t32\n",
      "\tproducer: \tTP: 0;\tFP: 0;\tFN: 33;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\taward received: \tTP: 0;\tFP: 1;\tFN: 38;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tcreator: \tTP: 2;\tFP: 1;\tFN: 32;\tprecision: 66.67;\trecall: 5.88;\tf1: 10.81;\t3\n",
      "\tparent taxon: \tTP: 1;\tFP: 1;\tFN: 10;\tprecision: 50.00;\trecall: 9.09;\tf1: 15.38;\t2\n",
      "\tethnic group: \tTP: 0;\tFP: 0;\tFN: 16;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tperformer: \tTP: 12;\tFP: 8;\tFN: 272;\tprecision: 60.00;\trecall: 4.23;\tf1: 7.89;\t20\n",
      "\tmanufacturer: \tTP: 0;\tFP: 1;\tFN: 30;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tdeveloper: \tTP: 2;\tFP: 1;\tFN: 53;\tprecision: 66.67;\trecall: 3.64;\tf1: 6.90;\t3\n",
      "\tseries: \tTP: 0;\tFP: 0;\tFN: 21;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsister city: \tTP: 0;\tFP: 0;\tFN: 2;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlegislative body: \tTP: 0;\tFP: 0;\tFN: 31;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tbasin country: \tTP: 0;\tFP: 0;\tFN: 24;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocated in or next to body of water: \tTP: 0;\tFP: 1;\tFN: 46;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tmilitary branch: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\trecord label: \tTP: 3;\tFP: 2;\tFN: 123;\tprecision: 60.00;\trecall: 2.38;\tf1: 4.58;\t5\n",
      "\tproduction company: \tTP: 0;\tFP: 1;\tFN: 18;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tlocation: \tTP: 0;\tFP: 0;\tFN: 30;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubclass of: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tsubsidiary: \tTP: 0;\tFP: 0;\tFN: 33;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpart of: \tTP: 0;\tFP: 5;\tFN: 166;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t5\n",
      "\toriginal language of work: \tTP: 0;\tFP: 0;\tFN: 10;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tplatform: \tTP: 0;\tFP: 0;\tFN: 56;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tmouth of the watercourse: \tTP: 0;\tFP: 0;\tFN: 22;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\toriginal network: \tTP: 2;\tFP: 2;\tFN: 29;\tprecision: 50.00;\trecall: 6.45;\tf1: 11.43;\t4\n",
      "\tmember of: \tTP: 1;\tFP: 0;\tFN: 95;\tprecision: 100.00;\trecall: 1.04;\tf1: 2.06;\t1\n",
      "\tchairperson: \tTP: 0;\tFP: 0;\tFN: 10;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcountry of origin: \tTP: 0;\tFP: 0;\tFN: 151;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\thas part: \tTP: 0;\tFP: 0;\tFN: 168;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tresidence: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tdate of birth: \tTP: 41;\tFP: 11;\tFN: 169;\tprecision: 78.85;\trecall: 19.52;\tf1: 31.30;\t52\n",
      "\tdate of death: \tTP: 22;\tFP: 12;\tFN: 143;\tprecision: 64.71;\trecall: 13.33;\tf1: 22.11;\t34\n",
      "\tinception: \tTP: 14;\tFP: 11;\tFN: 82;\tprecision: 56.00;\trecall: 14.58;\tf1: 23.14;\t25\n",
      "\tdissolved, abolished or demolished: \tTP: 0;\tFP: 0;\tFN: 16;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpublication date: \tTP: 45;\tFP: 8;\tFN: 245;\tprecision: 84.91;\trecall: 15.52;\tf1: 26.24;\t53\n",
      "\tstart time: \tTP: 1;\tFP: 0;\tFN: 23;\tprecision: 100.00;\trecall: 4.17;\tf1: 8.00;\t1\n",
      "\tend time: \tTP: 0;\tFP: 1;\tFN: 9;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t1\n",
      "\tpoint in time: \tTP: 0;\tFP: 2;\tFN: 31;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t2\n",
      "\tconflict: \tTP: 1;\tFP: 0;\tFN: 89;\tprecision: 100.00;\trecall: 1.11;\tf1: 2.20;\t1\n",
      "\tcharacters: \tTP: 0;\tFP: 0;\tFN: 30;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlyrics by: \tTP: 1;\tFP: 1;\tFN: 15;\tprecision: 50.00;\trecall: 6.25;\tf1: 11.11;\t2\n",
      "\tlocated on terrain feature: \tTP: 1;\tFP: 0;\tFN: 37;\tprecision: 100.00;\trecall: 2.63;\tf1: 5.13;\t1\n",
      "\tparticipant: \tTP: 0;\tFP: 0;\tFN: 23;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tinfluenced by: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlocation of formation: \tTP: 0;\tFP: 0;\tFN: 13;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparent organization: \tTP: 0;\tFP: 0;\tFN: 18;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnotable work: \tTP: 0;\tFP: 0;\tFN: 26;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tseparated from: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tnarrative location: \tTP: 0;\tFP: 0;\tFN: 12;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\twork location: \tTP: 0;\tFP: 0;\tFN: 24;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tapplies to jurisdiction: \tTP: 0;\tFP: 0;\tFN: 53;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tproduct or material produced: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tunemployment rate: \tTP: 0;\tFP: 0;\tFN: 1;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tterritory claimed by: \tTP: 0;\tFP: 0;\tFN: 4;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tparticipant of: \tTP: 2;\tFP: 3;\tFN: 26;\tprecision: 40.00;\trecall: 7.14;\tf1: 12.12;\t5\n",
      "\treplaces: \tTP: 0;\tFP: 0;\tFN: 10;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\treplaced by: \tTP: 0;\tFP: 0;\tFN: 15;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tcapital of: \tTP: 0;\tFP: 0;\tFN: 20;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tlanguages spoken, written or signed: \tTP: 0;\tFP: 0;\tFN: 33;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
      "\tpresent in work: \tTP: 1;\tFP: 1;\tFN: 49;\tprecision: 50.00;\trecall: 2.00;\tf1: 3.85;\t2\n",
      "\tsibling: \tTP: 0;\tFP: 4;\tFN: 109;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t4\n",
      "Testing: 100%|████████████████████████████████| 117/117 [12:18<00:00,  6.31s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_F1_micro': 7.231664195277745,\n",
      " 'test_loss': 0.37603384256362915,\n",
      " 'test_prec_micro': 60.15180265654649,\n",
      " 'test_recall_micro': 3.8470873786407767}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! python3 rebel/src/test.py model=rebel_model data=docred_data train=docred_train do_predict=True checkpoint_path=\"/home/gplsi/Escritorio/experiments/docred/last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-28 16:27:37.777326: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 16:27:37.780094: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-28 16:27:37.780104: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "\n",
    "\n",
    "refined = Refined.from_pretrained(model_name='wikipedia_model_with_numbers',\n",
    "                                  entity_set=\"wikipedia\")\n",
    "\n",
    "#spans = refined.process_text(\"England won the FIFA World Cup in 1966.\")\n",
    "spans = refined.process_text(\"England won the FIFA World Cup in 1966.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spans = refined.process_text(\"I studied in the university of texas system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', Entity not linked to a knowledge base, 'PERSON'],\n",
       " ['university of texas system', Entity(wikidata_entity_id=Q2140391, wikipedia_entity_title=University of Texas System), 'ORG']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mlayer[\u001b[38;5;241m11\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'transformer'"
     ]
    }
   ],
   "source": [
    "spans.transformer.encoder.layer[11].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    refined.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RefinedModel(\n",
       "  (mention_detection): MentionDetection(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=17, bias=True)\n",
       "  )\n",
       "  (mention_embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (entity_typing): EntityTyping(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=1369, bias=True)\n",
       "  )\n",
       "  (entity_disambiguation): EntityDisambiguation(\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "    (classifier): Linear(in_features=1372, out_features=1, bias=True)\n",
       "  )\n",
       "  (ed_2): EDLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (hidden_layer): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    (mention_projection): Linear(in_features=768, out_features=300, bias=True)\n",
       "    (description_encoder): DescriptionEncoder(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (hidden_layer): Linear(in_features=768, out_features=1000, bias=True)\n",
       "      (projection): Linear(in_features=768, out_features=300, bias=True)\n",
       "      (transformer): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-1): 2 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): RobertaPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaOutput(\n",
       "  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "refined.model.transformer.encoder.layer[11].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'refined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrefined\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\n",
      "\u001b[0;31mNameError\u001b[0m: name 'refined' is not defined"
     ]
    }
   ],
   "source": [
    "refined.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from refined.inference.processor import Refined\n",
    "import tqdm as notebook_tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/gplsi/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "refined = Refined.from_pretrained(model_name='wikipedia_model_with_numbers', entity_set='wikidata',use_precomputed_descriptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_extractor = pipeline('text2text-generation',model='Babelscape/rebel-large',tokenizer='Babelscape/rebel-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the generated text and extract the triplets\n",
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Marie Curie was a pioneering physicist and chemist. She discovered radioactivity and won Nobel Prizes in Physics and Chemistry.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "print(refined.preprocessor.tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_extractor.model.config.max_length = 1024\n",
    "triplet_extractor.tokenizer.model_max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 17105, 3622, 6, 10, 10857, 8, 9644, 1233, 1037, 950, 716, 11, 3622, 6, 2809, 6, 16, 12086, 13, 63, 32005, 638, 11, 1897, 8, 758, 9150, 6, 24764, 3617, 1587, 12966, 4867, 8, 15082, 3666, 815, 8156, 6, 8, 16, 5417, 13, 63, 5939, 472, 8, 8840, 720, 36673, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_extractor.tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_extractor.model.config.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Real Madrid, a prestigious and historically significant football club based in Madrid, Spain, is renowned for its illustrious record in domestic and international competitions, boasting numerous La Liga titles and UEFA Champions League victories, and is celebrated for its iconic players and passionate global fanbase.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 17105, 3622, 6, 10, 10857, 8, 9644, 1233, 1037, 950, 716, 11, 3622, 6, 2809, 6, 16, 12086, 13, 63, 32005, 638, 11, 1897, 8, 758, 9150, 6, 24764, 3617, 1587, 12966, 4867, 8, 15082, 3666, 815, 8156, 6, 8, 16, 5417, 13, 63, 5939, 472, 8, 8840, 720, 36673, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_extractor.tokenizer(text,max_length=1024,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction conditioning the output with <triplet> Alfredo Di Stéfano:\n",
      "<s><triplet> one <subj> football <obj> sport <subj> 1902 <obj> inception <subj> Madrid <obj> headquarters location <subj> Santiago Bernabéu Stadium <obj> home venue <subj> Real Madrid <obj> owned by <subj> football <obj> sport <subj> Madrid <obj> headquarters location <subj> Real Madrid <obj> owned by <subj> football <obj> sport <subj> football <obj> sport <subj> Madrid <obj> headquarters location <subj> football <obj> sport <subj> Madrid <obj> headquarters location <subj> football <obj> sport <subj> Madrid <obj> headquarters location <subj> Spain <obj> country <subj> Madrid <obj> headquarters location <subj> football <obj> sport</s>\n",
      "Prediction triplets sentence 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_triplets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(decoded_preds):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction triplets sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_triplets\u001b[49m(sentence))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_triplets' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "text = \"Real Madrid, one of the most iconic football clubs in the world, was founded in 1902 in Madrid, Spain. Known for their distinctive all-white kits, Los Blancos have a rich history marked by numerous domestic and international titles. They have won a record 14 UEFA Champions League titles, showcasing their dominance in European football. Legendary players like Alfredo Di Stéfano, Cristiano Ronaldo, and Zinedine Zidane have donned the Real Madrid jersey, contributing to their global fanbase. The club's home ground, Santiago Bernabéu Stadium, is a fortress renowned for its electric atmosphere. Real Madrid continues to be a symbol of excellence and ambition in football.\"\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 1024,\n",
    "    \"length_penalty\": 1, # increase length penaltytext = '''Tina Turner (born Anna Mae Bullock; November 26, 1939 – May 24, 2023) was an American-born singer. Known as the \"Queen of Rock 'n' Roll, she rose to prominence as the lead singer of the Ike & Tina Turner Revue before launching a successful career as a solo performer. She was noted for her \"swagger, sensuality, powerful gravelly vocals and unstoppable energy\", along with her well publicized history with ex-husband Ike Turner and her famous legs.'''\n",
    "    \"num_beams\": 3,\n",
    "}\n",
    "model_inputs = tokenizer(text, max_length=1024, padding=True, truncation=True, return_tensors = 'pt')\n",
    "model_outputs = tokenizer(\"<s><triplet> one <subj>\", max_length=1024, padding=True, truncation=True, return_tensors = 'pt', add_special_tokens=False)\n",
    "\n",
    "# Generate\n",
    "generated_tokens = model.generate(\n",
    "    model_inputs[\"input_ids\"].to(model.device),\n",
    "    decoder_input_ids=model_outputs[\"input_ids\"].to(model.device),\n",
    "    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "    bad_words_ids=tokenizer([\"<triplet>\"], add_special_tokens=False).input_ids, # don't generate <triplet>\n",
    "    **gen_kwargs,\n",
    ")\n",
    "\n",
    "# Extract text\n",
    "decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "print(\"Prediction conditioning the output with <triplet> Alfredo Di Stéfano:\")\n",
    "print(decoded_preds[0])\n",
    "# Extract triplets\n",
    "for idx, sentence in enumerate(decoded_preds):\n",
    "    print(f'Prediction triplets sentence {idx}')\n",
    "    print(extract_triplets(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction without conditioning the output:\n",
      "<s><triplet> Real Madrid <subj> 1902 <obj> inception <subj> Madrid <obj> headquarters location <subj> Santiago Bernabéu Stadium <obj> home venue <triplet> Real Madrid <subj> 1902 <obj> inception <subj> Madrid <obj> headquarters location <subj> Santiago Bernabéu Stadium <obj> home venue <triplet> Santiago Bernabéu Stadium <subj> Real Madrid <obj> occupant <subj> Real Madrid <obj> occupant</s>\n",
      "Prediction triplets sentence 0\n",
      "[{'head': 'Real Madrid', 'type': 'inception', 'tail': '1902'}, {'head': 'Real Madrid', 'type': 'headquarters location', 'tail': 'Madrid'}, {'head': 'Real Madrid', 'type': 'home venue', 'tail': 'Santiago Bernabéu Stadium'}, {'head': 'Real Madrid', 'type': 'inception', 'tail': '1902'}, {'head': 'Real Madrid', 'type': 'headquarters location', 'tail': 'Madrid'}, {'head': 'Real Madrid', 'type': 'home venue', 'tail': 'Santiago Bernabéu Stadium'}, {'head': 'Santiago Bernabéu Stadium', 'type': 'occupant', 'tail': 'Real Madrid'}, {'head': 'Santiago Bernabéu Stadium', 'type': 'occupant', 'tail': 'Real Madrid'}]\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "}\n",
    "# Generate\n",
    "generated_tokens = model.generate(\n",
    "    model_inputs[\"input_ids\"].to(model.device),\n",
    "    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "    **gen_kwargs,\n",
    ")\n",
    "\n",
    "# Extract text\n",
    "decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "print(\"Prediction without conditioning the output:\")\n",
    "print(decoded_preds[0])\n",
    "# Extract triplets\n",
    "for idx, sentence in enumerate(decoded_preds):\n",
    "    print(f'Prediction triplets sentence {idx}')\n",
    "    print(extract_triplets(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n",
    "model_outputs = tokenizer(\"<s><triplet> Ike Turner\", max_length=256, padding=True, truncation=True, return_tensors = 'pt', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s><triplet> Real Madrid <subj> football <obj> sport <subj> Madrid <obj> headquarters location <subj> Spain <obj> country <subj> La Liga <obj> league <subj> UEFA Champions League <obj> victory <triplet> Madrid <subj> Spain <obj> capital of <triplet> Spain <subj> Madrid <obj> capital <triplet> La Liga <subj> Real Madrid <obj> winner <subj> football <obj> sport <subj> Spain <obj> country <triplet> UEFA Champions League <subj> Real Madrid <obj> winner <subj> football <obj> sport <subj> Spain <obj> country</s>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_extractor.tokenizer.batch_decode([triplet_extractor(text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Real Madrid, one of the most iconic football clubs in the world, was founded in 1902 in Madrid, Spain. Known for their distinctive all-white kits, Los Blancos have a rich history marked by numerous domestic and international titles. They have won a record 14 UEFA Champions League titles, showcasing their dominance in European football. Legendary players like Alfredo Di Stéfano, Cristiano Ronaldo, and Zinedine Zidane have donned the Real Madrid jersey, contributing to their global fanbase. The club's home ground, Santiago Bernabéu Stadium, is a fortress renowned for its electric atmosphere. Real Madrid continues to be a symbol of excellence and ambition in football.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = extract_triplets(triplet_extractor.tokenizer.batch_decode([triplet_extractor(text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 'Real Madrid', 'type': 'sport', 'tail': 'football'},\n",
       " {'head': 'Real Madrid', 'type': 'headquarters location', 'tail': 'Madrid'},\n",
       " {'head': 'Real Madrid', 'type': 'country', 'tail': 'Spain'},\n",
       " {'head': 'Real Madrid', 'type': 'league', 'tail': 'La Liga'},\n",
       " {'head': 'Real Madrid', 'type': 'victory', 'tail': 'UEFA Champions League'},\n",
       " {'head': 'Madrid', 'type': 'capital of', 'tail': 'Spain'},\n",
       " {'head': 'Spain', 'type': 'capital', 'tail': 'Madrid'},\n",
       " {'head': 'La Liga', 'type': 'winner', 'tail': 'Real Madrid'},\n",
       " {'head': 'La Liga', 'type': 'sport', 'tail': 'football'},\n",
       " {'head': 'La Liga', 'type': 'country', 'tail': 'Spain'},\n",
       " {'head': 'UEFA Champions League', 'type': 'winner', 'tail': 'Real Madrid'},\n",
       " {'head': 'UEFA Champions League', 'type': 'sport', 'tail': 'football'},\n",
       " {'head': 'UEFA Champions League', 'type': 'country', 'tail': 'Spain'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_from_relation_extraction(triplets):\n",
    "    entity_mentions = set()\n",
    "    for triplet in triplets:\n",
    "        entity_mentions.add(triplet['head'])\n",
    "        entity_mentions.add(triplet['tail'])\n",
    "    \n",
    "    return entity_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = extract_entities_from_relation_extraction(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in entities:\n",
    "    index_start = text.find(ent)\n",
    "    index_end = index_start + len(ent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'La Liga',\n",
       " 'Madrid',\n",
       " 'Real Madrid',\n",
       " 'Spain',\n",
       " 'UEFA Champions League',\n",
       " 'football'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from refined.data_types.doc_types import Doc\n",
    "from refined.data_types.modelling_types import BatchedElementsTns\n",
    "from refined.utilities.preprocessing_utils import convert_doc_to_tensors\n",
    "\n",
    "## PREPROCESS OF THE TEXT\n",
    "doc = Doc.from_text(text,\n",
    "                    preprocessor=refined.preprocessor)\n",
    "tns: Iterable[BatchedElementsTns] = convert_doc_to_tensors(\n",
    "                doc,\n",
    "                refined.preprocessor,\n",
    "                collate=True,\n",
    "                max_batch_size=16,\n",
    "                sort_by_tokens=False,\n",
    "                max_seq=refined.max_seq,\n",
    "        )\n",
    "\n",
    "for batch_idx,batch in enumerate(tns):\n",
    "    batch_elements = batch.batch_elements\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "token_id_values = batch.token_id_values.to(device)\n",
    "attention_mask_values = batch.attention_mask_values.to(device)\n",
    "token_type_values = batch.token_type_values.to(device)\n",
    "\n",
    "output = refined.model.transformer(\n",
    "            input_ids=token_id_values,\n",
    "            attention_mask=attention_mask_values,\n",
    "            token_type_ids=token_type_values,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=None,\n",
    ")\n",
    "\n",
    "contextualised_embeddings = output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from refined.data_types.base_types import Span\n",
    "\n",
    "from mReFinED.src.refined.utilities.preprocessing_utils import pad\n",
    "\n",
    "spans: List[Span] = []\n",
    "\n",
    "person_coreference = dict()\n",
    "for ent in entities:\n",
    "    index_start = text.find(ent)\n",
    "    index_end = index_start + len(ent)\n",
    "\n",
    "    span = Span(\n",
    "        start = index_start,\n",
    "        ln = len(ent),\n",
    "        text = ent,\n",
    "        coarse_type=None,\n",
    "        coarse_mention_type=None,\n",
    "        doc_id=batch_elements[0].doc_id\n",
    "    )\n",
    "\n",
    "    spans.append(span)\n",
    "\n",
    "\n",
    "person_coreference = refined.preprocessor.add_candidates_to_spans(\n",
    "    spans,person_coreference=person_coreference\n",
    ")\n",
    "\n",
    "batch_elements[0].add_spans(spans)\n",
    "\n",
    "acc_sums_lst = [\n",
    "            [0] + list(map(lambda token: token.acc_sum, elem.tokens)) + [0]\n",
    "            for elem in batch_elements\n",
    "        ]\n",
    "\n",
    "max_seq = max([len(batch_elem.tokens) + 2 for batch_elem in batch_elements])\n",
    "acc_sums = torch.tensor(\n",
    "    pad(acc_sums_lst, seq_len=max_seq, pad_value=0), device=device, dtype=torch.long\n",
    ")\n",
    "\n",
    "\n",
    "b_entity_mask_lst = [elem.entity_mask for elem in batch_elements]\n",
    "b_entity_mask = torch.tensor(\n",
    "    pad(b_entity_mask_lst, seq_len=-1, pad_value=0), device=device, dtype=torch.long\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pem_values: List[List[float]] = []\n",
    "candidate_qcodes: List[str] = []\n",
    "candidate_qcodes_ints: List[List[int]] = []\n",
    "for batch_elem in batch_elements:\n",
    "    for span in batch_elem.spans:\n",
    "        pem_values.append(\n",
    "            [pem_value for _, pem_value in span.candidate_entities]\n",
    "        )  # TODO unpad and pad here\n",
    "        candidate_qcodes.extend(\n",
    "            [qcode for qcode, _ in span.candidate_entities]\n",
    "        )  # should pad here\n",
    "        # temporary hack (use negative IDs for additional entities IDs to avoid\n",
    "        # collisions with Wikdata IDs\n",
    "        candidate_qcodes_ints.append(\n",
    "            [int(qcode.replace(\"Q\", \"\")) if 'Q' in qcode else int(qcode.replace(\"A\", '-')) for qcode, _ in\n",
    "                span.candidate_entities]\n",
    "        )\n",
    "\n",
    "num_cands = refined.preprocessor.max_candidates\n",
    "num_ents = len([span for batch_elm in batch_elements for span in batch_elm.spans])\n",
    "cand_class_idx = refined.preprocessor.get_classes_idx_for_qcode_batch(\n",
    "            candidate_qcodes, shape=(num_ents, num_cands, -1)\n",
    ")\n",
    "\n",
    "b_cand_desc_emb = None\n",
    "b_cand_desc = None\n",
    "\n",
    "b_cand_desc_emb = refined.preprocessor.get_descriptions_emb_for_qcode_batch(\n",
    "                candidate_qcodes, shape=(num_ents, num_cands, -1)\n",
    "            ).to(device)\n",
    "b_cand_desc = None\n",
    "\n",
    "\n",
    "b_candidate_classes = torch.zeros(\n",
    "            size=(num_ents, num_cands, refined.preprocessor.num_classes+1), dtype=torch.float32, device=device\n",
    ")\n",
    "first_idx = (\n",
    "    torch.arange(num_ents, device=device)\n",
    "        .unsqueeze(1)\n",
    "        .unsqueeze(1)\n",
    "        .expand(cand_class_idx.size())\n",
    ")\n",
    "snd_idx = torch.arange(num_cands, device=device).unsqueeze(1)\n",
    "b_candidate_classes[first_idx, snd_idx, cand_class_idx] = 1\n",
    "b_pem_values = torch.tensor(pem_values, device=device, dtype=torch.float32)\n",
    "b_candidate_qcode_values = torch.tensor(\n",
    "    candidate_qcodes_ints, device=device, dtype=torch.long\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_tensors = (\n",
    "    b_candidate_qcode_values,\n",
    "    b_pem_values,\n",
    "    b_candidate_classes,\n",
    "    b_cand_desc,\n",
    "    b_cand_desc_emb,\n",
    ")\n",
    "\n",
    "(\n",
    "    cand_ids,\n",
    "    candidate_pem_values,\n",
    "    candidate_classes,\n",
    "    cand_desc,\n",
    "    cand_desc_emb,\n",
    ") = candidate_tensors\n",
    "\n",
    "mention_embeddings = refined.model._get_mention_embeddings(\n",
    "    sequence_output=contextualised_embeddings,\n",
    "    token_acc_sums=acc_sums,\n",
    "    entity_mask=b_entity_mask,\n",
    ")\n",
    "\n",
    "candidate_entity_targets = batch.candidate_target_values\n",
    "\n",
    "\n",
    "class_targets = refined.model._expand_class_targets(\n",
    "            batch.class_target_values, index_tensor=batch.entity_index_mask_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_description_scores.shape = (num_ents, num_cands)\n",
    "description_loss, candidate_description_scores = refined.model.ed_2(\n",
    "    candidate_desc=cand_desc,\n",
    "    mention_embeddings=mention_embeddings,\n",
    "    candidate_entity_targets=candidate_entity_targets,\n",
    "    candidate_desc_emb=cand_desc_emb,\n",
    ")\n",
    "\n",
    "# forward pass of entity typing layer (using predetermined spans if provided else span identified by md layer)\n",
    "et_loss, et_activations = refined.model.entity_typing(\n",
    "    mention_embeddings=mention_embeddings, span_classes=class_targets\n",
    ")\n",
    "\n",
    "# forward pass of entity disambiguation layer\n",
    "ed_loss, ed_activations = refined.model.entity_disambiguation(\n",
    "    class_activations=et_activations.detach() if refined.model.detach_ed_layer else et_activations,\n",
    "    candidate_entity_targets=candidate_entity_targets,\n",
    "    candidate_pem_values=candidate_pem_values,\n",
    "    candidate_classes=candidate_classes,\n",
    "    candidate_description_scores=candidate_description_scores.detach(),  # detach or not\n",
    "    current_device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mReFinED.src.refined.data_types.modelling_types import ModelReturn\n",
    "\n",
    "\n",
    "output = ModelReturn(\n",
    "            None,\n",
    "            None,\n",
    "            et_loss,\n",
    "            et_activations,\n",
    "            ed_loss,\n",
    "            ed_activations,\n",
    "            spans,\n",
    "            None,\n",
    "            cand_ids,\n",
    "            description_loss,\n",
    "            candidate_description_scores,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from mReFinED.src.refined.utilities.general_utils import round_list\n",
    "\n",
    "\n",
    "spans = output.entity_spans\n",
    "device = output.et_activations.device\n",
    "\n",
    "cand_ids = torch.cat(\n",
    "            [output.cand_ids, torch.ones((output.cand_ids.size(0), 1), device=device, dtype=torch.long) * -1], 1\n",
    "        )\n",
    "\n",
    "ed_targets_predictions = output.ed_activations.argmax(dim=1)\n",
    "ed_targets_softmax = output.ed_activations.softmax(dim=1)\n",
    "\n",
    "\n",
    "description_scores = output.candidate_description_scores.detach().cpu().numpy()\n",
    "\n",
    "predicted_entity_ids = (\n",
    "    cand_ids[torch.arange(cand_ids.size(0)), ed_targets_predictions].cpu().numpy().tolist()\n",
    ")\n",
    "predicted_entity_confidence = round_list(\n",
    "    ed_targets_softmax[torch.arange(ed_targets_softmax.size(0)), ed_targets_predictions]\n",
    "        .cpu().detach()\n",
    "        .numpy()\n",
    "        .tolist(),\n",
    "    4,\n",
    ")\n",
    "\n",
    "\n",
    "span_to_classes = defaultdict(list)\n",
    "span_indices, pred_class_indices = torch.nonzero(\n",
    "    output.et_activations > 0.5, as_tuple=True\n",
    ")\n",
    "for span_idx, pred_class_idx, conf in zip(\n",
    "        span_indices.cpu().numpy().tolist(),\n",
    "        pred_class_indices.cpu().numpy().tolist(),\n",
    "        round_list(\n",
    "            output.et_activations[(span_indices, pred_class_indices)].cpu().detach().numpy().tolist(), 4\n",
    "        ),\n",
    "):\n",
    "    if pred_class_idx == 0:\n",
    "        continue  # skip padding class label\n",
    "    class_id = refined.preprocessor.index_to_class.get(pred_class_idx, \"Q0\")\n",
    "    class_label = refined.preprocessor.class_to_label.get(class_id, \"no_label\")\n",
    "    span_to_classes[span_idx].append((class_id, class_label, conf))\n",
    "\n",
    "sorted_entity_ids_scores, old_indices = ed_targets_softmax.sort(descending=True)\n",
    "sorted_entity_ids_scores = sorted_entity_ids_scores.cpu().detach().numpy().tolist()\n",
    "sorted_entity_ids = refined.sort_tensor(cand_ids, old_indices).cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mReFinED.src.refined.data_types.base_types import Entity\n",
    "\n",
    "\n",
    "for span_idx, span in enumerate(spans):\n",
    "    wikidata_id = f'Q{str(predicted_entity_ids[span_idx])}'\n",
    "    span.predicted_entity = Entity(\n",
    "        wikidata_entity_id=wikidata_id,\n",
    "        wikipedia_entity_title=refined.preprocessor.qcode_to_wiki.get(wikidata_id)\n",
    "        if refined.preprocessor.qcode_to_wiki is not None else None\n",
    "    )\n",
    "    span.entity_linking_model_confidence_score = predicted_entity_confidence[span_idx]\n",
    "    span.top_k_predicted_entities = [\n",
    "        (Entity(wikidata_entity_id=f'Q{entity_id}',\n",
    "                wikipedia_entity_title=refined.preprocessor.qcode_to_wiki.get(wikidata_id)\n",
    "                if refined.preprocessor.qcode_to_wiki is not None else None\n",
    "                ),\n",
    "            round(score, 4))\n",
    "        for entity_id, score in\n",
    "        zip(sorted_entity_ids[span_idx], sorted_entity_ids_scores[span_idx])\n",
    "        if entity_id != 0\n",
    "    ]\n",
    "\n",
    "    span.candidate_entities = [\n",
    "        (qcode, round(conf, 4))\n",
    "        for qcode, conf in filter(lambda x: not x[0] == \"Q0\", span.candidate_entities)\n",
    "    ]\n",
    "    span.description_scores = round_list(\n",
    "        description_scores[span_idx].tolist(), 4\n",
    "    )  # matches candidate order\n",
    "    span.predicted_entity_types = span_to_classes[span_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Real Madrid', Entity(wikidata_entity_id=Q8682, wikipedia_entity_title=Real Madrid CF), None],\n",
       " ['Madrid', Entity(wikidata_entity_id=Q2807, wikipedia_entity_title=Madrid), None],\n",
       " ['football', Entity(wikidata_entity_id=Q2736, wikipedia_entity_title=Association football), None],\n",
       " ['Spain', Entity(wikidata_entity_id=Q29, wikipedia_entity_title=Spain), None],\n",
       " ['La Liga', Entity(wikidata_entity_id=Q324867, wikipedia_entity_title=La Liga), None],\n",
       " ['UEFA Champions League', Entity(wikidata_entity_id=Q18756, wikipedia_entity_title=UEFA Champions League), None]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[2].entity_linking_model_confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -cikit-learn (/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wikidata\n",
      "  Downloading Wikidata-0.8.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading Wikidata-0.8.1-py3-none-any.whl (29 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -cikit-learn (/home/gplsi/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wikidata\n",
      "Successfully installed wikidata-0.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: England\n",
      "Description: country in north-west Europe, part of the United Kingdom\n"
     ]
    }
   ],
   "source": [
    "from wikidata.client import Client\n",
    "import wikidata\n",
    "\n",
    "# Initialize the client\n",
    "client = Client()\n",
    "\n",
    "# Define the entity's ID (e.g., Q42 for Douglas Adams)\n",
    "entity_id = 'Q21'  # Change this to any Wikidata entity ID\n",
    "\n",
    "# Fetch the entity\n",
    "entity = client.get(entity_id, load=True)\n",
    "\n",
    "# Retrieve basic attributes of the entity\n",
    "print(\"Label:\", entity.label)  # Get the label (name) of the entity\n",
    "print(\"Description:\", entity.description)  # Get the description of the entity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q21'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = entity.attributes['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Novelda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['es']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Novelda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['en']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Novelda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['ca']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonym\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/wikidata/entity.py:57\u001b[0m, in \u001b[0;36mmultilingual_attribute.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcache_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '$labels'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m entity\u001b[38;5;241m.\u001b[39miterlists():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/wikidata/entity.py:59\u001b[0m, in \u001b[0;36mmultilingual_attribute.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     57\u001b[0m     value \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[cache_id]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute) \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping)\n\u001b[1;32m     61\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m         (item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m], item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/wikidata/entity.py:271\u001b[0m, in \u001b[0;36mEntity.attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattributes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/wikidata/entity.py:280\u001b[0m, in \u001b[0;36mEntity.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    279\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./wiki/Special:EntityData/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 280\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m EntityState\u001b[38;5;241m.\u001b[39mnon_existent\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/site-packages/wikidata/client.py:202\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    200\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: no cache; make a request...\u001b[39m\u001b[38;5;124m'\u001b[39m, url)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP error code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, e\u001b[38;5;241m.\u001b[39mcode, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/urllib/request.py:1397\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/urllib/request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1354\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1254\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m \n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 951\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:1418\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1421\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/http/client.py:922\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    921\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m~/anaconda3/envs/GeoPrueba/lib/python3.8/socket.py:796\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    795\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 796\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    798\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in entity.iterlists():\n",
    "    print(i[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wikidata.entity.Entity P244 'Library of Congress authority ID'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m'Library of Congress authority ID'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wikidata.entity.Entity Q9645584>\n",
      "Novelda\n",
      "<wikidata.entity.Entity Q29>\n",
      "03660\n",
      "<wikidata.commonsmedia.File 'File:Ayuntamiento de Novelda, Plaza de España, Novelda, Alicante - panoramio.jpg'>\n",
      "<wikidata.commonsmedia.File 'File:Localització de Novelda respecte el País Valencià.png'>\n",
      "wikidata.globecoordinate.GlobeCoordinate(38.386111111111, -0.76527777777778, <wikidata.entity.Entity Q2>, None)\n",
      "<wikidata.entity.Entity Q5866679>\n",
      "<wikidata.entity.Entity Q2300692>\n",
      "03093\n",
      "http://novelda.es\n",
      "<wikidata.entity.Entity Q2074737>\n",
      "<wikidata.entity.Entity Q123754112>\n",
      "/m/055hmj\n",
      "wikidata.quantity.Quantity(25771.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26517.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26692.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26873.0, None, None, None)\n",
      "wikidata.quantity.Quantity(27104.0, None, None, None)\n",
      "wikidata.quantity.Quantity(27135.0, None, None, None)\n",
      "wikidata.quantity.Quantity(27008.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26525.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26335.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26233.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25653.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25399.0, None, None, None)\n",
      "wikidata.quantity.Quantity(24885.0, None, None, None)\n",
      "wikidata.quantity.Quantity(24111.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26292.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26146.0, None, None, None)\n",
      "wikidata.quantity.Quantity(26054.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25868.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25725.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25651.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25741.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25611.0, None, None, None)\n",
      "wikidata.quantity.Quantity(25592.0, None, None, None)\n",
      "6355468\n",
      "<wikidata.entity.Entity Q13372>\n",
      "<wikidata.entity.Entity Q115329>\n",
      "<wikidata.entity.Entity Q15148574>\n",
      "341444\n",
      "155944053\n",
      "wikidata.quantity.Quantity(241.0, None, None, <wikidata.entity.Entity Q11573>)\n",
      "ae32bcf8-34c2-41f4-a4e5-485e6ea81261\n",
      "Novelda\n",
      "0046521\n",
      "<wikidata.entity.Entity Q1751353>\n",
      "<wikidata.entity.Entity Q1769358>\n",
      "<wikidata.entity.Entity Q1770153>\n",
      "<wikidata.entity.Entity Q1752019>\n",
      "<wikidata.entity.Entity Q1645615>\n",
      "<wikidata.entity.Entity Q608985>\n",
      "<wikidata.commonsmedia.File 'File:Escut de Novelda (1980).svg'>\n",
      "<wikidata.commonsmedia.File 'File:Bandera de Novelda.svg'>\n",
      "<wikidata.entity.Entity Q26702121>\n",
      "<wikidata.entity.Entity Q6655>\n",
      "Novelda\n",
      "pcrtnDoRiY45yK\n",
      "A\n",
      "wikidata.quantity.Quantity(75.7, None, None, <wikidata.entity.Entity Q712226>)\n",
      "7576772-7\n",
      "novelder\n",
      "noveldera\n",
      "noveldense\n",
      "101779043\n",
      "Novelda\n",
      "lccn-n81002947\n",
      "<wikidata.entity.Entity Q78030913>\n",
      "wikidata.quantity.Quantity(12881.0, None, None, None)\n",
      "wikidata.quantity.Quantity(12770.0, None, None, None)\n",
      "<wikidata.entity.Entity Q31948198>\n",
      "ES.IGN.BDDAE.34100303093\n",
      "Q351400\n",
      "<wikidata.entity.Entity Q7026>\n",
      "186\n",
      "<wikidata.commonsmedia.File 'File:Castillo de la Mola y Santuario de Santa María Magdalena, Novelda, Alicante - panoramio (cropped).jpg'>\n",
      "<wikidata.entity.Entity Q23982201>\n",
      "<wikidata.entity.Entity Q867541>\n",
      "novelda\n",
      "n81002947\n"
     ]
    }
   ],
   "source": [
    "for i in entity.iterlistvalues():\n",
    "    for value in i:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar json con todas las posibles propiedades que existen en wikidata para agilizar la búsqueda de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "url = \"https://www.wikidata.org/wiki/Wikidata:Database_reports/List_of_properties/all\"\n",
    "\n",
    "response = requests.get(url)\n",
    "webpage = response.content\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "table = soup.find(\"table\",{\"class\":\"wikitable sortable\"})\n",
    "\n",
    "# Extract headers (if present)\n",
    "headers = []\n",
    "for th in table.find_all(\"th\"):\n",
    "    headers.append(th.text.strip())\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "properties_dict = {\n",
    "\n",
    "}\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    cells = tr.find_all([\"td\", \"th\"])  # In case headers are used in the table\n",
    "    row = [cell.text.strip() for cell in cells]\n",
    "    if row:  # Make sure row is not empty\n",
    "        #rows.append(row)\n",
    "        properties_dict[row[0]] = row[1]\n",
    "\n",
    "properties_dict\n",
    "\n",
    "with open(\"properties.json\",\"w\") as file:\n",
    "    json.dump(properties_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P1332'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000000/9000000 [00:00<00:00, 12123079.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for i in tqdm(range(int(9e6))):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", n.`coordinates_of_northernmost_point`=$coordinates_of_northernmost_point, n.`iso_3166-2_code`=$iso_3166-2_code, n.`commons_category`=$commons_category, n.`coordinate_location`=$coordinate_location, n.`openstreetmap_relation_id`=$openstreetmap_relation_id, n.`curlie_id`=$curlie_id, n.`commons_gallery`=$commons_gallery, n.`musicbrainz_area_id`=$musicbrainz_area_id, n.`freebase_id`=$freebase_id, n.`gnd_id`=$gnd_id, n.`library_of_congress_authority_id`=$library_of_congress_authority_id, n.`viaf_id`=$viaf_id, n.`coordinates_of_southernmost_point`=$coordinates_of_southernmost_point, n.`coordinates_of_westernmost_point`=$coordinates_of_westernmost_point, n.`coordinates_of_easternmost_point`=$coordinates_of_easternmost_point, n.`geonames_id`=$geonames_id, n.`fast_id`=$fast_id, n.`gss_code_(2011)`=$gss_code_(2011), n.`encyclopædia_britannica_online_id`=$encyclopædia_britannica_online_id, n.`tripadvisor_id`=$tripadvisor_id, n.`ne.se_id`=$ne.se_id, n.`quora_topic_id`=$quora_topic_id, n.`woeid`=$woeid, n.`vision_of_britain_place_id`=$vision_of_britain_place_id, n.`toid`=$toid, n.`yso_id`=$yso_id, n.`area`=$area, n.`u.s._national_archives_identifier`=$u.s._national_archives_identifier, n.`bvmc_person_id`=$bvmc_person_id, n.`gacs_id`=$gacs_id, n.`mesh_descriptor_id`=$mesh_descriptor_id, n.`babelnet_id`=$babelnet_id, n.`early_modern_letters_online_location_id`=$early_modern_letters_online_location_id, n.`great_russian_encyclopedia_online_id_(old_version)`=$great_russian_encyclopedia_online_id_(old_version), n.`mean_age`=$mean_age, n.`number_of_households`=$number_of_households, n.`brockhaus_enzyklopädie_online_id`=$brockhaus_enzyklopädie_online_id, n.`store_norske_leksikon_id`=$store_norske_leksikon_id, n.`geoshape`=$geoshape, n.`isni`=$isni, n.`archinform_location_id`=$archinform_location_id, n.`national_library_of_israel_id_(old)`=$national_library_of_israel_id_(old), n.`pactols_thesaurus_id`=$pactols_thesaurus_id, n.`nl_cr_aut_id`=$nl_cr_aut_id, n.`getty_thesaurus_of_geographic_names_id`=$getty_thesaurus_of_geographic_names_id, n.`idref_id`=$idref_id, n.`bibliothèque_nationale_de_france_id`=$bibliothèque_nationale_de_france_id, n.`giant_bomb_id`=$giant_bomb_id, n.`klexikon_article_id`=$klexikon_article_id, n.`loc_and_marc_vocabularies_id`=$loc_and_marc_vocabularies_id, n.`dr_topic_id`=$dr_topic_id, n.`gran_enciclopèdia_catalana_id_(former_scheme)`=$gran_enciclopèdia_catalana_id_(former_scheme), n.`inaturalist_place_id`=$inaturalist_place_id, n.`tdv_i̇slam_ansiklopedisi_id`=$tdv_i̇slam_ansiklopedisi_id, n.`omegawiki_defined_meaning`=$omegawiki_defined_meaning, n.`official_website`=$official_website, n.`who's_on_first_id`=$who's_on_first_id, n.`fandom_article_id`=$fandom_article_id, n.`analysis_&_policy_observatory_term_id`=$analysis_&_policy_observatory_term_id, n.`niconicopedia_id`=$niconicopedia_id, n.`kbpedia_id`=$kbpedia_id, n.`grove_art_online_id`=$grove_art_online_id, n.`fandom_wiki_id`=$fandom_wiki_id, n.`gynopedia_id`=$gynopedia_id, n.`rkd_thesaurus_id`=$rkd_thesaurus_id, n.`interlingual_index_id`=$interlingual_index_id, n.`the_top_tens_id`=$the_top_tens_id, n.`edition_humboldt_digital_id`=$edition_humboldt_digital_id, n.`uk_parliament_thesaurus_id`=$uk_parliament_thesaurus_id, n.`bhcl_uuid`=$bhcl_uuid, n.`github_topic`=$github_topic, n.`wordnet_3.1_synset_id`=$wordnet_3.1_synset_id, n.`provenio_uuid`=$provenio_uuid, n.`aiatsis_place_thesaurus_id`=$aiatsis_place_thesaurus_id, n.`ávvir_topic_id`=$ávvir_topic_id, n.`ysa_id`=$ysa_id, n.`yle_topic_id`=$yle_topic_id, n.`x_topic_id`=$x_topic_id, n.`joconde_location_id`=$joconde_location_id, n.`idai.gazetteer_id`=$idai.gazetteer_id, n.`rationalwiki_id`=$rationalwiki_id, n.`armeniapedia_id`=$armeniapedia_id, n.`namuwiki_id`=$namuwiki_id, n.`schoenberg_database_of_manuscripts_place_id`=$schoenberg_database_of_manuscripts_place_id, n.`termcymru_id`=$termcymru_id, n.`online_pwn_encyclopedia_id`=$online_pwn_encyclopedia_id, n.`comic_vine_id`=$comic_vine_id, n.`colon_classification`=$colon_classification, n.`national_library_of_israel_j9u_id`=$national_library_of_israel_j9u_id, n.`gyldendals_teaterleksikon_id`=$gyldendals_teaterleksikon_id, n.`museum-digital_place_id`=$museum-digital_place_id, n.`google_arts_&_culture_entity_id`=$google_arts_&_culture_entity_id, n.`wikisimpsons_article_id`=$wikisimpsons_article_id, n.`den_store_danske_id`=$den_store_danske_id, n.`subreddit`=$subreddit, n.`mapy.cz_id`=$mapy.cz_id, n.`alltrails_trail_id`=$alltrails_trail_id, n.`country_calling_code`=$country_calling_code, n.`famous_birthdays_id`=$famous_birthdays_id, n.`de_agostini_id`=$de_agostini_id, n.`trismegistos_geo_id`=$trismegistos_geo_id, n.`obo_gazetteer_id`=$obo_gazetteer_id, n.`factgrid_item_id`=$factgrid_item_id, n.`icpsr_geographic_names_thesaurus_id`=$icpsr_geographic_names_thesaurus_id, n.`worldcat_entities_id`=$worldcat_entities_id, n.`britannica_kids_kids_level_article_id`=$britannica_kids_kids_level_article_id, n.`britannica_kids_students_level_article_id`=$britannica_kids_students_level_article_id, n.`britannica_kids_scholars_level_article_id`=$britannica_kids_scholars_level_article_id, n.`umls_cui`=$umls_cui, n.`bbc_news_topic_id`=$bbc_news_topic_id, n.`mindat_locality_id`=$mindat_locality_id, n.`open_library_subject_id`=$open_library_subject_id, n.`noraf_id`=$noraf_id, n.`national_library_of_brazil_id`=$national_library_of_brazil_id, n.`national_library_of_chile_id`=$national_library_of_chile_id, n.`national_library_of_spain_id`=$national_library_of_spain_id, n.`canadiana_name_authority_id`=$canadiana_name_authority_id, n.`dbc_author_id`=$dbc_author_id, n.`national_library_of_ireland_id`=$national_library_of_ireland_id, n.`nacsis-cat_author_id`=$nacsis-cat_author_id, n.`libraries_australia_id`=$libraries_australia_id, n.`portuguese_national_library_author_id`=$portuguese_national_library_author_id, n.`cinii_research_id`=$cinii_research_id, n.`wikikids_id`=$wikikids_id, n.`larousse_id`=$larousse_id, n.`gran_enciclopèdia_catalana_id`=$gran_enciclopèdia_catalana_id, n.`x_place_id`=$x_place_id, n.`population`=$population, n.`google_maps_customer_id`=$google_maps_customer_id, n.`australian_war_memorial_id`=$australian_war_memorial_id, n.`vikidia_article_id`=$vikidia_article_id, n.`guardian_topic_id`=$guardian_topic_id, n.`zhihu_topic_id`=$zhihu_topic_id, n.`data_commons_id`=$data_commons_id, n.`hashtag`=$hashtag\n",
      "{'coordinates_of_northernmost_point': 'point({latitude: 55.8,longitude:-2.0333333333333})', 'iso_3166-2_code': 'GB-ENG', 'commons_category': 'England', 'coordinate_location': 'point({latitude: 53,longitude:-1})', 'openstreetmap_relation_id': '58447', 'curlie_id': 'Regional/Europe/United_Kingdom/England/', 'commons_gallery': 'England', 'musicbrainz_area_id': '9d5dd675-3cf4-4296-9e39-67865ebee758', 'freebase_id': '/m/02jx1', 'gnd_id': '4014770-8', 'library_of_congress_authority_id': 'n82068148', 'viaf_id': '142995804', 'coordinates_of_southernmost_point': 'point({latitude: 49.85,longitude:-6.4})', 'coordinates_of_westernmost_point': 'point({latitude: 49.883333333333,longitude:-6.45})', 'coordinates_of_easternmost_point': 'point({latitude: 52.481166666667,longitude:1.7628333333333})', 'geonames_id': '2649994', 'fast_id': '1219920', 'gss_code_(2011)': 'E92000001', 'encyclopædia_britannica_online_id': 'place/England', 'tripadvisor_id': '186217', 'ne.se_id': 'england', 'quora_topic_id': 'England-U-K', 'woeid': '24554868', 'vision_of_britain_place_id': '20003', 'toid': 'country/england', 'yso_id': '107128', 'area': '130278.43,square kilometre', 'u.s._national_archives_identifier': '10044298', 'bvmc_person_id': '6749', 'gacs_id': '8071', 'mesh_descriptor_id': 'D004739', 'babelnet_id': '00030861n', 'early_modern_letters_online_location_id': '8029cfd7-cbda-454c-86e7-ec517c2b02d5', 'great_russian_encyclopedia_online_id_(old_version)': '1821392', 'mean_age': '39.3,annum', 'number_of_households': '23044097.0', 'brockhaus_enzyklopädie_online_id': 'england', 'store_norske_leksikon_id': 'England', 'geoshape': 'Data:England.map', 'isni': '0000000122934507', 'archinform_location_id': '2773', 'national_library_of_israel_id_(old)': '000992810', 'pactols_thesaurus_id': 'pcrtf8JAKrEv8Z', 'nl_cr_aut_id': 'ge134022', 'getty_thesaurus_of_geographic_names_id': '7002445', 'idref_id': '02735895X', 'bibliothèque_nationale_de_france_id': '11930575r', 'giant_bomb_id': '3035-192', 'klexikon_article_id': 'England', 'loc_and_marc_vocabularies_id': 'geographicAreas/e-uk-en', 'dr_topic_id': 'england', 'gran_enciclopèdia_catalana_id_(former_scheme)': '0004059', 'inaturalist_place_id': '6858', 'tdv_i̇slam_ansiklopedisi_id': 'ingiltere', 'omegawiki_defined_meaning': '357415', 'official_website': 'https://www.visitengland.com/', \"who's_on_first_id\": '1360699091', 'fandom_article_id': 'unitedkingdom:England', 'analysis_&_policy_observatory_term_id': '6002', 'niconicopedia_id': 'イングランド', 'kbpedia_id': 'England', 'grove_art_online_id': 'T026083', 'fandom_wiki_id': 'england', 'gynopedia_id': 'England', 'rkd_thesaurus_id': '457', 'interlingual_index_id': 'i83374', 'the_top_tens_id': '104', 'edition_humboldt_digital_id': 'H0005653', 'uk_parliament_thesaurus_id': '9942', 'bhcl_uuid': '4aa01595-5b48-489e-ad19-4dfa33c51019', 'github_topic': 'england', 'wordnet_3.1_synset_id': '08891234-n', 'provenio_uuid': 'e674a7f9-dae3-4930-b0ab-7cd9e7dcfa64', 'aiatsis_place_thesaurus_id': '4417', 'ávvir_topic_id': 'englanda', 'ysa_id': 'Y107128', 'yle_topic_id': '18-31020', 'x_topic_id': '897814268539682816', 'joconde_location_id': 'T84-3506', 'idai.gazetteer_id': '2081974', 'rationalwiki_id': 'England', 'armeniapedia_id': '4067', 'namuwiki_id': '잉글랜드', 'schoenberg_database_of_manuscripts_place_id': '5', 'termcymru_id': '169442446', 'online_pwn_encyclopedia_id': '3869522', 'comic_vine_id': '4020-55794', 'colon_classification': 'SG--561', 'national_library_of_israel_j9u_id': '987007566799405171', 'gyldendals_teaterleksikon_id': 'England', 'museum-digital_place_id': '317', 'google_arts_&_culture_entity_id': 'm02jx1', 'wikisimpsons_article_id': '16191', 'den_store_danske_id': 'England', 'subreddit': 'england', 'mapy.cz_id': 'osm&id=136390611', 'alltrails_trail_id': 'england', 'country_calling_code': '+44', 'famous_birthdays_id': 'birthplace/england', 'de_agostini_id': 'Inghiltèrra', 'trismegistos_geo_id': '19851', 'obo_gazetteer_id': '00002641', 'factgrid_item_id': 'Q140531', 'icpsr_geographic_names_thesaurus_id': '14281', 'worldcat_entities_id': 'E39PBJpYDdYvBpjXV6WpybK68C', 'britannica_kids_kids_level_article_id': '353101', 'britannica_kids_students_level_article_id': '274182', 'britannica_kids_scholars_level_article_id': '110752', 'umls_cui': 'C0014282', 'bbc_news_topic_id': 'ck71r1x591xt', 'mindat_locality_id': '14093', 'open_library_subject_id': 'place:england', 'noraf_id': '90298001', 'national_library_of_brazil_id': '000631887', 'national_library_of_chile_id': '000006048', 'national_library_of_spain_id': 'XX450601', 'canadiana_name_authority_id': 'ncf10028858', 'dbc_author_id': '87097992621006', 'national_library_of_ireland_id': 'vtls000011144', 'nacsis-cat_author_id': 'DA08722858', 'libraries_australia_id': '35764235', 'portuguese_national_library_author_id': '184394', 'cinii_research_id': '1140563741698911488', 'wikikids_id': 'Engeland', 'larousse_id': 'autre-region/Angleterre/105499', 'gran_enciclopèdia_catalana_id': 'anglaterra', 'x_place_id': '8ef32ff56ef11c22', 'population': '56325961.0', 'google_maps_customer_id': '17645548802019266216', 'australian_war_memorial_id': 'PL567', 'vikidia_article_id': 'fr:Angleterre', 'guardian_topic_id': 'uk-news/england', 'zhihu_topic_id': '19681014', 'data_commons_id': 'wikidataId/Q21', 'hashtag': 'england'}\n"
     ]
    }
   ],
   "source": [
    "import wikidata.quantity\n",
    "import json\n",
    "\n",
    "with open('properties.json','r') as file:\n",
    "    properties_dict = json.load(file)\n",
    "\n",
    "dict = {\n",
    "    \n",
    "}\n",
    "for i in entity.iterlists():\n",
    "    for j in i[1]:\n",
    "        property = None\n",
    "        if type(j) == str:\n",
    "             property = properties_dict[i[0].id].lower().replace(' ','_')\n",
    "             unity =  str(j) \n",
    "             dict[property] = j\n",
    "        if type(j) == wikidata.quantity.Quantity:\n",
    "             property = properties_dict[i[0].id].lower().replace(' ','_')\n",
    "             unity =  \",\" +  str(j.unit.label) if j.unit is not None else \"\"\n",
    "             dict[property] = str(j.amount) + unity\n",
    "        if type(j) == wikidata.globecoordinate.GlobeCoordinate:\n",
    "            property = properties_dict[i[0].id].lower().replace(' ','_')\n",
    "            dict[property] = \"point({latitude: \"+str(j.latitude)+\",longitude:\"+str(j.longitude)+\"})\"\n",
    "\n",
    "\n",
    "stmt_part = \"\"\n",
    "for key in dict.keys():\n",
    "    stmt_part += \", n.`\"+key+\"`=$\"+key\n",
    "\n",
    "print(stmt_part)\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', n.`coordinates_of_northernmost_point`=$coordinates_of_northernmost_point, n.`coordinate_location`=$coordinate_location, n.`coordinates_of_southernmost_point`=$coordinates_of_southernmost_point, n.`coordinates_of_westernmost_point`=$coordinates_of_westernmost_point, n.`coordinates_of_easternmost_point`=$coordinates_of_easternmost_point, n.`area`=$area, n.`mean_age`=$mean_age, n.`number_of_households`=$number_of_households, n.`population`=$population'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmt_part = \"\"\n",
    "for key in dict.keys():\n",
    "    stmt_part += \", n.`\"+key+\"`=$\"+key\n",
    "\n",
    "stmt_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.386111111111"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.76527777777778"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wikidata.entity.Entity Q2 'Earth'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoPrueba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
